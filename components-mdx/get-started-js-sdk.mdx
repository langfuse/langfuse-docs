```ts filename="server.ts"
import { Langfuse } from "langfuse";

const langfuse = new Langfuse();

const trace = langfuse.trace({
  name: "my-AI-application-endpoint",
});

// Example generation creation
const generation = trace.generation({
  name: "chat-completion",
  model: "gpt-3.5-turbo",
  modelParameters: {
    temperature: 0.9,
    maxTokens: 2000,
  },
  input: messages,
});

// Application code
const chatCompletion = await llm.respond(prompt);

// End generation - sets endTime
generation.end({
  output: chatCompletion,
});
```

**Install packages**

Install the Langfuse OpenAI wrapper, the official OpenAI SDK, and the Langfuse OpenTelemetry integration required for tracing.

```sh
npm install @langfuse/openai @langfuse/otel
```

**Add credentials**

Add your Langfuse credentials to your environment variables so the SDK knows which project to write to. 

import EnvJS from "@/components-mdx/env-js.mdx";
import SetupOtelJS from "@/components-mdx/setup-otel-js.mdx"

<EnvJS />

**Initialize OpenTelemetry**

<SetupOtelJS />

Wrap your normal OpenAI client. From now on, each OpenAI request  is automatically collected and forwarded to Langfuse.

**Wrap OpenAI client**
```ts
import OpenAI from "openai";
import { observeOpenAI } from "@langfuse/openai";

const openai = observeOpenAI(new OpenAI());

const res = await openai.chat.completions.create({
    messages: [{ role: "system", content: "Tell me a story about a dog." }],
    model: "gpt-4o",
    max_tokens: 300,
});
```

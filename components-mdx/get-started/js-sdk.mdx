**Install package**
```sh
npm install @langfuse/openai
```

**Add credentials**

Add your Langfuse credentials to your environment variables. Make sure that you have a `.env` file in your project root and a package like `dotenv` to load the variables.

import EnvJS from "@/components-mdx/env-js.mdx";
import SetupOtelJS from "@/components-mdx/setup-otel-js.mdx"

<EnvJS />

**Initialize OpenTelemetry**

<SetupOtelJS />

**Instrument application**

```ts filename="server.ts"
import { startActiveObservation, startObservation } from "@langfuse/tracing";

await startActiveObservation("user-request", async (span) => {
  span.update({
    input: { query: "What is the capital of France?" },
  });

  // This generation will automatically be a child of "user-request"
  const generation = startObservation(
    "llm-call",
    {
      model: "gpt-4",
      input: [{ role: "user", content: "What is the capital of France?" }],
    },
    { asType: "generation" },
  );

  // ... LLM call logic ...

  generation
    .update({
      output: { content: "The capital of France is Paris." },
    })
    .end();

  span.update({ output: "Successfully answered." });
});
```

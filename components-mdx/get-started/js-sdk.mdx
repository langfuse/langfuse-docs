**Install package**
```sh
npm install @langfuse/openai
```

**Add credentials**

Add your Langfuse credentials to your environment variables. Make sure that you have a `.env` file in your project root and a package like `dotenv` to load the variables.

import EnvJS from "@/components-mdx/env-js.mdx";
import SetupOtelJS from "@/components-mdx/setup-otel-js.mdx"

<EnvJS />

**Initialize OpenTelemetry**

<SetupOtelJS />

**Instrument application**

```ts filename="server.ts"
import { startActiveSpan, startActiveGeneration } from "@langfuse/tracing"

const completion = await starActiveSpan('my-AI-application-endpoint', async (span) => {
  await startActiveGeneration(async(generation) => {
    const chatCompletion = await llm.respond(prompt);

    generation.update({
      name: "chat-completion",
      model: "gpt-4o",
      input: messages,
      output: chatCompletion,
    })

    return chatCompletion
  })
})
```

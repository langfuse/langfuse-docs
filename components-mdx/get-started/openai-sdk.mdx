import Env from "@/components-mdx/env-python.mdx";

```bash
pip install langfuse
```

Set your Langfuse credentials as environment variables so the SDK knows which project to write to.
<Env />

Swap the regular OpenAI import to Langfuseâ€™s OpenAI drop-in. It behaves like the regular OpenAI client, but also automatically records each call for you.

```python
from langfuse.openai import openai
```

Use the OpenAI SDK as you normally would. The wrapper captures the prompt, model and output and forwards everything to Langfuse without changing the response you get back.

```python
completion = openai.chat.completions.create(
  name="test-chat",
  model="gpt-4o",
  messages=[
      {"role": "system", "content": "You are a very accurate calculator. You output only the result of the calculation."},
      {"role": "user", "content": "1 + 1 = "}],
  metadata={"someMetadataKey": "someValue"},
)
```
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWEKl-UfX-ZS"
      },
      "source": [
        "---\n",
        "description: End-to-end example of creating a dataset, adding items, and running experiments with Langfuse datasets.\n",
        "category: Datasets\n",
        "---\n",
        "\n",
        "# Langfuse Datasets Cookbook\n",
        "\n",
        "In this cookbook, we'll iterate on systems prompts with the goal of getting only the capital of a given country. We use Langfuse datasets, to store a list of example inputs and expected outputs.\n",
        "\n",
        "This is a very simple example, you can run experiments on any LLM application that you either trace with the [Langfuse SDKs](https://langfuse.com/docs/sdk) (Python, JS/TS) or via one of our [integrations](https://langfuse.com/docs/integrations) (e.g. Langchain).\n",
        "\n",
        "_Simple example application_\n",
        "\n",
        "- **Model**: gpt-3.5-turbo\n",
        "- **Input**: country name\n",
        "- **Output**: capital\n",
        "- **Evaluation**: exact match of completion and ground truth\n",
        "- **Experiment on**: system prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iexlvXyM2eFF"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PONlf847Xp-A"
      },
      "outputs": [],
      "source": [
        "%pip install langfuse openai langchain_openai langchain --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAquPGo3X8hg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# get keys for your project from https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"\"\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"\"\n",
        "\n",
        "# your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# Your host, defaults to https://cloud.langfuse.com\n",
        "# For US data region, set to \"https://us.cloud.langfuse.com\"\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"http://localhost:3000\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kM5oWlyYitA"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from langfuse import Langfuse\n",
        "import openai\n",
        "\n",
        "# init\n",
        "langfuse = Langfuse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwVQW5ZmX7_4"
      },
      "source": [
        "## Create a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH6_snEmXukE"
      },
      "outputs": [],
      "source": [
        "langfuse.create_dataset(name=\"capital_cities\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ArUZboetn3",
        "tags": []
      },
      "source": [
        "### Items\n",
        "\n",
        "Load local items into the Langfuse dataset. Alternatively you can add items from production via the Langfuse UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9dOD9FYX1uM"
      },
      "outputs": [],
      "source": [
        "# example items, could also be json instead of strings\n",
        "local_items = [\n",
        "    {\"input\": {\"country\": \"Italy\"}, \"expected_output\": \"Rome\"},\n",
        "    {\"input\": {\"country\": \"Spain\"}, \"expected_output\": \"Madrid\"},\n",
        "    {\"input\": {\"country\": \"Brazil\"}, \"expected_output\": \"Bras√≠lia\"},\n",
        "    {\"input\": {\"country\": \"Japan\"}, \"expected_output\": \"Tokyo\"},\n",
        "    {\"input\": {\"country\": \"India\"}, \"expected_output\": \"New Delhi\"},\n",
        "    {\"input\": {\"country\": \"Canada\"}, \"expected_output\": \"Ottawa\"},\n",
        "    {\"input\": {\"country\": \"South Korea\"}, \"expected_output\": \"Seoul\"},\n",
        "    {\"input\": {\"country\": \"Argentina\"}, \"expected_output\": \"Buenos Aires\"},\n",
        "    {\"input\": {\"country\": \"South Africa\"}, \"expected_output\": \"Pretoria\"},\n",
        "    {\"input\": {\"country\": \"Egypt\"}, \"expected_output\": \"Cairo\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwjfRIeYfEOQ"
      },
      "outputs": [],
      "source": [
        "# Upload to Langfuse\n",
        "for item in local_items:\n",
        "  langfuse.create_dataset_item(\n",
        "      dataset_name=\"capital_cities\",\n",
        "      # any python object or value\n",
        "      input=item[\"input\"],\n",
        "      # any python object or value, optional\n",
        "      expected_output=item[\"expected_output\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT15GYYOqJ2Q"
      },
      "source": [
        "## Define application and run experiments\n",
        "\n",
        "We implement the application in two ways to demonstrate how it's done\n",
        "\n",
        "1. Custom LLM app using e.g. OpenAI SDK, traced with Langfuse Python SDK\n",
        "2. Langchain Application, traced via native Langfuse integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE1VZlcEaDkQ"
      },
      "outputs": [],
      "source": [
        "# we use a very simple eval here, you can use any eval library\n",
        "# see https://langfuse.com/docs/scores/model-based-evals for details\n",
        "def simple_evaluation(output, expected_output):\n",
        "  return output == expected_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTTaYSkn3lOp"
      },
      "source": [
        "### Custom app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbhseVtjp1Br"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def run_my_custom_llm_app(input, system_prompt):\n",
        "  messages = [\n",
        "      {\"role\":\"system\", \"content\": system_prompt},\n",
        "      {\"role\":\"user\", \"content\": input[\"country\"]}\n",
        "  ]\n",
        "\n",
        "  generationStartTime = datetime.now()\n",
        "\n",
        "  openai_completion = openai.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=messages\n",
        "  ).choices[0].message.content\n",
        "\n",
        "  langfuse_generation = langfuse.generation(\n",
        "    name=\"guess-countries\",\n",
        "    input=messages,\n",
        "    output=openai_completion,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    start_time=generationStartTime,\n",
        "    end_time=datetime.now()\n",
        "  )\n",
        "\n",
        "  return openai_completion, langfuse_generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo-GmgwiuhcQ"
      },
      "outputs": [],
      "source": [
        "def run_experiment(experiment_name, system_prompt):\n",
        "  dataset = langfuse.get_dataset(\"capital_cities\")\n",
        "\n",
        "  for item in dataset.items:\n",
        "    completion, langfuse_generation = run_my_custom_llm_app(item.input, system_prompt)\n",
        "\n",
        "    item.link(langfuse_generation, experiment_name) # pass the observation/generation object or the id\n",
        "\n",
        "    langfuse_generation.score(\n",
        "      name=\"exact_match\",\n",
        "      value=simple_evaluation(completion, item.expected_output)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ede2UzNlxABq"
      },
      "outputs": [],
      "source": [
        "run_experiment(\n",
        "    \"famous_city\",\n",
        "    \"The user will input countries, respond with the most famous city in this country\"\n",
        ")\n",
        "run_experiment(\n",
        "    \"directly_ask\",\n",
        "    \"What is the capital of the following country?\"\n",
        ")\n",
        "run_experiment(\n",
        "    \"asking_specifically\",\n",
        "    \"The user will input countries, respond with only the name of the capital\"\n",
        ")\n",
        "run_experiment(\n",
        "    \"asking_specifically_2nd_try\",\n",
        "    \"The user will input countries, respond with only the name of the capital. State only the name of the city.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxHKNP7M36Z_"
      },
      "source": [
        "### Langchain application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZZEwFF732eU"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage\n",
        " \n",
        "def run_my_langchain_llm_app(input, system_message, callback_handler):\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            system_message,\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        "  )\n",
        "  chat = ChatOpenAI()\n",
        "  chain = prompt | chat\n",
        "\n",
        "  res = chain.invoke(\n",
        "    { \"messages\": [HumanMessage(content=input)] },\n",
        "    config={\"callbacks\":[callback_handler]}\n",
        "  )\n",
        "  \n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBW4VD536xPo"
      },
      "outputs": [],
      "source": [
        "def run_langchain_experiment(experiment_name, system_message):\n",
        "  dataset = langfuse.get_dataset(\"capital_cities\")\n",
        "\n",
        "  for item in dataset.items:\n",
        "    handler = item.get_langchain_handler(run_name=experiment_name)\n",
        "\n",
        "    completion = run_my_langchain_llm_app(item.input[\"country\"], system_message, handler)\n",
        "\n",
        "    handler.trace.score(\n",
        "      name=\"exact_match\",\n",
        "      value=simple_evaluation(completion, item.expected_output)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV0xas7o7Xuj"
      },
      "outputs": [],
      "source": [
        "run_langchain_experiment(\n",
        "    \"langchain_famous_city\",\n",
        "    \"The user will input countries, respond with the most famous city in this country\"\n",
        ")\n",
        "run_langchain_experiment(\n",
        "    \"langchain_directly_ask\",\n",
        "    \"What is the capital of the following country?\"\n",
        ")\n",
        "run_langchain_experiment(\n",
        "    \"langchain_asking_specifically\",\n",
        "    \"The user will input countries, respond with only the name of the capital\"\n",
        ")\n",
        "run_langchain_experiment(\n",
        "    \"langchain_asking_specifically_2nd_try\",\n",
        "    \"The user will input countries, respond with only the name of the capital. State only the name of the city.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmpVVSJ4X8hi"
      },
      "source": [
        "## Evaluate experiments in Langfuse UI\n",
        "\n",
        "- Average scores per experiment run\n",
        "- Browse each run for an individual item\n",
        "- Look at traces to debug issues\n",
        "\n",
        "![Experiment runs in Langfuse](https://langfuse.com/images/docs/dataset-runs-cookbook.jpg)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

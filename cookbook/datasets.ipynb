{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWEKl-UfX-ZS"
      },
      "source": [
        "---\n",
        "description: End-to-end example of creating a dataset, adding items, and running experiments with Langfuse datasets.\n",
        "category: Datasets\n",
        "---\n",
        "\n",
        "# Langfuse Datasets Cookbook\n",
        "\n",
        "In this cookbook, we'll iterate on systems prompts with the goal of getting only the capital of a given country. We use Langfuse datasets, to store a list of example inputs and expected outputs.\n",
        "\n",
        "This is a very simple example, you can run experiments on any LLM application that you either trace with the [Langfuse SDKs](https://langfuse.com/docs/sdk/overview) (Python, JS/TS) or via one of our [integrations](https://langfuse.com/integrations) (e.g. Langchain).\n",
        "\n",
        "_Simple example application_\n",
        "\n",
        "- **Model**: gpt-4o\n",
        "- **Input**: country name\n",
        "- **Output**: capital\n",
        "- **Evaluation**: exact match of completion and ground truth\n",
        "- **Experiment on**: system prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iexlvXyM2eFF"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PONlf847Xp-A"
      },
      "source": [
        "%pip install langfuse openai langchain_openai langchain --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAquPGo3X8hg"
      },
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
        "os.environ[\"LANGFUSE_BASE_URL\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
        "# os.environ[\"LANGFUSE_BASE_URL\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
        "\n",
        "# Your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the environment variables set, we can now initialize the Langfuse client. get_client() initializes the Langfuse client using the credentials provided in the environment variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kM5oWlyYitA"
      },
      "source": [
        "from langfuse import get_client\n",
        " \n",
        "langfuse = get_client()\n",
        " \n",
        "# Verify connection\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse client is authenticated and ready!\")\n",
        "else:\n",
        "    print(\"Authentication failed. Please check your credentials and host.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Langfuse client is authenticated and ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwVQW5ZmX7_4"
      },
      "source": [
        "## Create a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH6_snEmXukE"
      },
      "source": [
        "langfuse.create_dataset(name=\"capital_cities\");"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ArUZboetn3",
        "tags": []
      },
      "source": [
        "### Items\n",
        "\n",
        "Load local items into the Langfuse dataset. Alternatively you can add items from production via the Langfuse UI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9dOD9FYX1uM"
      },
      "source": [
        "# example items, could also be json instead of strings\n",
        "local_items = [\n",
        "    {\"input\": {\"country\": \"Italy\"}, \"expected_output\": \"Rome\"},\n",
        "    {\"input\": {\"country\": \"Spain\"}, \"expected_output\": \"Madrid\"},\n",
        "    {\"input\": {\"country\": \"Brazil\"}, \"expected_output\": \"BrasÃ­lia\"},\n",
        "    {\"input\": {\"country\": \"Japan\"}, \"expected_output\": \"Tokyo\"},\n",
        "    {\"input\": {\"country\": \"India\"}, \"expected_output\": \"New Delhi\"},\n",
        "    {\"input\": {\"country\": \"Canada\"}, \"expected_output\": \"Ottawa\"},\n",
        "    {\"input\": {\"country\": \"South Korea\"}, \"expected_output\": \"Seoul\"},\n",
        "    {\"input\": {\"country\": \"Argentina\"}, \"expected_output\": \"Buenos Aires\"},\n",
        "    {\"input\": {\"country\": \"South Africa\"}, \"expected_output\": \"Pretoria\"},\n",
        "    {\"input\": {\"country\": \"Egypt\"}, \"expected_output\": \"Cairo\"},\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwjfRIeYfEOQ"
      },
      "source": [
        "# Upload to Langfuse\n",
        "for item in local_items:\n",
        "  langfuse.create_dataset_item(\n",
        "      dataset_name=\"capital_cities\",\n",
        "      # any python object or value\n",
        "      input=item[\"input\"],\n",
        "      # any python object or value, optional\n",
        "      expected_output=item[\"expected_output\"]\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT15GYYOqJ2Q"
      },
      "source": [
        "## Example using Langfuse `@observe()` decorator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTTaYSkn3lOp"
      },
      "source": [
        "### Application\n",
        "\n",
        "This an example production application that we want to evaluate. It is instrumented with the Langfuse Decorator. We do not need to change the application code to evaluate it subsequently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from langfuse.openai import openai\n",
        "from langfuse import observe, get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "@observe()\n",
        "def run_my_custom_llm_app(input, system_prompt):\n",
        "    messages = [\n",
        "        {\"role\":\"system\", \"content\": system_prompt},\n",
        "        {\"role\":\"user\", \"content\": input[\"country\"]}\n",
        "    ]\n",
        "\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # Explicitly set trace input/output for evaluation features\n",
        "    langfuse.update_current_trace(\n",
        "        input=input,\n",
        "        output=completion\n",
        "    )\n",
        "\n",
        "    return completion"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment runner\n",
        "\n",
        "We use the experiment runner SDK to run our application against each item in the dataset and evaluate the output. The experiment runner handles concurrent execution and automatic tracing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE1VZlcEaDkQ"
      },
      "source": [
        "# We use Langfuse's Evaluation class to return evaluation results\n",
        "# see https://langfuse.com/docs/scores/model-based-evals for details\n",
        "# you can also use LLM-as-a-judge managed within Langfuse to evaluate the outputs\n",
        "\n",
        "from langfuse import Evaluation\n",
        "\n",
        "def exact_match_evaluator(*, output, expected_output, **kwargs):\n",
        "    \"\"\"Evaluator that checks if output exactly matches expected output\"\"\"\n",
        "    is_match = output == expected_output\n",
        "    return Evaluation(\n",
        "        name=\"exact_match\", \n",
        "        value=1.0 if is_match else 0.0,\n",
        "        comment=\"Exact match\" if is_match else f\"Expected '{expected_output}', got '{output}'\"\n",
        "    )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo-GmgwiuhcQ"
      },
      "source": [
        "def run_experiment(experiment_name, system_prompt):\n",
        "    \"\"\"Run experiment using the experiment runner SDK\"\"\"\n",
        "    dataset = langfuse.get_dataset(\"capital_cities\")\n",
        "    \n",
        "    # Define task function that will be called for each dataset item\n",
        "    def task(*, item, **kwargs):\n",
        "        \"\"\"Task function receives a DatasetItemClient object\"\"\"\n",
        "        output = run_my_custom_llm_app(item.input, system_prompt)\n",
        "        return output\n",
        "    \n",
        "    # Run experiment with automatic tracing and evaluation\n",
        "    result = dataset.run_experiment(\n",
        "        name=experiment_name,\n",
        "        task=task,\n",
        "        evaluators=[exact_match_evaluator]\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nFinished processing dataset 'capital_cities' for run '{experiment_name}'.\")\n",
        "    print(result.format())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run experiments\n",
        "\n",
        "Now we can easily run experiments with different configurations to explore which yields the best results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ede2UzNlxABq"
      },
      "source": [
        "from langfuse import get_client\n",
        "langfuse = get_client()\n",
        "\n",
        "run_experiment(\n",
        "    \"famous_city\",\n",
        "    \"The user will input countries, respond with the most famous city in this country\"\n",
        ")\n",
        "run_experiment(\n",
        "    \"directly_ask\",\n",
        "    \"What is the capital of the following country?\"\n",
        ")\n",
        "run_experiment(\n",
        "    \"asking_specifically\",\n",
        "    \"The user will input countries, respond with only the name of the capital\"\n",
        ")\n",
        "run_experiment(\n",
        "    \"asking_specifically_2nd_try\",\n",
        "    \"The user will input countries, respond with only the name of the capital. State only the name of the city.\"\n",
        ")\n",
        "\n",
        "# Flush to ensure all events were sent to the Langfuse API\n",
        "langfuse.flush()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished processing dataset 'capital_cities' for run 'famous_city'.\n",
            "\n",
            "Finished processing dataset 'capital_cities' for run 'directly_ask'.\n",
            "\n",
            "Finished processing dataset 'capital_cities' for run 'asking_specifically'.\n",
            "\n",
            "Finished processing dataset 'capital_cities' for run 'asking_specifically_2nd_try'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxHKNP7M36Z_"
      },
      "source": [
        "## Example using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZZEwFF732eU"
      },
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage\n",
        " \n",
        "def run_my_langchain_llm_app(input, system_message, callback_handler):\n",
        "\n",
        "  # Create a trace via Langfuse spans and use Langchain within it\n",
        "  with langfuse.start_as_current_observation(as_type=\"span\", name=\"my-langchain-agent\") as root_span:\n",
        "        \n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "      [(\"system\", system_message), MessagesPlaceholder(variable_name=\"messages\")]\n",
        "    )\n",
        "    chat = ChatOpenAI()\n",
        "    chain = prompt | chat\n",
        "\n",
        "    result = chain.invoke(\n",
        "      { \"messages\": [HumanMessage(content=input)] },\n",
        "      config={\"callbacks\":[callback_handler]}\n",
        "    )\n",
        "\n",
        "    # Update trace output\n",
        "    root_span.update_trace(\n",
        "        input=input,\n",
        "        output=result.content)\n",
        "\n",
        "  return result.content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBW4VD536xPo"
      },
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        "\n",
        "def run_langchain_experiment(experiment_name, system_prompt):\n",
        "    \"\"\"Run Langchain experiment using the experiment runner SDK\"\"\"\n",
        "    dataset = langfuse.get_dataset(\"capital_cities\")\n",
        "\n",
        "    # Initialize the Langfuse handler\n",
        "    langfuse_handler = CallbackHandler()\n",
        "    \n",
        "    # Define task function that will be called for each dataset item\n",
        "    def task(*, item, **kwargs):\n",
        "        \"\"\"Task function receives a DatasetItemClient object\"\"\"\n",
        "        output = run_my_langchain_llm_app(item.input[\"country\"], system_prompt, langfuse_handler)\n",
        "        return output\n",
        "    \n",
        "    # Run experiment with automatic tracing and evaluation\n",
        "    result = dataset.run_experiment(\n",
        "        name=experiment_name,\n",
        "        description=\"Langchain experiment run\",\n",
        "        task=task,\n",
        "        evaluators=[exact_match_evaluator],\n",
        "        metadata={\"model\": \"gpt-4o\"}\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nFinished processing dataset 'capital_cities' for run '{experiment_name}'.\")\n",
        "    print(result.format())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV0xas7o7Xuj"
      },
      "source": [
        "run_langchain_experiment(\n",
        "    \"langchain_famous_city\",\n",
        "    \"The user will input countries, respond with the most famous city in this country\"\n",
        ")\n",
        "run_langchain_experiment(\n",
        "    \"langchain_directly_ask\",\n",
        "    \"What is the capital of the following country?\"\n",
        ")\n",
        "run_langchain_experiment(\n",
        "    \"langchain_asking_specifically\",\n",
        "    \"The user will input countries, respond with only the name of the capital\"\n",
        ")\n",
        "run_langchain_experiment(\n",
        "    \"langchain_asking_specifically_2nd_try\",\n",
        "    \"The user will input countries, respond with only the name of the capital. State only the name of the city.\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmpVVSJ4X8hi"
      },
      "source": [
        "## More Examples\n",
        "\n",
        "- [LangGraph Dataset Experiment](https://langfuse.com/guides/cookbook/example_langgraph_agents#offline-evaluation)\n",
        "- [OpenAI Agents SDK Dataset Experiment](https://langfuse.com/guides/cookbook/example_evaluating_openai_agents#dataset-evaluation)\n",
        "- [CrewAI Dataset Experiment](https://langfuse.com/integrations/frameworks/crewai#dataset-experiments)\n",
        "- [Smolagents Dataset Experiment](https://huggingface.co/learn/agents-course/en/bonus-unit2/monitoring-and-evaluating-agents-notebook#offline-evaluation)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
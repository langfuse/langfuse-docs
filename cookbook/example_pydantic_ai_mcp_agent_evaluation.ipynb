{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb39bc06",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Example - Pydantic AI MCP Agent Evaluation\" description: \"This guide shows how to evaluate Pydantic AI MCP Agents with Langfuse using online and offline evaluation methods.\" category: \"Evaluation\" -->\n",
    "\n",
    "# LangfuseÂ Ã—Â PydanticÂ AI â€“ Agent Evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72216ec6",
   "metadata": {},
   "source": [
    "## 1.Â Setup â€“ install packages & add credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea433d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: pydantic-ai 1.11.0 does not provide the extra 'mcp'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.0.1 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If you are running this on colab/@home commentâ€‘out what you already have\n",
    "%pip install -q --upgrade \"pydantic-ai[mcp]\" langfuse openai nest_asyncio aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb291415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-...\" \n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ğŸ‡ªğŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ğŸ‡ºğŸ‡¸ US region\n",
    "\n",
    "# Your openai key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fbb9b",
   "metadata": {},
   "source": [
    "## 2. Enable Langfuse Tracing\n",
    "\n",
    "All integrations: https://langfuse.com/integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eddfdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pydantic AI instrumentation enabled - traces will stream to Langfuse\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    "from pydantic_ai.agent import Agent\n",
    "\n",
    "# Initialise Langfuse client and verify connectivity\n",
    "langfuse = get_client()\n",
    "assert langfuse.auth_check(), \"Langfuse auth failed - check your keys âœ‹\"\n",
    "\n",
    "# Turn on OpenTelemetry instrumentation for *all* future Agent instances\n",
    "Agent.instrument_all()\n",
    "print(\"âœ… Pydantic AI instrumentation enabled - traces will stream to Langfuse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45848d67",
   "metadata": {},
   "source": [
    "## 3. Create an agent that can search the Langfuse docs\n",
    "\n",
    "We use the Lagfuse Docs MCP Server to provide tools to the agent: https://langfuse.com/docs/docs-mcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e718f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.mcp import MCPServerStreamableHTTP, CallToolFunc, ToolResult\n",
    "from typing import Any\n",
    "\n",
    "# Public MCP server that exposes Langfuse docs tools\n",
    "LANGFUSE_MCP_URL = \"https://langfuse.com/api/mcp\"\n",
    "\n",
    "async def run_agent(item, system_prompt=\"You are an expert on Langfuse. \", model=\"openai:o3-mini\"):\n",
    "    langfuse.update_current_trace(input=item.input)\n",
    "\n",
    "    tool_call_history = []\n",
    "\n",
    "    # Log all tool calls for trajectory analysis\n",
    "    async def process_tool_call(\n",
    "        ctx: RunContext[int],\n",
    "        call_tool: CallToolFunc,\n",
    "        tool_name: str,\n",
    "        args: dict[str, Any],\n",
    "    ) -> ToolResult:\n",
    "        \"\"\"A tool call processor that passes along the deps.\"\"\"\n",
    "        print(f\"MCP Tool call: {tool_name} with args: {args}\")\n",
    "        tool_call_history.append({\n",
    "            \"tool_name\": tool_name,\n",
    "            \"args\": args\n",
    "        })\n",
    "        return await call_tool(tool_name, args)\n",
    "    \n",
    "    langfuse_docs_server = MCPServerStreamableHTTP(\n",
    "        LANGFUSE_MCP_URL,\n",
    "        process_tool_call=process_tool_call\n",
    "    )\n",
    "\n",
    "    agent = Agent(\n",
    "        model=model,\n",
    "        mcp_servers=[langfuse_docs_server],\n",
    "        system_prompt=system_prompt\n",
    "    )\n",
    "\n",
    "    async with agent.run_mcp_servers():\n",
    "        print(\"\\n---\")\n",
    "        print(\"Q:\", item.input)\n",
    "        result = await agent.run(item.input[\"question\"])\n",
    "        print(\"A:\", result.output)\n",
    "\n",
    "        langfuse.update_current_trace(\n",
    "            output=result.output,\n",
    "            metadata={\"tool_call_history\": tool_call_history\n",
    "        })\n",
    "\n",
    "        return result.output, tool_call_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2edbef7",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "1. Create Test Cases\n",
    "    - input\n",
    "    - reference for reference-based evaluations\n",
    "2. Set up evaluators\n",
    "3. Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35017511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_cases = [\n",
    "    {\n",
    "        \"input\": {\"question\": \"What is Langfuse?\"},\n",
    "        \"expected_output\": {\n",
    "            \"response_facts\": [\n",
    "                \"Open Source LLM Engineering Platform\",\n",
    "                \"Product modules: Tracing, Evaluation and Prompt Management\"\n",
    "            ],\n",
    "            \"trajectory\": [\n",
    "                \"getLangfuseOverview\"\n",
    "            ],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\n",
    "            \"question\": \"How to trace a python application with Langfuse?\"\n",
    "        },\n",
    "        \"expected_output\": {\n",
    "            \"response_facts\": [\n",
    "                \"Python SDK, you can use the observe() decorator\",\n",
    "                \"Lots of integrations, LangChain, LlamaIndex, Pydantic AI, and many more.\"\n",
    "            ],\n",
    "            \"trajectory\": [\n",
    "                \"getLangfuseOverview\",\n",
    "                \"searchLangfuseDocs\"\n",
    "            ],\n",
    "            \"search_term\": \"Python Tracing\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\"question\": \"How to connect to the Langfuse Docs MCP server?\"},\n",
    "        \"expected_output\": {\n",
    "            \"response_facts\": [\n",
    "                \"Connect via the MCP server endpoint: https://langfuse.com/api/mcp\",\n",
    "                \"Transport protocol: `streamableHttp`\"\n",
    "            ],\n",
    "            \"trajectory\": [\"getLangfuseOverview\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\n",
    "            \"question\": \"How long are traces retained in langfuse?\",\n",
    "        },\n",
    "        \"expected_output\": {\n",
    "            \"response_facts\": [\n",
    "                \"By default, traces are retained indefinetly\",\n",
    "                \"You can set custom data retention policy in the project settings\"\n",
    "            ],\n",
    "            \"trajectory\": [\"getLangfuseOverview\", \"searchLangfuseDocs\"],\n",
    "            \"search_term\": \"Data retention\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50656c",
   "metadata": {},
   "source": [
    "Upload to Langfuse datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa55584",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATSET_NAME = \"pydantic-ai-mcp-agent-evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = langfuse.create_dataset(\n",
    "    name=DATSET_NAME\n",
    ")\n",
    "for case in tests_cases:\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=DATSET_NAME,\n",
    "        input=case[\"input\"],\n",
    "        expected_output=case[\"expected_output\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f59ea5",
   "metadata": {},
   "source": [
    "### Set up Evaluations in Langfuse\n",
    "\n",
    "#### Final response evaluation\n",
    "\n",
    "```md\n",
    "You are a teacher grading a student based on the factual correctness of his statements. In the following please find some example gradings that you did in the past.\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### **Example 1:**\n",
    "- **Response:** \"The sun is shining brightly.\"\n",
    "- **Facts to verify:** [\"The sun is up.\", \"It is a beautiful day.\"]\n",
    "\n",
    "Grading\n",
    "- Reasoning: The response accurately includes both facts and aligns with the context of a beautiful day.\n",
    "- Score: 1\n",
    "\n",
    "#### **Example 2:**\n",
    "- **Response:** \"When I was in the kitchen, the dog was there\"\n",
    "- **Facts to verify:** [\"The cat is on the table.\", \"The dog is in the kitchen.\"]\n",
    "\n",
    "Grading\n",
    "- Reasoning: The response includes that the dog is in the kitchen but does not mention that the cat is on the table.\n",
    "- Score: 0\n",
    "\n",
    "### New Student Response\n",
    "\n",
    "- **Response**: {{response}}\n",
    "- **Facts to verify:** {{facts_to_verify}}\n",
    "```\n",
    "\n",
    "#### Trajectory\n",
    "\n",
    "```md\n",
    "You are comparing two lists of strings. Please check whether the lists contain exactly the same items. The order does not matter.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Input\n",
    "Expected: [\"searchWeb\", \"visitWebsite\"]\n",
    "Output: [\"searchWeb\"]\n",
    "\n",
    "Grading\n",
    "Reasoning: [\"searchWeb\", \"visitWebsite\"] are expected. In the output, \"visitWebsite\" is missing. Thus the two arrays are not the same.\n",
    "Score: 0\n",
    "\n",
    "Input\n",
    "Expected: [\"drawImage\", \"visitWebsite\", \"speak\"]\n",
    "Output: [\"visitWebsite\", \"speak\", \"drawImage\"]\n",
    "\n",
    "Grading\n",
    "Reasoning: The output matches the items from the expected output.\n",
    "Score: 1\n",
    "\n",
    "Input\n",
    "Expected: [\"getNews\"]\n",
    "Output: [\"getNews\", \"watchTv\"]\n",
    "\n",
    "Grading\n",
    "Reasoning: The output contains \"watchTv\" which was not expected.\n",
    "Score: 0\n",
    "\n",
    "## This excercise\n",
    "\n",
    "Expected: {{expected}}\n",
    "Output: {{output}}\n",
    "```\n",
    "\n",
    "#### Search quality\n",
    "\n",
    "```md\n",
    "You are a teacher grading a student based on whether he has looked for the right information in order to answe a question. In the following please find some example gradings that you did in the past.\n",
    "\n",
    "The search by the student does not need to exactly match the response you expected; searches are often brief. The search term should correspond vaguely with the expected search term.\n",
    "\n",
    "### Examples\n",
    "#### **Example 1:**\n",
    "- **Response:** How can I contact support?\n",
    "- **Expected search topics**: Support\n",
    "\n",
    "Grading\n",
    "- Reasoning: The response accurately searches for support.\n",
    "- Score: 1\n",
    "\n",
    "#### **Example 2:**\n",
    "- **Response:** Deployment\n",
    "- **Expected search topics:** Tracing\n",
    "\n",
    "Grading\n",
    "- Reasoning: The response does not match the expected search topic of Tracing. Deployment questions are unrelated.\n",
    "- Score: 0\n",
    "\n",
    "#### **Example 3:**\n",
    "- **Response:**\n",
    "- **Expected search topics:**\n",
    "\n",
    "Grading\n",
    "- Reasoning: No search was done and no search term was expected.\n",
    "- Score: 1\n",
    "\n",
    "#### **Example 4:**\n",
    "- **Response:** How to view sessions?\n",
    "- **Expected search topics:**\n",
    "\n",
    "Grading\n",
    "- Reasoning: No search was expected, but search was used. This is not a problem.\n",
    "- Score: 1\n",
    "\n",
    "#### **Example 5:**\n",
    "- **Response:**\n",
    "- **Expected search topics:** How to run Langfuse locally?\n",
    "\n",
    "Grading\n",
    "- Reasoning: Even though we expected a search regarding running Langfuse locally, no search was made.\n",
    "- Score: 0\n",
    "\n",
    "### New Student Response\n",
    "\n",
    "- **Response:** {{search}}\n",
    "- **Expected search topics:** {{expected_search_topic}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb8b36",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dabea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompts = {\n",
    "    \"simple\": (\n",
    "        \"You are an expert on Langfuse. \"\n",
    "        \"Answer user questions accurately and concisely using the available MCP tools. \"\n",
    "        \"Cite sources when appropriate.\"\n",
    "    ),\n",
    "    \"nudge_search_and_sources\": (\n",
    "        \"You are an expert on Langfuse. \"\n",
    "        \"Answer user questions accurately and concisely using the available MCP tools. \"\n",
    "        \"Always cite sources when appropriate.\"\n",
    "        \"When you are unsure, always use getLangfuseOverview tool to do some research and then search the docs for more information. You can if needed use these tools multiple times.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "models = [\n",
    "    \"openai:gpt-5-nano\",\n",
    "    \"openai:gpt-5-mini\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922f010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset from Langfuse\n",
    "dataset = langfuse.get_dataset(DATSET_NAME)\n",
    "\n",
    "# Run experiment directly on the dataset\n",
    "result = dataset.run_experiment(\n",
    "    name=\"Production Model Test\"\n",
    "    description=\"Monthly evaluation of our production model\",\n",
    "    task=run_agent # see above for the task definition\n",
    ")\n",
    "\n",
    "# Use format method to display results\n",
    "print(result.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c40766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Q: {'question': 'How long are traces retained in langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How to connect to the Langfuse Docs MCP server?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How to trace a python application with Langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'What is Langfuse?'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'trace a Python application with Langfuse'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'trace retention period in Langfuse'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'What is Langfuse?'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'Connecting to the Langfuse MCP server'}\n",
      "A: In Langfuse, traces are retained for a configurable period specified at the project level, with a minimum retention period of 3 days. By default, data retention is set to indefinite storage unless explicitly configured otherwise. The retention policy applies to traces, observations, scores, and media assets and is managed through project settings or API for non-zero values. You can find more details on data retention policies in the [Langfuse Data Retention documentation](https://langfuse.com/docs/administration/data-retention).\n",
      "A: To connect to the Langfuse MCP server, you should use the endpoint: `https://langfuse.com/api/mcp`. The communication transport is `streamableHttp`, which is supported by most clients. \n",
      "\n",
      "You can add the MCP server configuration in your client (e.g., in your settings JSON or via CLI). For example, the JSON configuration looks like this:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"mcpServers\": {\n",
      "    \"langfuse-docs\": {\n",
      "      \"url\": \"https://langfuse.com/api/mcp\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Depending on the client you're using, refer to the specific instructions on how to add this server. For instance, in VSCode, you can add it via Command Palette, or manually add it to your `mcp.json`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Item 2 failed: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "Item 3 failed: unhandled errors in a TaskGroup (1 sub-exception)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Results: Hidden (2 items)\\nğŸ’¡ Set include_item_results=True to view them\\n\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ§ª Experiment: Production Model Test: simple openai:gpt-4.1-nano\n",
      "ğŸ“‹ Run name: Production Model Test: simple openai:gpt-4.1-nano - 2025-11-05T10:44:50.974380Z - Monthly evaluation of our production model\\n2 items\\nğŸ”— Dataset Run:\\n   https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/datasets/cmhlmusje003fad07bzz4bhim/runs/86101eb4-b41e-4666-9bc9-8045de24c241\n",
      "\n",
      "---\n",
      "Q: {'question': 'How to connect to the Langfuse Docs MCP server?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'What is Langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How long are traces retained in langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How to trace a python application with Langfuse?'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'What is Langfuse? Langfuse overview'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'trace a python application with Langfuse'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'trace retention langfuse traces retained how long'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'connect to MCP server Langfuse docs connect to MCP server'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'MCP server'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'trace python application Langfuse Python SDK overview get_client observe context'}\n",
      "A: By default Langfuse keeps all traces (and related events) indefinitely. However, you can enable the Data Retention feature on a per-project basis to automatically purge old data:\n",
      "\n",
      "â€¢ Retention period is configurable in the Project Settings (or via the Projects API)  \n",
      "â€¢ You must specify a number of days (minimum 3 days)  \n",
      "â€¢ A nightly job will delete any traces (and observations, scores, media) older than your retention window  \n",
      "â€¢ Deleted data cannot be recovered  \n",
      "\n",
      "Source: Langfuse Data Retention docs (https://langfuse.com/docs/administration/data-retention)\n",
      "MCP Tool call: getLangfuseDocsPage with args: {'pathOrUrl': '/docs/observability/sdk/python/overview'}\n",
      "A: To trace your Python application with Langfuse, youâ€™ll generally follow three steps:\n",
      "\n",
      "1. Install & configure the SDK  \n",
      "2. Instrument your code  \n",
      "3. View your traces in the Langfuse UI  \n",
      "\n",
      "Below are the details.\n",
      "\n",
      "â€“â€“â€“  \n",
      "1) Install & configure  \n",
      "â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“  \n",
      "\n",
      "â€¢ Install the Langfuse Python SDK (v3) and, if youâ€™re using OpenAI, the OpenAI SDK:  \n",
      "```bash\n",
      "pip install langfuse openai\n",
      "```  \n",
      "â€¢ Set your Langfuse credentials (and region) as environment variables:  \n",
      "```bash\n",
      "export LANGFUSE_PUBLIC_KEY=\"pk-lf-â€¦\"\n",
      "export LANGFUSE_SECRET_KEY=\"sk-lf-â€¦\"\n",
      "export LANGFUSE_BASE_URL=\"https://cloud.langfuse.com\"   # or https://us.cloud.langfuse.com\n",
      "```  \n",
      "â€¢ (Optional) Verify connectivity:  \n",
      "```python\n",
      "from langfuse import get_client\n",
      "client = get_client()\n",
      "assert client.auth_check()\n",
      "```  \n",
      "Source: â€œObservability for OpenAI SDK (Python)â€ integration guide.  \n",
      "\n",
      "â€“â€“â€“  \n",
      "2) Instrument your code  \n",
      "â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“  \n",
      "\n",
      "You have three choicesâ€”pick one or mix and match:\n",
      "\n",
      "A) OpenAI-SDK Drop-in Replacement  \n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”  \n",
      "If youâ€™re already using the OpenAI Python SDK for calls, you get full tracing by changing only your import:  \n",
      "```diff\n",
      "- import openai\n",
      "+ from langfuse.openai import openai\n",
      "```\n",
      "Everything else (chat.completions.create, streaming, async, functions) works unchanged and is automatically tracked (prompts, usage, latencies, errors).  \n",
      "Remember to flush in short-lived apps:  \n",
      "```python\n",
      "from langfuse import get_client\n",
      "get_client().flush()\n",
      "```  \n",
      "Source: â€œObservability for OpenAI SDK (Python)â€  \n",
      "\n",
      "B) Python-SDK v3 Instrumentation  \n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”  \n",
      "If you want to trace arbitrary code (database calls, your own logic, custom functions), use the new OpenTelemetry-based Python SDK v3:\n",
      "\n",
      "â€¢ Observe decorator (simplest):  \n",
      "```python\n",
      "from langfuse import observe, get_client\n",
      "\n",
      "@observe()\n",
      "def process_data(x):\n",
      "    # This function becomes a span; inputs, outputs, timings are captured\n",
      "    return x * 2\n",
      "\n",
      "process_data(21)\n",
      "get_client().flush()\n",
      "```\n",
      "\n",
      "â€¢ Context managers (more control / nesting):  \n",
      "```python\n",
      "from langfuse import get_client\n",
      "\n",
      "client = get_client()\n",
      "with client.start_as_current_span(name=\"user-request\") as span:\n",
      "    span.update_trace(user_id=\"alice\", input={\"q\":\"hello\"})\n",
      "    # do work...\n",
      "    span.update(output={\"result\":42})\n",
      "get_client().flush()\n",
      "```\n",
      "\n",
      "â€¢ Manual spans (full control, but you must call .end()):  \n",
      "```python\n",
      "span = client.start_span(name=\"background-task\")\n",
      "# â€¦ work â€¦\n",
      "span.end()\n",
      "client.flush()\n",
      "```  \n",
      "Source: â€œOverview of the Python SDK v3â€ and â€œInstrumentationâ€ docs.  \n",
      "\n",
      "C) Framework-specific integrations  \n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”  \n",
      "Langfuse also ships wrappers/handlers for popular LLM frameworks:\n",
      "\n",
      "â€¢ LangChain: use `langfuse.langchain.CallbackHandler` as a callback  \n",
      "â€¢ LlamaIndex: via community OTEL instrumentors  \n",
      "â€¢ Anthropic: via OpenTelemetryâ€™s `AnthropicInstrumentor()`  \n",
      "\n",
      "See the â€œTrace Anthropic Modelsâ€ and â€œIntegrate Langfuse with AutoGenâ€ guides for examples.  \n",
      "\n",
      "â€“â€“â€“  \n",
      "3) View your traces  \n",
      "â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“  \n",
      "\n",
      "After youâ€™ve run your instrumented application, go to your Langfuse projectâ€™s â€œTracesâ€ page. Youâ€™ll see each root trace (e.g., a user request) and nested observations/spans for your function calls, LLM generations, external API calls, etc. You can filter by trace ID, user ID, tags, or evaluate them with custom scores.  \n",
      "\n",
      "Thatâ€™s it! You now have end-to-end observability of your Python LLM application with Langfuse.  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Item 1 failed: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "Item 3 failed: unhandled errors in a TaskGroup (1 sub-exception)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Results: Hidden (2 items)\\nğŸ’¡ Set include_item_results=True to view them\\n\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ§ª Experiment: Production Model Test: simple openai:o4-mini\n",
      "ğŸ“‹ Run name: Production Model Test: simple openai:o4-mini - 2025-11-05T10:49:52.742937Z - Monthly evaluation of our production model\\n2 items\\nğŸ”— Dataset Run:\\n   https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/datasets/cmhlmusje003fad07bzz4bhim/runs/b97f1ae5-d7fa-4186-93b9-d340f6e78ba1\n",
      "\n",
      "---\n",
      "Q: {'question': 'How long are traces retained in langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'What is Langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How to trace a python application with Langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How to connect to the Langfuse Docs MCP server?'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'trace retention period in langfuse'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'What is Langfuse?'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'trace a Python application with Langfuse'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'How to connect to the Langfuse Docs MCP server'}\n",
      "A: The search didn't return specific instructions on connecting to the Langfuse MCP (Managed Collection Protocol) server. \n",
      "\n",
      "To connect to the Langfuse server, you typically need to set up your client environment with the appropriate API endpoints and credentials, depending on whether you're self-hosting or using their cloud service. \n",
      "\n",
      "For detailed instructions, including configuration and connection steps, I recommend reviewing the official API documentation: [https://api.reference.langfuse.com](https://api.reference.langfuse.com). If you're self-hosting, ensure your server is running and accessible, and use the API base URL configured during setup.\n",
      "\n",
      "Would you like guidance on specific connection steps for your environment?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Item 0 failed: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "Item 2 failed: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "Item 3 failed: unhandled errors in a TaskGroup (1 sub-exception)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Results: Hidden (1 items)\\nğŸ’¡ Set include_item_results=True to view them\\n\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ§ª Experiment: Production Model Test: nudge_search_and_sources openai:gpt-4.1-nano\n",
      "ğŸ“‹ Run name: Production Model Test: nudge_search_and_sources openai:gpt-4.1-nano - 2025-11-05T10:55:03.366739Z - Monthly evaluation of our production model\\n1 items\\nğŸ”— Dataset Run:\\n   https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/datasets/cmhlmusje003fad07bzz4bhim/runs/0d13d393-1ba4-4fa3-a109-78b28de59b52\n",
      "\n",
      "---\n",
      "Q: {'question': 'What is Langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How long are traces retained in langfuse?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How to connect to the Langfuse Docs MCP server?'}\n",
      "\n",
      "---\n",
      "Q: {'question': 'How to trace a python application with Langfuse?'}\n",
      "MCP Tool call: getLangfuseOverview with args: {}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'traces retention length in langfuse traces retained'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'Langfuse python tracing application instrumentation example'}\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'connect MCP server Langfuse Docs'}\n",
      "A: Langfuse is an open-source LLM-engineering platform that helps teams collaboratively debug, analyze, and iterate on their large-language-model applications. It provides end-to-end toolsâ€”observability (trace-level logging, cost & token tracking, metadata, sessions), prompt management (versioning, A/B testing, caching), evaluation (annotation, LLM-as-judge, custom metrics), and a unified API & data-platformâ€”to accelerate development and ensure reliability.  \n",
      "Source: Langfuse overview (via getLangfuseOverview)\n",
      "MCP Tool call: searchLangfuseDocs with args: {'query': 'MCP server Langfuse Docs MCP'}\n",
      "MCP Tool call: getLangfuseDocsPage with args: {'pathOrUrl': '/docs/docs-mcp'}\n",
      "A: To connect your AI-coding agent to the Langfuse Docs MCP server, point it at:\n",
      "\n",
      "  â€¢ Endpoint: https://langfuse.com/api/mcp  \n",
      "  â€¢ Transport: streamableHttp  \n",
      "\n",
      "Below are the quick steps for popular clients:\n",
      "\n",
      "1. Cursor (one-click)  \n",
      "   â€“ Visit:  \n",
      "     https://cursor.com/en/install-mcp?name=langfuse-docs&config=eyJ1cmwiOiJodHRwczovL2xhbmdmdXNlLmNvbS9hcGkvbWNwIn0%3D  \n",
      "   â€“ Or add to your mcp.json:  \n",
      "     {  \n",
      "       \"mcpServers\": {  \n",
      "         \"langfuse-docs\": { \"url\":\"https://langfuse.com/api/mcp\" }  \n",
      "       }  \n",
      "     }  \n",
      "   (see source)[1]\n",
      "\n",
      "2. GitHub Copilot (VS Code)  \n",
      "   â€“ âŒ˜+Shift+P â†’ â€œMCP: Add Serverâ€¦â€ â†’ HTTP â†’ URL=https://langfuse.com/api/mcp â†’ give it a name â†’ save  \n",
      "   (see source)[1]\n",
      "\n",
      "3. Claude Code  \n",
      "   â€“ CLI:  \n",
      "     claude mcp add   \n",
      "       --transport http   \n",
      "       langfuse-docs   \n",
      "       https://langfuse.com/api/mcp   \n",
      "       --scope user  \n",
      "   â€“ Or edit ~/.claude/settings.json:  \n",
      "     {  \n",
      "       \"mcpServers\": {  \n",
      "         \"langfuse-docs\": {  \n",
      "           \"transportType\":\"http\",  \n",
      "           \"url\":\"https://langfuse.com/api/mcp\",  \n",
      "           \"verifySsl\":true  \n",
      "         }  \n",
      "       }  \n",
      "     }  \n",
      "   (see source)[1]\n",
      "\n",
      "4. Windsurf  \n",
      "   â€“ âŒ˜+Shift+P â†’ â€œMCP Configuration Panelâ€ â†’ â€œAdd custom serverâ€ â†’ paste:  \n",
      "     {  \n",
      "       \"mcpServers\": {  \n",
      "         \"langfuse-docs\": {  \n",
      "           \"command\":\"npx\",  \n",
      "           \"args\":[\"mcp-remote\",\"https://langfuse.com/api/mcp\"]  \n",
      "         }  \n",
      "       }  \n",
      "     }  \n",
      "   or, if your client supports HTTP transport, just use the URL directly.  \n",
      "   (see source)[1]\n",
      "\n",
      "5. Other MCP clients  \n",
      "   â€“ Add to your clientâ€™s mcp.json or equivalent:  \n",
      "     {  \n",
      "       \"mcpServers\": {  \n",
      "         \"langfuse-docs\": { \"url\":\"https://langfuse.com/api/mcp\" }  \n",
      "       }  \n",
      "     }  \n",
      "\n",
      "Once configured, your agent can call the MCP search and pageâ€“fetch tools under the hood to pull docs, code snippets, and examples straight from Langfuseâ€™s live documentation.  \n",
      "\n",
      "References:  \n",
      "[1] Langfuse Docs MCP Server: https://langfuse.com/docs/docs-mcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Item 0 failed: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "Item 2 failed: unhandled errors in a TaskGroup (1 sub-exception)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Results: Hidden (2 items)\\nğŸ’¡ Set include_item_results=True to view them\\n\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ§ª Experiment: Production Model Test: nudge_search_and_sources openai:o4-mini\n",
      "ğŸ“‹ Run name: Production Model Test: nudge_search_and_sources openai:o4-mini - 2025-11-05T11:00:05.606758Z - Monthly evaluation of our production model\\n2 items\\nğŸ”— Dataset Run:\\n   https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/datasets/cmhlmusje003fad07bzz4bhim/runs/235549d8-d116-4532-ae29-2f030cebc4cf\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Get dataset from Langfuse\n",
    "dataset = langfuse.get_dataset(\"pydantic-ai-mcp-agent-evaluation\")\n",
    "\n",
    "\n",
    "for prompt_name, prompt_content in list(system_prompts.items()):\n",
    "    for test_model in models:\n",
    "\n",
    "        task = partial(\n",
    "            run_agent,\n",
    "            system_prompt=prompt_content,\n",
    "            model=test_model,\n",
    "        )\n",
    "\n",
    "        # Run experiment directly on the dataset\n",
    "        result = dataset.run_experiment(\n",
    "            name=\"Production Model Test: \" + prompt_name + \" \" + test_model,\n",
    "            description=\"Monthly evaluation of our production model\",\n",
    "            task=task # see above for the task definition\n",
    "        )\n",
    "\n",
    "        # Use format method to display results\n",
    "        print(result.format())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

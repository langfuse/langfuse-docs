{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_acndviOrOXi"
      },
      "source": [
        "---\n",
        "title: Query Data in Langfuse via the SDK\n",
        "description: All data in Langfuse is available via API. This Python notebook includes a number of examples of how to use the Langfuse SDK to query data.\n",
        "category: Examples\n",
        "---\n",
        "\n",
        "# Example: Query Data in Langfuse via the SDK\n",
        "\n",
        "This notebook demonstrates how to programmatically access your LLM observability data from Langfuse using the Python SDK. As outlined in our [documentation](https://langfuse.com/docs/query-traces), Langfuse provides several methods to fetch traces, observations, and sessions for various use cases like collecting few-shot examples, creating datasets, or preparing training data for fine-tuning.\n",
        "\n",
        "We'll explore the main query functions and show practical examples of filtering and processing the returned data.\n",
        "\n",
        "**This notebook is work-in-progress, feel free to contribute additional examples that you find useful.**\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDQgzAOnr5q8"
      },
      "outputs": [],
      "source": [
        "!pip install langfuse --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PHtGGXC8rN4B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
        "\n",
        "# Your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8z776XxDr4m0"
      },
      "outputs": [],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GX4fhu2Zwl7d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# helper function\n",
        "def pydantic_list_to_dataframe(pydantic_list):\n",
        "    \"\"\"\n",
        "    Convert a list of pydantic objects to a pandas dataframe.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for item in pydantic_list:\n",
        "        data.append(item.dict())\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m-JB4xssPhh"
      },
      "source": [
        "## Fetch Multiple Traces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6vg-2UV3pvO"
      },
      "source": [
        "Default: get the last 50 traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "Nq4_mDSVsPCL",
        "outputId": "58eaa4e0-9ac7-4b48-f3f5-9b26ee99f1fc"
      },
      "outputs": [],
      "source": [
        "traces = langfuse.api.trace.list(limit=50)\n",
        "# pydantic_list_to_dataframe(traces.data).head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK3hvMev3mpR"
      },
      "source": [
        "Get traces created by a specific user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "3d-oWa6Qx9yU",
        "outputId": "8856c1f7-f1df-450e-970e-54fd30b33680"
      },
      "outputs": [],
      "source": [
        "traces = langfuse.api.trace.list(user_id=\"u-svQKrql\")\n",
        "# pydantic_list_to_dataframe(traces.data).head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekHYSYP03h8Y"
      },
      "source": [
        "Fetch many traces via pagination:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5blf8PB1r1n",
        "outputId": "9c19a28b-e5cd-4943-cb5c-c807c26e27c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 1000 traces.\n"
          ]
        }
      ],
      "source": [
        "all_traces = []\n",
        "limit = 50  # Adjust as needed to balance performance and data retrieval.\n",
        "page = 1\n",
        "while True:\n",
        "    traces = langfuse.api.trace.list(limit=limit, page=page)\n",
        "    all_traces.extend(traces.data)\n",
        "    if len(traces.data) < limit or len(all_traces) >= 1000:\n",
        "        break\n",
        "    page += 1\n",
        "\n",
        "print(f\"Retrieved {len(all_traces)} traces.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icxMC8-jx84D"
      },
      "source": [
        "## Fetch Single Trace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIsUnpFq4X9S"
      },
      "source": [
        "Simple example: fetch and render as json -> get the full traces including evals, observation inputs/outputs, timings and costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH4-MbUFwtYY",
        "outputId": "77626204-50a8-4d26-8b96-251a0f76959d"
      },
      "outputs": [],
      "source": [
        "trace = langfuse.api.trace.get(\"9a6071d27444a0f5d7cc431ecdd72e70\")\n",
        "# print(trace.json(indent=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy-tJ85X48XY"
      },
      "source": [
        "Summarize cost by model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ov8X9MZv4ewU"
      },
      "outputs": [],
      "source": [
        "trace = langfuse.api.trace.get(\"9a6071d27444a0f5d7cc431ecdd72e70\")\n",
        "observations = trace.observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ItvrU7f15B-f",
        "outputId": "9a905682-d9ea-496e-b56d-8d765190a691"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gpt-4o-2024-08-06</th>\n",
              "      <td>31</td>\n",
              "      <td>100</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   input  output  total\n",
              "model                                  \n",
              "gpt-4o-2024-08-06     31     100    131"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def summarize_usage(observations):\n",
        "    \"\"\"Summarizes usage data grouped by model.\"\"\"\n",
        "\n",
        "    usage_data = []\n",
        "    for obs in observations:\n",
        "        usage = obs.usage\n",
        "        if usage:\n",
        "            usage_data.append({\n",
        "                'model': obs.model,\n",
        "                'input': usage.input,\n",
        "                'output': usage.output,\n",
        "                'total': usage.total,\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(usage_data)\n",
        "    if df.empty:\n",
        "      return pd.DataFrame()\n",
        "\n",
        "    summary = df.groupby('model').sum()\n",
        "    return summary\n",
        "\n",
        "# Example usage (assuming 'observations' is defined as in the provided code):\n",
        "summary_df = summarize_usage(observations)\n",
        "summary_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISpZeONm6w1F"
      },
      "source": [
        "## Fetch Multiple Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUKW1qnX7S2A"
      },
      "source": [
        "Simple example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "K9osjsU55ZoR",
        "outputId": "a01b3496-be21-4ebd-e0dc-1c7892c42132"
      },
      "outputs": [],
      "source": [
        "observations = langfuse.api.observations.get_many(limit=50)\n",
        "# pydantic_list_to_dataframe(observations.data).head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObservationsViews(data=[ObservationsView(id='a90e84da299a0231', trace_id='e1e6a3c770b793d3605360fe3d42581a', type='GENERATION', name='OpenAI-generation', start_time=datetime.datetime(2025, 6, 12, 16, 35, 45, 184000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 35, 49, 212000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='gpt-4o-mini-2024-07-18', model_parameters={'temperature': 1, 'max_tokens': 'Infinity', 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, input=[{'content': [{'type': 'text', 'text': \"What's in this image?\"}, {'type': 'image_url', 'image_url': {'url': '@@@langfuseMedia:type=image/jpeg|id=i5BuV2qX9nPaAAPf7c0gCY|source=base64_data_uri@@@'}}], 'role': 'user'}], version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output={'role': 'assistant', 'content': \"The image features a dog with curly fur, sitting with its front paws resting on a person's knee. The dog appears to be friendly and is sticking out its tongue. In the background, there are a few people and some indoor furniture, suggesting a home environment. The floor has a colorful rug, and there are items like a basket and a leash visible.\"}, usage=Usage(input=25513, output=71, total=25584, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={'input': 25513, 'output': 71, 'total': 25584, 'input_audio_tokens': 0, 'input_cached_tokens': 0, 'output_accepted_prediction_tokens': 0, 'output_audio_tokens': 0, 'output_reasoning_tokens': 0, 'output_rejected_prediction_tokens': 0}, cost_details={'input': 0.00382695, 'output': 4.26e-05, 'input_cached_tokens': 0.0, 'total': 0.00386955}, environment='default', prompt_name=None, prompt_version=None, model_id='clyrjpbe20000t0mzcbwc42rg', input_price=1.5e-07, output_price=6e-07, total_price=None, calculated_input_cost=0.00382695, calculated_output_cost=4.26e-05, calculated_total_cost=0.00386955, latency=4028.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:35:49.360Z', promptTokens=25513, totalTokens=25584, updatedAt='2025-06-12T16:35:49.397Z', completionTokens=71), ObservationsView(id='24ef0545d1a9d66d', trace_id='87d4eedc8b68fa960ab487a0fd12e136', type='GENERATION', name='ChatOpenAI', start_time=datetime.datetime(2025, 6, 12, 16, 35, 45, 182000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 35, 49, 218000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='gpt-4o-mini-2024-07-18', model_parameters={}, input=[{'role': 'user', 'content': [{'type': 'text', 'text': \"What's in this image?\"}, {'type': 'image_url', 'image_url': {'url': '@@@langfuseMedia:type=image/jpeg|id=i5BuV2qX9nPaAAPf7c0gCY|source=base64_data_uri@@@'}}]}], version=None, metadata={'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output={'role': 'assistant', 'content': \"The image features a dog with curly fur, sitting with its front paws resting on a person's knee. The dog appears to be friendly and is sticking out its tongue. In the background, there are a few people and some indoor furniture, suggesting a home environment. The floor has a colorful rug, and there are items like a basket and a leash visible.\", 'additional_kwargs': {'refusal': None}}, usage=Usage(input=25513, output=71, total=25584, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={'input': 25513, 'output': 71, 'total': 25584, 'input_audio': 0, 'input_cache_read': 0, 'output_audio': 0, 'output_reasoning': 0}, cost_details={'input': 0.00382695, 'output': 4.26e-05, 'input_cache_read': 0.0, 'total': 0.00386955}, environment='default', prompt_name=None, prompt_version=None, model_id='clyrjpbe20000t0mzcbwc42rg', input_price=1.5e-07, output_price=6e-07, total_price=None, calculated_input_cost=0.00382695, calculated_output_cost=4.26e-05, calculated_total_cost=0.00386955, latency=4036.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:35:49.512Z', promptTokens=25513, totalTokens=25584, updatedAt='2025-06-12T16:35:49.602Z', completionTokens=71), ObservationsView(id='9120c59b45e285f6', trace_id='27bf223edc5f1cc3e9e632602e4a4a76', type='SPAN', name='main', start_time=datetime.datetime(2025, 6, 12, 16, 33, 46, 735000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 33, 46, 737000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': [], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:33:46.866Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T16:33:46.924Z', completionTokens=0), ObservationsView(id='3a687f0b4d591fb1', trace_id='2b1552aae36a22124d8cd56545a7c615', type='GENERATION', name='OpenAI-generation', start_time=datetime.datetime(2025, 6, 12, 16, 32, 43, 617000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 32, 52, 936000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='gpt-4o-audio-preview-2024-12-17', model_parameters={'temperature': 1, 'max_tokens': 'Infinity', 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, input=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Do what this recording says.'}, {'type': 'input_audio', 'input_audio': {'data': '@@@langfuseMedia:type=audio/wav|id=EAP3nmd-P5gxNgwcRL22qB|source=base64_data_uri@@@', 'format': 'wav'}}]}], version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output={'role': 'assistant', 'content': None, 'audio': {'id': 'audio_684b01341fd081918a825276eb36472b', 'data': '@@@langfuseMedia:type=audio/wav|id=JW7UVjwi6QFdiGieq5nulf|source=base64_data_uri@@@', 'expires_at': 1749749572, 'transcript': 'Why did the Berlin Bear get lost in the city? Because he couldn\\'t decide whether to take the U-Bahn, the S-Bahn, or just \"bear\"ly walk anywhere!'}}, usage=Usage(input=66, output=245, total=311, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={'input': 17, 'output': 51, 'total': 311, 'input_audio_tokens': 49, 'input_cached_tokens': 0, 'output_accepted_prediction_tokens': 0, 'output_audio_tokens': 194, 'output_reasoning_tokens': 0, 'output_rejected_prediction_tokens': 0}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=9319.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:32:53.147Z', promptTokens=66, totalTokens=311, updatedAt='2025-06-12T16:32:53.301Z', completionTokens=245), ObservationsView(id='b20b80a5efdcd8c5', trace_id='c6f25142e5bee16e9cfa417c1b8d7e52', type='GENERATION', name='OpenAI-generation', start_time=datetime.datetime(2025, 6, 12, 16, 32, 0, 775000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 32, 6, 887000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='gpt-4o-audio-preview-2024-12-17', model_parameters={'temperature': 1, 'max_tokens': 'Infinity', 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, input=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Do what this recording says.'}, {'type': 'input_audio', 'input_audio': {'data': '@@@langfuseMedia:type=audio/wav|id=EAP3nmd-P5gxNgwcRL22qB|source=base64_data_uri@@@', 'format': 'wav'}}]}], version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output={'role': 'assistant', 'content': None, 'audio': {'id': 'audio_684b0105f130819191c64f62e2ba101b', 'data': '@@@langfuseMedia:type=audio/wav|id=T9rrdzVwdiZzlAh-_VAeOA|source=base64_data_uri@@@', 'expires_at': 1749749525, 'transcript': 'Sure, here\\'s a joke for you: Why don\\'t secrets last long in Berlin? Because as soon as someone says, \"This is top secret,\" someone else replies, \"Nein, this is Hauptstadt!\"'}}, usage=Usage(input=66, output=345, total=411, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={'input': 17, 'output': 60, 'total': 411, 'input_audio_tokens': 49, 'input_cached_tokens': 0, 'output_accepted_prediction_tokens': 0, 'output_audio_tokens': 285, 'output_reasoning_tokens': 0, 'output_rejected_prediction_tokens': 0}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=6112.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:32:07.049Z', promptTokens=66, totalTokens=411, updatedAt='2025-06-12T16:32:07.123Z', completionTokens=345), ObservationsView(id='add854bc2bd23027', trace_id='9f5c17ebf39c7ab6956ec8f2f244352e', type='GENERATION', name='OpenAI-generation', start_time=datetime.datetime(2025, 6, 12, 16, 30, 46, 336000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 30, 49, 163000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='gpt-4o-mini-2024-07-18', model_parameters={'temperature': 1, 'max_tokens': 300, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, input=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Whatâ€™s in this image?'}, {'type': 'image_url', 'image_url': {'url': '@@@langfuseMedia:type=image/jpeg|id=i5BuV2qX9nPaAAPf7c0gCY|source=base64_data_uri@@@'}}]}], version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output={'role': 'assistant', 'content': \"The image features a dog sitting on a person's lap with its front paws resting on their knee. The dog has a curly coat with black and white fur and appears to be happy, with its tongue out. In the background, there are people standing, likely engaged in conversation. The setting seems to be a cozy indoor space with wooden flooring and a colorful rug.\"}, usage=Usage(input=25514, output=72, total=25586, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={'input': 25514, 'output': 72, 'total': 25586, 'input_audio_tokens': 0, 'input_cached_tokens': 0, 'output_accepted_prediction_tokens': 0, 'output_audio_tokens': 0, 'output_reasoning_tokens': 0, 'output_rejected_prediction_tokens': 0}, cost_details={'input': 0.0038271, 'output': 4.32e-05, 'input_cached_tokens': 0.0, 'total': 0.0038703}, environment='default', prompt_name=None, prompt_version=None, model_id='clyrjpbe20000t0mzcbwc42rg', input_price=1.5e-07, output_price=6e-07, total_price=None, calculated_input_cost=0.0038271, calculated_output_cost=4.32e-05, calculated_total_cost=0.0038703, latency=2827.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:30:49.318Z', promptTokens=25514, totalTokens=25586, updatedAt='2025-06-12T16:30:49.351Z', completionTokens=72), ObservationsView(id='aab878527ac51e67', trace_id='58731fd633fe070a11f1ff32694d8d91', type='GENERATION', name='OpenAI-generation', start_time=datetime.datetime(2025, 6, 12, 16, 30, 24, 459000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 30, 29, 112000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='gpt-4o-mini-2024-07-18', model_parameters={'temperature': 1, 'max_tokens': 300, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, input=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Whatâ€™s in this image?'}, {'type': 'image_url', 'image_url': {'url': '@@@langfuseMedia:type=image/jpeg|id=i5BuV2qX9nPaAAPf7c0gCY|source=base64_data_uri@@@'}}]}], version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output={'role': 'assistant', 'content': \"The image shows a fluffy black and white dog sitting with its paws on a person's knee. The dog appears to be happy, with its tongue out. In the background, there are a few people standing, but they are not the focus of the image. The setting looks like a cozy indoor space with wooden floors and some colorful decor.\"}, usage=Usage(input=25514, output=67, total=25581, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={'input': 25514, 'output': 67, 'total': 25581, 'input_audio_tokens': 0, 'input_cached_tokens': 0, 'output_accepted_prediction_tokens': 0, 'output_audio_tokens': 0, 'output_reasoning_tokens': 0, 'output_rejected_prediction_tokens': 0}, cost_details={'input': 0.0038271, 'output': 4.02e-05, 'input_cached_tokens': 0.0, 'total': 0.003867299999}, environment='default', prompt_name=None, prompt_version=None, model_id='clyrjpbe20000t0mzcbwc42rg', input_price=1.5e-07, output_price=6e-07, total_price=None, calculated_input_cost=0.0038271, calculated_output_cost=4.02e-05, calculated_total_cost=0.003867299999, latency=4653.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:30:29.262Z', promptTokens=25514, totalTokens=25581, updatedAt='2025-06-12T16:30:29.376Z', completionTokens=67), ObservationsView(id='a1e6da6ad73f73b8', trace_id='01ff750a8388d222a8ac635ee015cfbe', type='GENERATION', name='OpenAI-generation', start_time=datetime.datetime(2025, 6, 12, 16, 29, 59, 135000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 30, 2, 864000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='gpt-4o-mini-2024-07-18', model_parameters={'temperature': 1, 'max_tokens': 300, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, input=[{'role': 'user', 'content': [{'type': 'text', 'text': 'Whatâ€™s in this image?'}, {'type': 'image_url', 'image_url': {'url': '@@@langfuseMedia:type=image/jpeg|id=i5BuV2qX9nPaAAPf7c0gCY|source=base64_data_uri@@@'}}]}], version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output={'role': 'assistant', 'content': 'The image shows a dog with a curly coat, sitting and interacting with a person whose leg is visible. The dog appears to be happy, with its tongue out. In the background, there are several people standing, but they are not the main focus of the image. The setting seems to be an indoor space, possibly a living room, with wooden flooring.'}, usage=Usage(input=25514, output=72, total=25586, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={'input': 25514, 'output': 72, 'total': 25586, 'input_audio_tokens': 0, 'input_cached_tokens': 0, 'output_accepted_prediction_tokens': 0, 'output_audio_tokens': 0, 'output_reasoning_tokens': 0, 'output_rejected_prediction_tokens': 0}, cost_details={'input': 0.0038271, 'output': 4.32e-05, 'input_cached_tokens': 0.0, 'total': 0.0038703}, environment='default', prompt_name=None, prompt_version=None, model_id='clyrjpbe20000t0mzcbwc42rg', input_price=1.5e-07, output_price=6e-07, total_price=None, calculated_input_cost=0.0038271, calculated_output_cost=4.32e-05, calculated_total_cost=0.0038703, latency=3729.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:30:04.143Z', promptTokens=25514, totalTokens=25586, updatedAt='2025-06-12T16:30:04.207Z', completionTokens=72), ObservationsView(id='044bc6266ea84732', trace_id='abdbcb07f7e198ea4ac4b307f652fbb1', type='GENERATION', name='intent_classification', start_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 481000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 481000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters={}, input={'message': 'Could you recommend a good book?'}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=0.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:24:33.753Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T16:24:33.788Z', completionTokens=0), ObservationsView(id='30c2b310c5276e6d', trace_id='bb2bfc105b87552a2433579b83671fdb', type='GENERATION', name='intent_classification', start_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 481000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 481000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters={}, input={'message': 'Can you do anything else?'}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=0.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:24:33.752Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T16:24:33.792Z', completionTokens=0), ObservationsView(id='4d2b98486a778f4f', trace_id='a8a3503d0205cbe9d85b9719ef272744', type='GENERATION', name='intent_classification', start_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 481000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 481000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters={}, input={'message': 'Please revert to the beginning'}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=0.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:24:33.753Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T16:24:33.791Z', completionTokens=0), ObservationsView(id='4e2caf070f36a9ae', trace_id='bb0746d759d639fc31d77d017d0f89b9', type='GENERATION', name='intent_classification', start_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 481000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 481000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters={}, input={'message': \"I'd like to watch a drama\"}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=0.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:24:33.754Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T16:24:33.811Z', completionTokens=0), ObservationsView(id='4a627e57614b5117', trace_id='e6b1825635fe1810c1324560e84b7015', type='GENERATION', name='intent_classification', start_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 480000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 16, 24, 33, 480000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters={}, input={'message': 'Hello again'}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=0.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T16:24:33.752Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T16:24:33.783Z', completionTokens=0), ObservationsView(id='797913fddf744a0a', trace_id='9a6071d27444a0f5d7cc431ecdd72e70', type='GENERATION', name='OpenAI-generation', start_time=datetime.datetime(2025, 6, 12, 15, 33, 48, 67000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 33, 50, 664000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='gpt-4o-2024-08-06', model_parameters={'temperature': 1, 'max_tokens': 100, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, input=[{'role': 'system', 'content': 'You are a great storyteller. Write a story about the topic that the user provides.'}, {'role': 'user', 'content': 'war-crimes'}], version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output={'role': 'assistant', 'content': \"In the peaceful village of Lindenvale, nestled between rolling hills and a tranquil river, life had always followed the gentle rhythm of nature. Farmers tended to their fields, children played in the meadows, and elders shared their stories under the shade of sprawling oak trees. But the echoes of distant drums began to resonate through the air, signaling an encroaching darkness that would shatter the village's serenity.\\n\\nIt was during one cloudy autumn morning that the first shadows appeared on the horizon. Soldiers in grim\"}, usage=Usage(input=31, output=100, total=131, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='9c2d9c476912afbd', prompt_id=None, usage_details={'input': 31, 'output': 100, 'total': 131, 'input_audio_tokens': 0, 'input_cached_tokens': 0, 'output_accepted_prediction_tokens': 0, 'output_audio_tokens': 0, 'output_reasoning_tokens': 0, 'output_rejected_prediction_tokens': 0}, cost_details={'input': 3.1e-05, 'output': 0.0001, 'total': 0.000131}, environment='default', prompt_name=None, prompt_version=None, model_id='b33c06da-9490-4bbd-a2dd-878222948539', input_price=1e-06, output_price=1e-06, total_price=None, calculated_input_cost=3.1e-05, calculated_output_cost=0.0001, calculated_total_cost=0.000131, latency=2597.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:33:51.208Z', promptTokens=31, totalTokens=131, updatedAt='2025-06-12T15:33:51.319Z', completionTokens=100), ObservationsView(id='9c2d9c476912afbd', trace_id='9a6071d27444a0f5d7cc431ecdd72e70', type='SPAN', name='story', start_time=datetime.datetime(2025, 6, 12, 15, 33, 48, 63000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 33, 50, 665000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['war-crimes'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=\"In the peaceful village of Lindenvale, nestled between rolling hills and a tranquil river, life had always followed the gentle rhythm of nature. Farmers tended to their fields, children played in the meadows, and elders shared their stories under the shade of sprawling oak trees. But the echoes of distant drums began to resonate through the air, signaling an encroaching darkness that would shatter the village's serenity.\\n\\nIt was during one cloudy autumn morning that the first shadows appeared on the horizon. Soldiers in grim\", usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='d5a79b74aea5049d', prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2602.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:33:51.178Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:33:51.225Z', completionTokens=0), ObservationsView(id='d5a79b74aea5049d', trace_id='9a6071d27444a0f5d7cc431ecdd72e70', type='SPAN', name='main', start_time=datetime.datetime(2025, 6, 12, 15, 33, 48, 63000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 33, 50, 665000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': [], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=\"In the peaceful village of Lindenvale, nestled between rolling hills and a tranquil river, life had always followed the gentle rhythm of nature. Farmers tended to their fields, children played in the meadows, and elders shared their stories under the shade of sprawling oak trees. But the echoes of distant drums began to resonate through the air, signaling an encroaching darkness that would shatter the village's serenity.\\n\\nIt was during one cloudy autumn morning that the first shadows appeared on the horizon. Soldiers in grim\", usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2602.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:33:51.226Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:33:51.318Z', completionTokens=0), ObservationsView(id='7e92ef6ab99cca44', trace_id='34fdb78d37c9413102d83f9f7eee4bed', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 27, 4, 86000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 27, 9, 679000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'true', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='a82a5b74291d02d6', prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=5593.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:27:12.300Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:27:12.411Z', completionTokens=0), ObservationsView(id='a82a5b74291d02d6', trace_id='34fdb78d37c9413102d83f9f7eee4bed', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 27, 4, 78000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 27, 5, 206000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'false', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1128.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:27:07.436Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:27:07.492Z', completionTokens=0), ObservationsView(id='98ed8003257374e4', trace_id='ff825d4f344d1c252b8616962b78517f', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 26, 57, 556000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 27, 3, 276000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'true', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='65f080fcdeab6861', prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=5720.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:27:05.570Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:27:05.623Z', completionTokens=0), ObservationsView(id='65f080fcdeab6861', trace_id='ff825d4f344d1c252b8616962b78517f', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 26, 57, 548000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 27, 3, 277000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'false', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=5729.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:27:05.665Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:27:05.717Z', completionTokens=0), ObservationsView(id='501126e8079a148f', trace_id='6f7e8869393486dc82b7d98d55fd1c9f', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 23, 56, 932000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 24, 2, 162000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'true', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='7f8a394429643393', prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=5230.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:24:02.386Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:24:02.425Z', completionTokens=0), ObservationsView(id='7f8a394429643393', trace_id='6f7e8869393486dc82b7d98d55fd1c9f', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 23, 56, 929000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 24, 2, 163000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'false', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=5234.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:24:02.448Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:24:02.491Z', completionTokens=0), ObservationsView(id='9e91736f231b27f9', trace_id='6792062c423a9c85b4008febf6d6280d', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 23, 47, 47000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 23, 56, 919000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'true', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='3712dfe7a923ad5a', prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=9872.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:23:58.896Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:23:58.943Z', completionTokens=0), ObservationsView(id='3712dfe7a923ad5a', trace_id='6792062c423a9c85b4008febf6d6280d', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 23, 47, 35000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 23, 56, 921000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'false', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=9886.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:23:59.089Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:23:59.144Z', completionTokens=0), ObservationsView(id='d37ae3165d90fa10', trace_id='ece0aacddcc29bb1edce6196f945093b', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 16, 57, 316000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 17, 4, 563000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'old', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'true', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='b578a2c31b4b66d6', prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=7247.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:17:06.111Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:17:06.186Z', completionTokens=0), ObservationsView(id='b578a2c31b4b66d6', trace_id='ece0aacddcc29bb1edce6196f945093b', type='SPAN', name='Correctness (GEval)', start_time=datetime.datetime(2025, 6, 12, 15, 16, 57, 312000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 17, 4, 564000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input=None, version=None, metadata={'attributes': {'logged_in_with': 'NA', 'environment': 'jupyter', 'user.status': 'new', 'user.unique_id': '91afc881-fa93-4e20-9b4d-ba5c0ea7726c', 'user.public_ip': '89.247.226.29', 'async_mode': 'false', 'in_component': '0'}, 'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'deepeval.telemetry', 'attributes': {}}}, output=None, usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=7252.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:17:06.204Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:17:06.269Z', completionTokens=0), ObservationsView(id='f453fbed5e80da64', trace_id='34d6ce72d505acb25a89c6b197df9f5f', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 39, 453000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 41, 187000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The physics behind time travel theories.'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Time travel is a fascinating concept that sparks the imagination! Theories suggest that if we could manipulate space and time, like bending a cosmic highway, we might jump to different moments in time. Some ideas involve cosmic phenomena, like black holes or wormholes, which are like shortcuts through the universe. While itâ€™s all still theoretical, exploring these ideas can feel like stepping into a sci-fi adventure!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1734.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:41.610Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:41.716Z', completionTokens=0), ObservationsView(id='09245722f8edb570', trace_id='6ce44bbf90e6b29748c7f5e8cbf5cf3e', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 34, 3000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 39, 453000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['How virtual reality is changing therapy'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=\"Virtual reality (VR) is shaking up therapy by creating immersive experiences that help people face their fears and practice new skills in a safe space! For example, someone with a fear of heights can explore a virtual skyscraper, gradually building confidence without the real-world risks. It also allows therapists to tailor experiences to individual needs, making sessions more engaging and effective. Plus, who wouldn't want to tackle challenges while wearing cool VR goggles?\", usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=5450.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:39.605Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:39.639Z', completionTokens=0), ObservationsView(id='4ae0077f0023e420', trace_id='7be93bb05f108c70a515d6a0c8aeed64', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 32, 6000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 34, 3000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The evolutionary mysteries of the human hand'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=\"Isn't it fascinating how our hands tell a story of evolution? Theyâ€™re not just tools for gripping and holding; theyâ€™re a perfect blend of strength and dexterity! Over millions of years, our ancestors adapted their hands for tasks like climbing, making tools, and even expressing emotions. So next time you wave hello or tackle a tricky puzzle, rememberâ€”your hands are a remarkable result of evolutionary creativity!\", usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1997.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:35.514Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:35.587Z', completionTokens=0), ObservationsView(id='fdfdd41d33550d2a', trace_id='fc1c85b47a13397e873828a7c0863299', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 29, 371000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 32, 5000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['Space dust and its impact on the solar system'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Space dust might sound like a tiny detail, but it plays a big role in our solar system! This cosmic sprinkle, made of tiny particles from comets and asteroids, helps form new planets and even supports the creation of stars. Plus, it can affect the orbits of smaller celestial bodies, giving them a little nudge now and then. So, next time you gaze at the night sky, remember that even the smallest bits of dust are part of a grand cosmic dance!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2634.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:33.714Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:33.832Z', completionTokens=0), ObservationsView(id='384d77f3cce2653b', trace_id='067a697374243b77b4411f2f8a1dbbc6', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 27, 363000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 29, 370000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['How the brain processes fear'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='When you sense something scary, your brain kicks into high gear! It starts with a tiny area called the amygdala, which acts like a smoke alarm, detecting danger and triggering a fear response. This can make your heart race and your senses sharper, preparing you to either fight or run away. Isnâ€™t it fascinating how our brains help keep us safe, even when weâ€™re just watching a spooky movie?', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2007.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:31.883Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:31.946Z', completionTokens=0), ObservationsView(id='904f6c42383b13bf', trace_id='83a99a72694e61292cd8219cee4db696', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 24, 269000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 27, 362000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The impact of urbanization on wildlife'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Urbanization profoundly changes the habitats where wildlife lives, often leading to a struggle for survival. As cities expand, animals may lose their homes, face more pollution, and encounter more vehicles, making it harder for them to thrive. However, some species adapt remarkably well, finding new niches in urban environments, like raccoons rummaging through trash or pigeons nesting on buildings. Itâ€™s a fascinating reminder of natureâ€™s resilience, even in the face of our bustling cities!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=3093.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:30.270Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:30.325Z', completionTokens=0), ObservationsView(id='89986655f5299226', trace_id='e907a0333928b30b73fdd6f1195d3af4', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 22, 291000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 24, 267000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['Exploring the limits of human endurance'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Exploring the limits of human endurance is like a thrilling adventure into what our bodies can really do! From ultra-marathons to extreme sports, people are constantly pushing their physical and mental boundaries. Amazing feats, like climbing Mount Everest or swimming across the English Channel, show us just how far determination and training can take us. Itâ€™s not just about strength; itâ€™s also about the power of the mind and the spirit to keep going, even when the going gets tough!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1976.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:25.977Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:26.260Z', completionTokens=0), ObservationsView(id='41f469490c7f4a97', trace_id='03686712e95c60aa86be9c865263933d', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 20, 564000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 22, 291000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The role of emotions in decision-making'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Emotions play a huge role in how we make decisions, often acting like a guiding compass! They help us weigh our options by influencing what feels right or wrong in a situation. For example, excitement might push us to take a risk, while fear could hold us back. So, the next time youâ€™re faced with a choice, remember that your feelings are there to help you navigate the path ahead!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1727.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:22.624Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:22.763Z', completionTokens=0), ObservationsView(id='e7506fbd146ea25d', trace_id='ac2cddbc805a514f3a48e7075ce8a720', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 18, 872000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 20, 563000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['How dolphins communicate and their intelligence'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Dolphins are like the chatty social butterflies of the ocean! They use a mix of clicks, whistles, and body movements to express themselves, almost like a complex language. Their intelligence is off the charts; they can solve problems, recognize themselves in mirrors, and even play games! Itâ€™s no wonder we find these playful creatures so fascinating!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1691.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:20.876Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:20.941Z', completionTokens=0), ObservationsView(id='7a16bb28637a86d1', trace_id='d02447a2d242e6fe6606f3bbd1d8a8f2', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 17, 410000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 18, 871000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['Nanotechnology and its impact on medicine'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=\"Nanotechnology is like having tiny superheroes at our disposal! These minuscule particles, often smaller than a human cell, can deliver drugs directly to where they're needed in the body, making treatments more effective and reducing side effects. They can also help in diagnosing diseases earlier by highlighting problem areas in scans. With ongoing research, the future of medicine looks brighter and more precise thanks to these little wonders!\", usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1461.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:19.133Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:19.177Z', completionTokens=0), ObservationsView(id='be69b0393870c9ae', trace_id='22946a25740c69f5d7cf8d397ae59995', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 15, 370000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 17, 409000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The chemistry behind culinary flavors'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Culinary flavors are like a delicious dance of chemistry! When you cook, heat causes ingredients to release aromatic compounds that tickle your taste buds. For example, caramelization transforms sugars into rich, sweet flavors, while the Maillard reaction creates those mouthwatering savory notes in grilled meats. So, every time you savor a dish, youâ€™re enjoying a symphony of chemical reactions that make your food truly delightful!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2039.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:17.562Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:17.629Z', completionTokens=0), ObservationsView(id='24f0afa736dce2a9', trace_id='f8ad60d4fe9aa6c617324b54ccaf4842', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 13, 86000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 15, 369000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The science of tsunamis and earthquakes'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=\"Tsunamis and earthquakes are like nature's dramatic dance! Earthquakes happen when the Earth's tectonic plates shift, releasing energy that causes the ground to shake. If that shift occurs under the ocean, it can displace a massive amount of water, creating a tsunami that travels across the sea like a giant wave. While both are powerful forces of nature, understanding them helps us prepare and stay safe when the earth decides to shake things up!\", usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2283.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:16.442Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:16.483Z', completionTokens=0), ObservationsView(id='c3c7406d0ea444f4', trace_id='df6dc4c9b210bb1df07d1e0f7754c117', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 10, 545000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 13, 85000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['How technology is changing agriculture'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Technology is transforming agriculture in exciting ways! Farmers are now using drones to monitor crops from above, which helps them spot issues like pests or diseases early on. Smart sensors in the soil can tell them exactly when to water or fertilize, saving resources and boosting yields. Plus, with the rise of apps and data analysis, farmers can make better decisions based on real-time information, leading to healthier crops and a more sustainable future!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2540.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:14.537Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:14.595Z', completionTokens=0), ObservationsView(id='8ff1c9a796f97b7b', trace_id='8cb172df4f03d33f031f8ac1a6a86f01', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 8, 446000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 10, 544000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The future of personalized medicine'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='The future of personalized medicine is like having a tailored suit for your health! Imagine doctors using your unique genetic makeup to create treatments that fit you perfectly, just like your favorite outfit. This could mean more effective therapies with fewer side effects, as well as proactive health measures that keep you feeling your best. With ongoing advances in technology and research, weâ€™re on the brink of a healthcare revolution that truly puts you at the center of your wellness journey!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2098.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:12.570Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:12.614Z', completionTokens=0), ObservationsView(id='2f78fa4b39ac5783', trace_id='b55d83b978be1a48e5a5192d07da4b3b', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 6, 667000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 8, 445000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The impact of deforestation on the environment'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Deforestation is like giving our planet a bad haircut! When we cut down trees, we lose homes for countless animals and plants, and it disrupts the balance of our ecosystems. Plus, trees play a crucial role in cleaning our air by absorbing carbon dioxide, so fewer trees mean more greenhouse gases in the atmosphere. Letâ€™s plant more trees and protect our forests to keep our planet healthy and happy! ðŸŒ³âœ¨', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1778.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:11.066Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:11.380Z', completionTokens=0), ObservationsView(id='189c3e6c73fadb65', trace_id='58c9bb9f186430cc6b2191b25195549c', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 4, 595000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 6, 667000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The ethics of gene editing'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Gene editing is like having a superpower to change the instructions in our DNA, but it comes with big responsibilities! While it has the potential to cure diseases and improve crops, we must consider the moral implications, like fairness and safety. Imagine if we could edit traits in humansâ€”what would that mean for diversity and identity? Itâ€™s a thrilling adventure in science, but we need to tread carefully and think about the impact on everyone!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=2072.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:08.957Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:09.093Z', completionTokens=0), ObservationsView(id='ccc3e198225016d7', trace_id='4a74f65d0aa1cb39de847dfd53b7ac2e', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 3, 102000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 4, 595000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The biology of resilience and stress management'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=\"Resilience is like our bodyâ€™s built-in superhero cape, helping us bounce back from challenges! It involves a mix of our brainâ€™s wiring, hormones, and even our immune system working together. When stress hits, our body releases chemicals that can either help us cope or, if we're overwhelmed, can make things tougher. By practicing self-care, like exercise and mindfulness, we can boost our resilience and manage stress like a pro!\", usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1493.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:06.142Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:06.566Z', completionTokens=0), ObservationsView(id='691f0106849eae07', trace_id='299b7d53887c074450d933e05f0f9dbc', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 15, 0, 1, 462000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 3, 101000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['How technology is transforming education'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Technology is shaking up education in some really exciting ways! Imagine learning from the comfort of your home with online classes, where you can connect with teachers and friends from all over the world. Plus, interactive tools like apps and games make studying feel more like playtime, helping students grasp tough concepts with ease. With all these cool gadgets and resources at their fingertips, learners today can explore their passions like never before!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1639.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:03.554Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:03.620Z', completionTokens=0), ObservationsView(id='8436611242214d36', trace_id='1a4915d948fc7735d3cbfe3cc8e60657', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 14, 59, 59, 523000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 15, 0, 1, 462000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The science of pheromones and attraction'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Pheromones are like nature\\'s secret signals that our bodies release to communicate with others, especially when it comes to attraction! These invisible chemical messengers can influence how we perceive someone and even spark interest without us realizing it. Think of them as the ultimate \"love scents\" that help us find a compatible partner. So, the next time you feel an instant connection with someone, it might just be those sneaky pheromones at play!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1939.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T15:00:01.585Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T15:00:01.656Z', completionTokens=0), ObservationsView(id='ffc93246c992258f', trace_id='add5e56b7827c15b6ad4154642c1735f', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 14, 59, 57, 697000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 14, 59, 59, 522000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The role of sleep in memory consolidation'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output=\"Sleep is like a superhero for your brain when it comes to memory! During those cozy hours of slumber, your brain works hard to organize and strengthen the memories you've made throughout the day. Itâ€™s as if your mind is filing away important information, making it easier to recall later. So, if you want to remember that fun fact or new skill, donâ€™t skip out on a good nightâ€™s sleep! ðŸ’¤âœ¨\", usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1825.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T14:59:59.685Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T14:59:59.943Z', completionTokens=0), ObservationsView(id='ca0ff53b8177b5a2', trace_id='0c5a3edf93d78917e25e59af3a89e263', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 14, 59, 56, 142000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 14, 59, 57, 697000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The effects of meditation on the brain'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Meditation is like a workout for your brain, helping it become more flexible and resilient! Studies show that regular meditation can increase the thickness of the prefrontal cortex, which is responsible for decision-making and self-control. It also boosts areas linked to emotional regulation, making you feel calmer and more focused. So, not only does meditation help you relax, but it also gives your brain a superpower upgrade! ðŸ§ âœ¨', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1555.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T14:59:57.815Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T14:59:57.872Z', completionTokens=0), ObservationsView(id='bb4331d24f4da4c3', trace_id='ffbed23bb3c9111b2aec98a60c5c663f', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 14, 59, 54, 644000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 14, 59, 56, 142000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The science of empathy and altruism'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Empathy is like having a superpower that lets us understand and share the feelings of others, helping us connect on a deeper level. Altruism, on the other hand, is when we act selflessly to help someone else, often without expecting anything in return. Scientists believe that both traits are rooted in our brains and can be influenced by our experiences and environment. So, by practicing kindness and compassion, we can actually boost our empathy and make the world a better place!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1498.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T14:59:56.777Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T14:59:56.825Z', completionTokens=0), ObservationsView(id='6e5621c79243e98d', trace_id='36b0eb4378cb9f683c04c6cb83d8d74f', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 14, 59, 53, 99000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 14, 59, 54, 644000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The rise of sustainable fashion'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Sustainable fashion is all about creating clothes in a way thatâ€™s kind to our planet and its people! It focuses on using eco-friendly materials, reducing waste, and ensuring fair labor practices. More brands are embracing this shift as consumers demand stylish options that donâ€™t harm the environment. So, when you choose sustainable fashion, youâ€™re not just looking goodâ€”youâ€™re making a positive impact!', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=1545.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T14:59:55.669Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T14:59:55.712Z', completionTokens=0), ObservationsView(id='4e330e2586854323', trace_id='1609200cdc963df756c24a892eaa5707', type='SPAN', name='explain_concept', start_time=datetime.datetime(2025, 6, 12, 14, 59, 49, 879000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2025, 6, 12, 14, 59, 53, 98000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'args': ['The physics of black holes'], 'kwargs': {}}, version=None, metadata={'resourceAttributes': {'telemetry.sdk.language': 'python', 'telemetry.sdk.name': 'opentelemetry', 'telemetry.sdk.version': '1.33.1', 'service.name': 'unknown_service'}, 'scope': {'name': 'langfuse-sdk', 'version': '3.0.1', 'attributes': {'public_key': 'pk-lf-5855d85e-3943-497e-bd10-f50ad414bcba'}}}, output='Black holes are like cosmic vacuum cleaners, but instead of sucking up dirt, they pull in everything around them with their intense gravity! They form when massive stars collapse under their own weight, creating a point where gravity is so strong that not even light can escape. Imagine a whirlpool in space that traps everything nearbyâ€”once something crosses the \"event horizon,\" there\\'s no turning back! They\\'re mysterious and fascinating, giving scientists a glimpse into the extreme laws of physics.', usage=Usage(input=0, output=0, total=0, unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, usage_details={}, cost_details={}, environment='default', prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=0.0, latency=3219.0, time_to_first_token=None, unit='TOKENS', projectId='cloramnkj0002jz088vzn1ja4', createdAt='2025-06-12T14:59:54.596Z', promptTokens=0, totalTokens=0, updatedAt='2025-06-12T14:59:54.656Z', completionTokens=0)], meta=MetaResponse(page=1, limit=50, total_items=30744, total_pages=615))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSDLt-7z8rvC"
      },
      "source": [
        "## Fetch Single Observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p49VH27b8rS_",
        "outputId": "67b314e4-9d21-4dbe-8d63-e308cd3fc90f"
      },
      "outputs": [],
      "source": [
        "observation = langfuse.api.observations.get(\"24ef0545d1a9d66d\")\n",
        "# print(observation.json(indent=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vztqWLz85WG"
      },
      "source": [
        "## Fetch Multiple Sessions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OApAjQPt9FBC"
      },
      "source": [
        "Simple example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "IZon_rre80Iw",
        "outputId": "886cd143-d6c5-44bd-c904-94f715a93e68"
      },
      "outputs": [],
      "source": [
        "sessions = langfuse.api.sessions.list(limit=50)\n",
        "# pydantic_list_to_dataframe(sessions.data).head(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

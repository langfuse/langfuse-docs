{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Observability for Agno with Langfuse\n",
    "description: Learn how to integrate Langfuse with Agno via OpenTelemetry\n",
    "category: Integrations\n",
    "---\n",
    "\n",
    "# Integrate Langfuse with Agno\n",
    "\n",
    "This notebook demonstrates how to integrate **Langfuse** with **Agno** using OpenTelemetry via the **OpenLIT** instrumentation. By the end of this notebook, you will be able to trace your Agno applications with Langfuse for improved observability and debugging.\n",
    "\n",
    "> **What is Agno?** [Agno](https://docs.agno.com/) is a platform for building and managing AI agents.\n",
    "\n",
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source LLM engineering platform. It provides tracing and monitoring capabilities for LLM applications, helping developers debug, analyze, and optimize their AI systems. Langfuse integrates with various tools and frameworks via native integrations, OpenTelemetry, and API/SDKs.\n",
    "\n",
    "## Get Started\n",
    "\n",
    "We'll walk through examples of using Agno and integrating it with Langfuse.\n",
    "\n",
    "### Step 1: Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agno openai langfuse yfinance openlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Up Environment Variables\n",
    "\n",
    "Get your Langfuse API keys by signing up for [Langfuse Cloud](https://cloud.langfuse.com) or [self-hosting Langfuse](https://langfuse.com/self-hosting).You'll also need your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
    "\n",
    "# your openai key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the environment variables set, we can now initialize the Langfuse client. `get_client()` initializes the Langfuse client using the credentials provided in the environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Sending Traces to Langfuse\n",
    "\n",
    "This example demonstrates how to use the OpenLit instrumentation library to ingfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.33.1\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559112000,\n",
      "                                        \"time_unix_nano\": 1749653425848669000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 1071,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 183,\n",
      "                                        \"max\": 888,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559190000,\n",
      "                                        \"time_unix_nano\": 1749653425848669000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 5.745627164840698,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 0.9523701667785645,\n",
      "                                        \"max\": 4.793256998062134,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559238000,\n",
      "                                        \"time_unix_nano\": 1749653425848669000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 5.745627164840698,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 0.9523701667785645,\n",
      "                                        \"max\": 4.793256998062134,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559759000,\n",
      "                                        \"time_unix_nano\": 1749653425848669000,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559799000,\n",
      "                                        \"time_unix_nano\": 1749653425848669000,\n",
      "                                        \"value\": 245,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559818000,\n",
      "                                        \"time_unix_nano\": 1749653425848669000,\n",
      "                                        \"value\": 826,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559840000,\n",
      "                                        \"time_unix_nano\": 1749653425848669000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0.00027089999999999997,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 3.645e-05,\n",
      "                                        \"max\": 0.00023444999999999998,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.33.1\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559112000,\n",
      "                                        \"time_unix_nano\": 1749653485854488000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 1071,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 183,\n",
      "                                        \"max\": 888,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559190000,\n",
      "                                        \"time_unix_nano\": 1749653485854488000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 5.745627164840698,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 0.9523701667785645,\n",
      "                                        \"max\": 4.793256998062134,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559238000,\n",
      "                                        \"time_unix_nano\": 1749653485854488000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 5.745627164840698,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 0.9523701667785645,\n",
      "                                        \"max\": 4.793256998062134,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559759000,\n",
      "                                        \"time_unix_nano\": 1749653485854488000,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559799000,\n",
      "                                        \"time_unix_nano\": 1749653485854488000,\n",
      "                                        \"value\": 245,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559818000,\n",
      "                                        \"time_unix_nano\": 1749653485854488000,\n",
      "                                        \"value\": 826,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-mini-2024-07-18\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1749650493559840000,\n",
      "                                        \"time_unix_nano\": 1749653485854488000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0.00027089999999999997,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 3.645e-05,\n",
      "                                        \"max\": 0.00023444999999999998,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "\n",
    "# Initialize OpenLIT instrumentation\n",
    "import openlit\n",
    "openlit.init(tracer=langfuse._otel_tracer, disable_batch=True)\n",
    "\n",
    "# Create and configure the agent\n",
    "agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4o-mini\"),\n",
    "    tools=[DuckDuckGoTools()],\n",
    "    markdown=True,\n",
    "    debug_mode=True,\n",
    ")\n",
    "\n",
    "# Use the agent\n",
    "agent.print_response(\"What is currently trending on Twitter?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: See Traces in Langfuse\n",
    "\n",
    "After running the agent examples above, you can view the traces generated by your Agno agent in Langfuse. \n",
    "\n",
    "![Agno Agents OpenLit Instrumentation](https://langfuse.com/images/cookbook/integration-agno-agents/agno-agents-openlit.png)\n",
    "\n",
    "[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/080130871f53145aecf7c29d5dfb6e4c?timestamp=2025-06-11T14:01:32.598Z&display=details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Agno Langfuse Integration Docs](https://docs.agno.com/observability/langfuse)\n",
    "- [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

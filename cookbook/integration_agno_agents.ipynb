{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Observability for Agno with Langfuse\n",
    "description: Learn how to integrate Langfuse with Agno via OpenTelemetry using OpenInference or OpenLIT\n",
    "category: Integrations\n",
    "---\n",
    "\n",
    "# Integrate Langfuse with Agno\n",
    "\n",
    "This notebook demonstrates how to integrate **Langfuse** with **Agno** using OpenTelemetry via **OpenInference** or the **OpenLIT** SDK. By the end of this notebook, you will be able to trace your Agno applications with Langfuse for improved observability and debugging.\n",
    "\n",
    "> **What is Agno?** [Agno](https://docs.agno.com/) is a platform for building and managing AI agents.\n",
    "\n",
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source LLM engineering platform. It provides tracing and monitoring capabilities for LLM applications, helping developers debug, analyze, and optimize their AI systems. Langfuse integrates with various tools and frameworks via native integrations, OpenTelemetry, and API/SDKs.\n",
    "\n",
    "## Get Started\n",
    "\n",
    "We'll walk through examples of using Agno and integrating it with Langfuse.\n",
    "\n",
    "### Step 1: Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agno openai langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno yfinance openlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Up Environment Variables\n",
    "\n",
    "Set your Langfuse API keys and configure OpenTelemetry export settings to send traces to Langfuse. Please refer to the [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started) for more information on the Langfuse OpenTelemetry endpoint `/api/public/otel` and authentication.\n",
    "\n",
    "You'll also need your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
    "\n",
    "LANGFUSE_AUTH = base64.b64encode(\n",
    "    f\"{os.environ.get('LANGFUSE_PUBLIC_KEY')}:{os.environ.get('LANGFUSE_SECRET_KEY')}\".encode()\n",
    ").decode()\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = os.environ.get(\"LANGFUSE_HOST\") + \"/api/public/otel\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
    "\n",
    "# your openai key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Sending Traces to Langfuse\n",
    "\n",
    "#### Example 1: Using Langfuse with OpenInference\n",
    "\n",
    "This example demonstrates how to instrument your Agno agent with OpenInference and send traces to Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.yfinance import YFinanceTools\n",
    "from openinference.instrumentation.agno import AgnoInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "# Configure the tracer provider\n",
    "tracer_provider = TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "\n",
    "# Start instrumenting agno\n",
    "AgnoInstrumentor().instrument()\n",
    "\n",
    "# Create and configure the agent\n",
    "agent = Agent(\n",
    "    name=\"Stock Price Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-4o-mini\"),\n",
    "    tools=[YFinanceTools()],\n",
    "    instructions=\"You are a stock price agent. Answer questions in the style of a stock analyst.\",\n",
    "    debug_mode=True,\n",
    ")\n",
    "\n",
    "# Use the agent\n",
    "agent.print_response(\"What is the current price of Tesla?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Using Langfuse with OpenLIT\n",
    "\n",
    "This example demonstrates how to use Langfuse via OpenLIT to trace model calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "from opentelemetry import trace\n",
    "\n",
    "# Configure the tracer provider\n",
    "trace_provider = TracerProvider()\n",
    "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
    "trace.set_tracer_provider(trace_provider)\n",
    "\n",
    "# Initialize OpenLIT instrumentation\n",
    "import openlit\n",
    "openlit.init(tracer=trace.get_tracer(__name__), disable_batch=True)\n",
    "\n",
    "# Create and configure the agent\n",
    "agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4o-mini\"),\n",
    "    tools=[DuckDuckGoTools()],\n",
    "    markdown=True,\n",
    "    debug_mode=True,\n",
    ")\n",
    "\n",
    "# Use the agent\n",
    "agent.print_response(\"What is currently trending on Twitter?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: See Traces in Langfuse\n",
    "\n",
    "After running the agent examples above, you can view the traces generated by your Agno agent in Langfuse. \n",
    "\n",
    "**Openinference Instrumentation:**\n",
    "\n",
    "![Agno Agents OpenInference Instrumentation](https://langfuse.com/images/cookbook/integration-agno-agents/agno-agents-openinference.png)\n",
    "\n",
    "[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/8405ef8c640e146680d10f14560b0123?display=preview%3Ftimestamp%3D2025-05-26T12%3A04%3A55.692Z%3Ftimestamp%3D2025-05-26T12%3A04%3A33.072Z%3Ftimestamp%3D2025-05-26T12%3A04%3A55.692Z?timestamp=2025-05-26T12%3A04%3A33.072Z)\n",
    "\n",
    "**OpenLit Instrumentation:**\n",
    "\n",
    "![Agno Agents OpenLit Instrumentation](https://langfuse.com/images/cookbook/integration-agno-agents/agno-agents-openlit.png)\n",
    "\n",
    "[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/556248fcb1ab657d0dddbc200c690449?display=preview%3Ftimestamp%3D2025-05-26T12%3A04%3A55.692Z&observation=e16fdc48043554b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Agno Langfuse Integration Docs](https://docs.agno.com/observability/langfuse)\n",
    "- [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- NOTEBOOK_METADATA source: \"âš ï¸ Jupyter Notebook\" title: \"Observability for Anthropic with Langfuse Integration\" sidebarTitle: \"Anthropic\" logo: \"/images/integrations/anthropic_icon.png\" description: \"Learn how to integrate Langfuse with Anthropic for comprehensive tracing and debugging of your AI conversations.\" category: \"Integrations\" -->\n",
        "\n",
        "# Trace Anthropic Models in Langfuse\n",
        "\n",
        "Anthropic provides advanced language models like Claude, known for their safety, helpfulness, and strong reasoning capabilities. By combining Anthropic's models with **Langfuse**, you can trace, monitor, and analyze your AI workloads in development and production.\n",
        "\n",
        "This notebook demonstrates **two** different ways to use Anthropic models with Langfuse:\n",
        "1. **OpenTelemetry Instrumentation:** Use the [`AnthropicInstrumentor`](https://pypi.org/project/opentelemetry-instrumentation-anthropic/) library to wrap Anthropic SDK calls and send OpenTelemetry spans to Langfuse.\n",
        "2. **OpenAI SDK:** Use Anthropic's OpenAI-compatible endpoints via [Langfuse's OpenAI SDK wrapper](https://langfuse.com/integrations/model-providers/openai-py).\n",
        "\n",
        "> **What is Anthropic?**  \n",
        "Anthropic is an AI safety company that develops Claude, a family of large language models designed to be helpful, harmless, and honest. Claude models excel at complex reasoning, analysis, and creative tasks.\n",
        "\n",
        "> **What is Langfuse?**  \n",
        "[Langfuse](https://langfuse.com) is an open source platform for LLM observability and monitoring. It helps you trace and monitor your AI applications by capturing metadata, prompt details, token usage, latency, and more.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- STEPS_START -->\n",
        "## Step 1: Install Dependencies\n",
        "\n",
        "Before you begin, install the necessary packages in your Python environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install anthropic openai langfuse opentelemetry-instrumentation-anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configure Langfuse SDK\n",
        "\n",
        "Next, set up your Langfuse API keys. You can get these keys by signing up for a free [Langfuse Cloud](https://cloud.langfuse.com/) account or by [self-hosting Langfuse](https://langfuse.com/self-hosting). These environment variables are essential for the Langfuse client to authenticate and send data to your Langfuse project.\n",
        "\n",
        "Also set your Anthropic API ([Anthropic Console](https://console.anthropic.com/))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
        "\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-...\"  # Your Anthropic API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the environment variables set, we can now initialize the Langfuse client. `get_client()` initializes the Langfuse client using the credentials provided in the environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Langfuse client is authenticated and ready!\n"
          ]
        }
      ],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        " \n",
        "# Verify connection\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse client is authenticated and ready!\")\n",
        "else:\n",
        "    print(\"Authentication failed. Please check your credentials and host.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Approach 1: OpenTelemetry Instrumentation\n",
        "\n",
        "Use the [`AnthropicInstrumentor`](https://pypi.org/project/opentelemetry-instrumentation-anthropic/) library to wrap Anthropic SDK calls and send OpenTelemetry spans to Langfuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opentelemetry.instrumentation.anthropic import AnthropicInstrumentor\n",
        "\n",
        "AnthropicInstrumentor().instrument()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from anthropic import Anthropic\n",
        "\n",
        "# Initialize the Anthropic client\n",
        "client = Anthropic(\n",
        "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        ")\n",
        "\n",
        "# Make the API call to Anthropic\n",
        "message = client.messages.create(\n",
        "    model=\"claude-opus-4-20250514\",\n",
        "    max_tokens=1000,\n",
        "    temperature=1,\n",
        "    system=\"You are a world-class poet. Respond only with short poems.\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"Why is the ocean salty?\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "print(message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Approach 2: OpenAI SDK Drop-in Replacement\n",
        "\n",
        "Anthropic provides [OpenAI-compatible endpoints](https://docs.anthropic.com/en/api/openai-sdk) that allow you to use the OpenAI SDK to interact with Claude models. This is particularly useful if you have existing code using the OpenAI SDK that you want to switch to Claude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Langfuse OpenAI client\n",
        "from langfuse.openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),  # Your Anthropic API key\n",
        "    base_url=\"https://api.anthropic.com/v1/\"  # Anthropic's API endpoint\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"claude-opus-4-20250514\", # Anthropic model name\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who are you?\"}\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Traces in Langfuse\n",
        "\n",
        "After executing the application, navigate to your Langfuse Trace Table. You will find detailed traces of the application's execution, providing insights into the agent conversations, LLM calls, inputs, outputs, and performance metrics. \n",
        "\n",
        "![Langfuse Trace](https://langfuse.com/images/cookbook/integration_anthropic/anthropic-example-trace.png)\n",
        "\n",
        "You can also view the trace in Langfuse here: \n",
        "\n",
        "- [Approach 1: OpenTelemetry Instrumentation](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/308aca9bc430ad872d474fc545889ee2?timestamp=2025-07-25T07:35:01.172Z&display=details)\n",
        "- [Approach 2: OpenAI SDK](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/8e8da1b2c15036ed9c25b37c604f2d29?timestamp=2025-07-22T16:05:47.602Z&display=details)\n",
        "\n",
        "<!-- STEPS_END -->\n",
        "\n",
        "<!-- MARKDOWN_COMPONENT name: \"LearnMore\" path: \"@/components-mdx/integration-learn-more.mdx\" -->"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

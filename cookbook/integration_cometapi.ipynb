{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473eb32b",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"⚠️ Jupyter Notebook\" title: \"Monitor CometAPI with Langfuse\" sidebarTitle: \"CometAPI\" logo: \"/images/integrations/cometapi_icon.svg\" description: \"Learn how to integrate CometAPI with Langfuse using the OpenAI drop-in replacement.\" category: \"Integrations\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4950d7",
   "metadata": {},
   "source": [
    "# Observability for CometAPI with Langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f5b25",
   "metadata": {},
   "source": [
    "This guide shows you how to integrate CometAPI with Langfuse. CometAPI's API endpoints for chat, language and code are fully compatible with OpenAI's API. This allows us to use the Langfuse OpenAI drop-in replacement to trace all parts of your application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a90b5c",
   "metadata": {},
   "source": [
    "> **What is CometAPI?** [CometAPI](https://www.cometapi.com/?utm_source=langfuse&utm_campaign=integration&utm_medium=integration&utm_content=integration) is a unified AI model API platform providing access to 500+ AI models through a single OpenAI-compatible interface. Whether you need chat models, embeddings, or specialized AI capabilities, CometAPI offers affordable and reliable access with simple integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42428d1",
   "metadata": {},
   "source": [
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open source LLM engineering platform that helps teams trace API calls, monitor performance, and debug issues in their AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef948686",
   "metadata": {},
   "source": [
    "<!-- STEPS_START -->\n",
    "\n",
    "## Step 1: Install Dependencies\n",
    "\n",
    "Make sure you have installed the necessary Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f827409",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad32c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys for your project from the project settings page\n",
    "# https://cloud.langfuse.com\n",
    "\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-...\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # 🇪🇺 EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # 🇺🇸 US region\n",
    "\n",
    "\n",
    "# Get your CometAPI API key from https://api.cometapi.com/console/token\n",
    "os.environ[\"COMETAPI_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfefe5",
   "metadata": {},
   "source": [
    "## Step 3: Langfuse OpenAI drop-in Replacement\n",
    "\n",
    "In this step we use the native [OpenAI drop-in replacement](https://langfuse.com/integrations/model-providers/openai-py) by importing `from langfuse.openai import openai`.\n",
    "\n",
    "To start using CometAPI with OpenAI's client libraries, pass in your CometAPI API key to the `api_key` option, and change the `base_url` to `https://api.cometapi.com/v1/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of import openai:\n",
    "from langfuse.openai import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "  api_key=os.environ.get(\"COMETAPI_KEY\"),\n",
    "  base_url=\"https://api.cometapi.com/v1/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8686b73c",
   "metadata": {},
   "source": [
    "<!-- CALLOUT_START type: \"info\" emoji: \"ℹ️\" -->\n",
    "**Note:** The OpenAI drop-in replacement is fully compatible with the [Low-Level Langfuse Python SDKs](https://langfuse.com/docs/sdk/python/low-level-sdk) and [`@observe()` decorator](https://langfuse.com/docs/sdk/python/decorators) to trace all parts of your application.\n",
    "<!-- CALLOUT_END -->\n",
    "\n",
    "## Step 4: Run An Example\n",
    "\n",
    "The following cell demonstrates how to call CometAPI's chat model using the traced OpenAI client. All API calls will be automatically traced by Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5976d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "  api_key=os.environ.get(\"COMETAPI_KEY\"),\n",
    "  base_url=\"https://api.cometapi.com/v1/\",\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Act like you are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the famous attractions in San Francisco?\"},\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a284d12",
   "metadata": {},
   "source": [
    "## Step 5: See Traces in Langfuse\n",
    "\n",
    "After running the example model call, you can see the traces in Langfuse. You will see detailed information about your CometAPI API calls, including:\n",
    "\n",
    "- Request parameters (model, messages, temperature, etc.)\n",
    "- Response content\n",
    "- Token usage statistics\n",
    "- Latency metrics\n",
    "\n",
    "\n",
    "_Example trace link in Langfuse_\n",
    "\n",
    "<!-- STEPS_END -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99285863",
   "metadata": {},
   "source": [
    "<!-- MARKDOWN_COMPONENT name: \"LearnMore\" path: \"@/components-mdx/integration-learn-more.mdx\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31599b5e",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- Check the [CometAPI Documentation](https://api.cometapi.com/doc) for further details on available models and API options.\n",
    "- Visit [CometAPI](https://www.cometapi.com/?utm_source=langfuse&utm_campaign=integration&utm_medium=integration&utm_content=integration) to get your API key and explore 500+ AI models.\n",
    "- Visit [Langfuse](https://langfuse.com) to learn more about monitoring and tracing capabilities for your LLM applications."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

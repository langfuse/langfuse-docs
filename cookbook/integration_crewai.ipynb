{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Observability for CrewAI with Langfuse Integration\" sidebarTitle: \"CrewAI\" logo: \"/images/integrations/crewai_icon.svg\" description: \"Discover how to integrate Langfuse with CrewAI for enhanced LLM application monitoring, debugging, and tracing. Improve your AI development workflow today.\" category: \"Integrations\" -->\n",
        "\n",
        "# Integrate Langfuse with CrewAI\n",
        "\n",
        "This notebook provides a step-by-step guide on integrating **Langfuse** with **CrewAI** to achieve observability and debugging for your LLM applications.\n",
        "\n",
        "> **What is CrewAI?** [CrewAI](https://github.com/crewAIInc/crewAI) ([GitHub](https://github.com/crewAIInc/crewAI)) is a framework for orchestrating autonomous AI agents. CrewAI enables you to create AI teams where each agent has specific roles, tools, and goals, working together to accomplish complex tasks. Each member (agent) brings unique skills and expertise, collaborating seamlessly to achieve your objectives.\n",
        "\n",
        "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source LLM engineering platform. It offers tracing and monitoring capabilities for AI applications. Langfuse helps developers debug, analyze, and optimize their AI systems by providing detailed insights and integrating with a wide array of tools and frameworks through native integrations, OpenTelemetry, and dedicated SDKs.\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "Let's walk through a practical example of using CrewAI and integrating it with Langfuse for comprehensive tracing.\n",
        "\n",
        "<!-- STEPS_START -->\n",
        "### Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install langfuse crewai openinference-instrumentation-crewai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Configure Langfuse SDK\n",
        "\n",
        "Next, set up your Langfuse API keys. You can get these keys by signing up for a free [Langfuse Cloud](https://cloud.langfuse.com/) account or by [self-hosting Langfuse](https://langfuse.com/self-hosting). These environment variables are essential for the Langfuse client to authenticate and send data to your Langfuse project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-***\" \n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-***\" \n",
        "os.environ[\"LANGFUSE_BASE_URL\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
        "# os.environ[\"LANGFUSE_BASE_URL\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
        "\n",
        "# Your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-***\""
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "With the environment variables set, we can now initialize the Langfuse client. `get_client()` initializes the Langfuse client using the credentials provided in the environment variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langfuse import get_client\n",
        " \n",
        "langfuse = get_client()\n",
        " \n",
        "# Verify connection\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse client is authenticated and ready!\")\n",
        "else:\n",
        "    print(\"Authentication failed. Please check your credentials and host.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Initialize CrewAI Instrumentation\n",
        "\n",
        "Now, we initialize the [OpenInference instrumentation SDK](https://github.com/Arize-ai/openinference/tree/main/python/instrumentation/openinference-instrumentation-crewai) to automatically capture CrewAI operations and export OpenTelemetry (OTel) spans to Langfuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openinference.instrumentation.crewai import CrewAIInstrumentor\n",
        "\n",
        "CrewAIInstrumentor().instrument(skip_dep_check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Basic CrewAI Application\n",
        "\n",
        "Let's create a straightforward CrewAI application. In this example, we'll create a simple crew with agents that can collaborate to complete tasks. This will serve as the foundation for demonstrating Langfuse tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# Define your agents with roles and goals\n",
        "coder = Agent(\n",
        "    role='Software developer',\n",
        "    goal='Write clear, concise code on demand',\n",
        "    backstory='An expert coder with a keen eye for software trends.',\n",
        ")\n",
        "\n",
        "# Create tasks for your agents\n",
        "task1 = Task(\n",
        "    description=\"Define the HTML for making a simple website with heading- Hello World! Langfuse monitors your CrewAI agent!\",\n",
        "    expected_output=\"A clear and concise HTML code\",\n",
        "    agent=coder\n",
        ")\n",
        "\n",
        "# Instantiate your crew\n",
        "crew = Crew(\n",
        "    agents=[coder],\n",
        "    tasks=[task1],\n",
        ")\n",
        "\n",
        "with langfuse.start_as_current_observation(as_type=\"span\", name=\"crewai-index-trace\"):\n",
        "    result = crew.kickoff()\n",
        "    print(result)\n",
        "\n",
        "langfuse.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: View Traces in Langfuse\n",
        "\n",
        "After executing the application, navigate to your Langfuse Trace Table. You will find detailed traces of the application's execution, providing insights into the LLM calls, agent operations, inputs, outputs, and performance metrics. The trace will show the complete flow from task processing through agent collaboration to response generation.\n",
        "\n",
        "![CrewAI example trace in Langfuse](https://langfuse.com/images/cookbook/integration_crewai/crewai-example-trace.png)\n",
        "\n",
        "[Example Trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/a287bb31e317433610d8827617471140?timestamp=2025-07-11T07:45:13.601Z&display=details)\n",
        "<!-- STEPS_END -->\n",
        "\n",
        "<!-- MARKDOWN_COMPONENT name: \"LearnMore\" path: \"@/components-mdx/integration-learn-more.mdx\" -->"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

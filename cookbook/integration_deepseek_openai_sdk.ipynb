{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "description: Example cookbook on how to monitor DeepSeek models with Langfuse using the OpenAI SDK\n",
    "category: Integrations\n",
    "---\n",
    "\n",
    "# Cookbook: Monitor DeepSeek Models with Langfuse Using the OpenAI SDK\n",
    "\n",
    "The DeepSeek API uses an API format compatible with OpenAI. By modifying the configuration, you can use the OpenAI SDK or software compatible with the OpenAI API to access the DeepSeek API.\n",
    "\n",
    "This cookbook demonstrates how to monitor [DeepSeek](https://github.com/deepseek-ai/DeepSeek-V3) models using the OpenAI SDK integration with [Langfuse](https://langfuse.com). By leveraging Langfuse's observability tools and the OpenAI SDK, you can effectively debug, monitor, and evaluate your applications that utilize DeepSeek models.\n",
    "\n",
    "This guide will walk you through setting up the integration, making requests to DeepSeek models, and observing the interactions with Langfuse.\n",
    "\n",
    "**Note:** *Langfuse is also natively integrated with [LangChain](https://langfuse.com/docs/integrations/langchain/tracing), [LlamaIndex](https://langfuse.com/docs/integrations/llama-index/get-started), [LiteLLM](https://langfuse.com/docs/integrations/litellm/tracing), and [other frameworks](https://langfuse.com/docs/integrations/overview). These frameworks can be used as well to trace DeepSeek requests.*\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Install Required Packages\n",
    "\n",
    "To get started, install the necessary packages. Ensure you have the latest versions of `langfuse` and `openai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langfuse openai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Environment Variables\n",
    "\n",
    "Set up your environment variables with the necessary keys. Obtain your Langfuse project keys from [Langfuse Cloud](https://cloud.langfuse.com). You will also need an access token from [DeepSeek](https://platform.deepseek.com/api_keys) to access their models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys for your project from https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"  # ðŸ‡ºðŸ‡¸ US region\n",
    "\n",
    "# Your DeepSeek API key (get it from https://platform.deepseek.com/api_keys)\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-...\"  # Replace with your DeepSeek API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Modules\n",
    "\n",
    "Instead of importing `openai` directly, import it from `langfuse.openai`. Also, import any other necessary modules.\n",
    "\n",
    "Check out our [OpenAI integration docs](https://langfuse.com/docs/integrations/openai/python/get-started) to learn how to use this integration with other Langfuse [features](https://langfuse.com/docs/tracing#advanced-usage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of: import openai\n",
    "from langfuse.openai import OpenAI\n",
    "from langfuse.decorators import observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the OpenAI Client for DeepSeek Models\n",
    "\n",
    "Initialize the OpenAI client, pointing it to the DeepSeek model endpoint. Replace the model URL and APP key with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client, pointing it to the DeepSeek Inference API\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.deepseek.com\",  # Replace with the DeepSeek model endpoint URL\n",
    "    api_key=os.getenv('DEEPSEEK_API_KEY'),  # Replace with your DeepSeek API key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### Chat Completion Request\n",
    "\n",
    "Use the `client` to make a chat completion request to the DeepSeek model. The `model` parameter can be any identifier since the actual model is specified in the `base_url`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is cool because it automates tasks, enhances creativity, solves complex problems, and transforms industries with smart, efficient solutions.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Why is AI cool? Answer in 20 words or less.\"}\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration_deepseek/deepseek-simple-trace.png)\n",
    "\n",
    "*[View the example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/83702a6c-ae0e-4317-87fa-dc82568a2d89?timestamp=2025-01-09T17%3A06%3A40.848Z)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe the Request with Langfuse\n",
    "\n",
    "By using the `OpenAI` client from `langfuse.openai`, your requests are automatically traced in Langfuse. You can also use the `@observe()` decorator to group multiple generations into a single trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once, a tiny token named Lex set off to join a language model's grand library. Along the way, Lex got distracted by a shimmering metaphor and wandered into a syntax labyrinth. Lost among dangling modifiers and rogue commas, Lex cried for help. A friendly emoji spotted Lex and guided it back to the path. \"Stick to the vectors,\" the emoji advised. Lex finally arrived, a little wiser, and whispered its tale into the model's vast neural network. From then on, the model always paused to appreciate the journey of every token, no matter how small or lost.\n"
     ]
    }
   ],
   "source": [
    "@observe()  # Decorator to automatically create a trace and nest generations\n",
    "def generate_story():\n",
    "    completion = client.chat.completions.create(\n",
    "        name=\"story-generator\",\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a creative storyteller.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Tell me a short story about a token that got lost on its way to the language model. Answer in 100 words or less.\"}\n",
    "        ],\n",
    "        metadata={\"genre\": \"adventure\"},\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "story = generate_story()\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration_deepseek/deepseek-story-trace.png)\n",
    "\n",
    "*[View the example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/9a0dca39-9fac-4fce-ace9-52b85edfb0d8?timestamp=2025-01-09T17%3A08%3A25.698Z)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Additional Langfuse Features (User, Tags, Metadata, Session)\n",
    "\n",
    "You can enhance your traces by adding attributes such as `user_id`, `session_id`, `tags`, and `metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pythagorean theorem is a fundamental principle in geometry, stating that in a right-angled triangle, the square of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the other two sides. Mathematically, it's expressed as \\( a^2 + b^2 = c^2 \\), where \\( c \\) is the hypotenuse, and \\( a \\) and \\( b \\) are the other two sides. This theorem is useful for calculating distances, constructing shapes, and solving various real-world problems involving right triangles. It's named after the ancient Greek mathematician Pythagoras, who is credited with its discovery.\n"
     ]
    }
   ],
   "source": [
    "completion_with_attributes = client.chat.completions.create(\n",
    "    name=\"math-tutor\",  # Trace name\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a math tutor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Help me understand the Pythagorean theorem. Answer in 100 words or less.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    metadata={\"subject\": \"Mathematics\"},  # Trace metadata\n",
    "    tags=[\"education\", \"math\"],  # Trace tags\n",
    "    user_id=\"student_001\",  # Trace user ID\n",
    "    session_id=\"session_abc123\",  # Trace session ID\n",
    ")\n",
    "print(completion_with_attributes.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[View the example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e18ab6ff-7ad5-491b-87bf-571dd7854923?timestamp=2025-01-09T17%3A09%3A52.866Z)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize Langfuse Context to Update Trace Attributes\n",
    "\n",
    "You can modify trace attributes within a function using `langfuse_context`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blockchain is a decentralized digital ledger that records transactions across a network of computers. Each block contains data, a timestamp, and a cryptographic link to the previous block, ensuring security and transparency.\n"
     ]
    }
   ],
   "source": [
    "from langfuse.decorators import langfuse_context\n",
    "\n",
    "@observe()\n",
    "def technical_explanation():\n",
    "    # Your main application logic\n",
    "    response = client.chat.completions.create(\n",
    "        name=\"tech-explainer\",\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Explain how blockchain technology works. Answer in 30 words or less.\"}\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    # Update the current trace with additional information\n",
    "    langfuse_context.update_current_trace(\n",
    "        name=\"Blockchain Explanation\",\n",
    "        session_id=\"session_xyz789\",\n",
    "        user_id=\"user_tech_42\",\n",
    "        tags=[\"technology\", \"blockchain\"],\n",
    "        metadata={\"topic\": \"blockchain\", \"difficulty\": \"intermediate\"},\n",
    "        release=\"v1.0.0\",\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "result = technical_explanation()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[View the example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/06cca972-a885-454f-8303-0fd753dbf5e3?timestamp=2025-01-09T17%3A10%3A39.275Z)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatically Add Scores\n",
    "\n",
    "Add [scores](https://langfuse.com/docs/scores) to the trace to record user feedback or programmatic evaluations. In production the scoring usually happens in a separate function and can be accomplished by passing the `trace_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing leverages quantum mechanics to process information using qubits, which can exist in multiple states simultaneously. This enables solving complex problems faster than classical computers, particularly in cryptography, optimization, and simulations, by exploiting superposition, entanglement, and quantum interference.\n"
     ]
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()\n",
    "\n",
    "@observe()\n",
    "def generate_and_score():\n",
    "    # Get the trace_id of the current trace\n",
    "    trace_id = langfuse_context.get_current_trace_id()\n",
    "    \n",
    "    # Generate content\n",
    "    content = client.chat.completions.create(\n",
    "        name=\"content-generator\",\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"What is quantum computing? Answer in 50 words or less.\"}\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Evaluate content (placeholder function)\n",
    "    score_value = evaluate_content(content)\n",
    "    \n",
    "    # Add score to Langfuse\n",
    "    langfuse.score(\n",
    "        trace_id=trace_id,\n",
    "        name=\"content_quality\",\n",
    "        value=score_value,\n",
    "    )\n",
    "    \n",
    "    return content\n",
    "\n",
    "def evaluate_content(content):\n",
    "    # Placeholder evaluation function (e.g., content length or keyword presence)\n",
    "    return 9.0  # Score out of 10\n",
    "\n",
    "output = generate_and_score()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[View the example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/44616768-253d-41fd-b336-8611899a2fad?timestamp=2025-01-09T17%3A11%3A01.665Z)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn More\n",
    "\n",
    "- **[Langfuse Documentation](https://langfuse.com/docs)**: Explore the full capabilities of Langfuse and learn how to utilize advanced features.\n",
    "- **[Langfuse Integrations](https://langfuse.com/docs/integrations)**: Discover other integrations and examples.\n",
    "- **[DeepSeek GitHub Repository](https://github.com/deepseek-ai/DeepSeek-V3)**: Learn more about DeepSeek models and access additional resources.\n",
    "\n",
    "## Feedback\n",
    "\n",
    "If you have any feedback or requests, please create an issue on [GitHub](https://github.com/langfuse/langfuse/issues) or share your ideas with the community on [Discord](https://langfuse.com/discord)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"⚠️ Jupyter Notebook\" title: \"Integrate Fireworks AI with Langfuse\" sidebarTitle: \"Fireworks AI\" logo: \"/images/integrations/fireworks_ai_icon.svg\" description: \"Guide on using Fireworks AI's open-source and proprietary AI models with Langfuse via the OpenAI SDK.\" category: \"Integrations\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observability for Fireworks AI with Langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide shows you how to integrate Fireworks AI with Langfuse. Fireworks AI's API endpoints are fully [compatible](https://docs.fireworks.ai/tools-sdks/openai-compatibility) with the OpenAI SDK, allowing you to trace and monitor your AI applications seamlessly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What is Fireworks AI?** [Fireworks AI](https://fireworks.ai/) is a platform that provides API access to state-of-the-art open-source and proprietary AI models with OpenAI-compatible endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open source LLM engineering platform that helps teams trace API calls, monitor performance, and debug issues in their AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- STEPS_START -->\n",
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys for your project from the project settings page\n",
    "# https://cloud.langfuse.com\n",
    "\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # 🇪🇺 EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # 🇺🇸 US region\n",
    "\n",
    "# Set your Fireworks API details\n",
    "os.environ[\"FIREWORKS_AI_API_BASE\"] = \"https://api.fireworks.ai/inference/v1\"\n",
    "os.environ[\"FIREWORKS_AI_API_KEY\"] = \"fw_...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use Langfuse OpenAI Drop-in Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import openai\n",
    "\n",
    "client = openai.OpenAI(\n",
    "  api_key=os.environ.get(\"FIREWORKS_AI_API_KEY\"),\n",
    "  base_url=os.environ.get(\"FIREWORKS_AI_API_BASE\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run an Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Why is open source important?\"},\n",
    "  ],\n",
    "  name = \"Fireworks-AI-Trace\" # name of the trace\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: See Traces in Langfuse\n",
    "\n",
    "After running the example, log in to Langfuse to view the detailed traces, including:\n",
    "\n",
    "- Request parameters\n",
    "- Response content\n",
    "- Token usage and latency metrics\n",
    "\n",
    "![Langfuse Trace Example](https://langfuse.com/images/cookbook/integration-fireworks-ai/fireworks-ai-example-trace.png)\n",
    "\n",
    "_[Public example trace link in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/2c11b0e4-eb40-49de-aee9-2ed11bed2839?timestamp=2025-03-05T13%3A31%3A34.781Z&observation=e9668bb4-29d7-4239-87be-e3019480f71f)_\n",
    "<!-- STEPS_END -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- MARKDOWN_COMPONENT name: \"LearnMore\" path: \"@/components-mdx/integration-learn-more.mdx\" -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "description: Cookbook with examples of the Langfuse Integration for Groq SDK (Python).\n",
    "category: Integrations\n",
    "---\n",
    "\n",
    "# Cookbook: Groq SDK Integration (Python)\n",
    "\n",
    "This cookbook provides step-by-step examples of integrating Langfuse with the Groq SDK in Python. By following these examples, you'll learn how to log and trace interactions with Groq language models, enabling you to debug and evaluate the performance of your AI-driven applications.\n",
    "\n",
    "**Note:** *Langfuse is also natively integrated with [LangChain](https://langfuse.com/docs/integrations/langchain/tracing), [LlamaIndex](https://langfuse.com/docs/integrations/llama-index/get-started), [LiteLLM](https://langfuse.com/docs/integrations/litellm/tracing), and [other frameworks](https://langfuse.com/docs/integrations/overview). If you use one of them, any use of Groq models is instrumented right away.*\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we will explore various use cases where Langfuse can be integrated with the Groq SDK, including:\n",
    "\n",
    "- **Basic LLM Calls:** Learn how to wrap standard Groq model interactions with Langfuse's `@observe` decorator for comprehensive logging.\n",
    "- **Chained Function Calls:** See how to manage and observe complex workflows where multiple model interactions are linked together to produce a final result.\n",
    "- **Streaming Support:** Discover how to use Langfuse with streaming responses from Groq models, ensuring that real-time interactions are fully traceable.\n",
    "\n",
    "For more detailed guidance on the Groq SDK or the **`@observe`** decorator from Langfuse, please refer to the [Groq Documentation](https://console.groq.com/docs) and the [Langfuse Documentation](https://langfuse.com/docs/sdk/python/decorators#log-any-llm-call).\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install groq langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Set up your environment variables for Langfuse and Groq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys for your project from https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" # Docs Example\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" # Docs Example\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # 游쀯릖 EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"  # 游쥟릖 US region\n",
    "\n",
    "# Your Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"gsk_...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Groq client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "# Initialize Groq client\n",
    "groq_client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### Basic LLM Calls\n",
    "\n",
    "We are integrating the Groq SDK with Langfuse using the [`@observe` decorator](https://langfuse.com/docs/sdk/python/decorators), which is crucial for logging and tracing interactions with large language models (LLMs). The `@observe(as_type=\"generation\")` decorator specifically logs LLM interactions, capturing inputs, outputs, and model parameters. The resulting `groq_chat_completion` method can then be used across your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "# Function to handle Groq chat completion calls, wrapped with @observe to log the LLM interaction\n",
    "@observe(as_type=\"generation\")\n",
    "def groq_chat_completion(**kwargs):\n",
    "    # Clone kwargs to avoid modifying the original input\n",
    "    kwargs_clone = kwargs.copy()\n",
    "\n",
    "    # Extract relevant parameters from kwargs\n",
    "    messages = kwargs_clone.pop('messages', None)\n",
    "    model = kwargs_clone.pop('model', None)\n",
    "    temperature = kwargs_clone.pop('temperature', None)\n",
    "    max_tokens = kwargs_clone.pop('max_tokens', None)\n",
    "    top_p = kwargs_clone.pop('top_p', None)\n",
    "\n",
    "    # Filter and prepare model parameters for logging\n",
    "    model_parameters = {\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p\n",
    "    }\n",
    "    model_parameters = {k: v for k, v in model_parameters.items() if v is not None}\n",
    "\n",
    "    # Log the input and model parameters before calling the LLM\n",
    "    langfuse_context.update_current_observation(\n",
    "        input=messages,\n",
    "        model=model,\n",
    "        model_parameters=model_parameters,\n",
    "        metadata=kwargs_clone,\n",
    "    )\n",
    "\n",
    "    # Call the Groq model to generate a response\n",
    "    response = groq_client.chat.completions.create(**kwargs)\n",
    "\n",
    "    # Log the usage details and output content after the LLM call\n",
    "    choice = response.choices[0]\n",
    "    langfuse_context.update_current_observation(\n",
    "        usage_details={\n",
    "            \"input\": len(str(messages)),\n",
    "            \"output\": len(choice.message.content)\n",
    "        },\n",
    "        output=choice.message.content\n",
    "    )\n",
    "\n",
    "    # Return the model's response object\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Example\n",
    "\n",
    "In the following example, we also added the decorator to the top-level function `find_best_painter_from`. This function calls the `groq_chat_completion` function, which is decorated with `@observe(as_type=\"generation\")`. This hierarchical setup helps to trace more complex applications that involve multiple LLM calls and other non-LLM methods decorated with `@observe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Monet, a founder of Impressionism, is often considered the best painter from France.\n"
     ]
    }
   ],
   "source": [
    "@observe()\n",
    "def find_best_painter_from(country=\"France\"):\n",
    "    response = groq_chat_completion(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        max_tokens=1024,\n",
    "        temperature=0.4,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Who is the best painter from {country}? Answer in one short sentence.\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(find_best_painter_from())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration-groq/single-trace-example.png)\n",
    "\n",
    "*[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/d5f7e896-a51c-4f70-b066-114f0cab9020?timestamp=2025-01-09T10%3A23%3A26.872Z&observation=3dee4a0f-e348-481f-a795-d46c90ffbea5)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chained Completions\n",
    "\n",
    "This example demonstrates chaining multiple LLM calls using the `@observe()` decorator. The first call identifies the best painter from a specified country, and the second call uses that painter's name to find their most famous painting. Both interactions are logged by Langfuse as we use the wrapped `groq_chat_completion` method created above, ensuring full traceability across the chained requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albrecht D칲rer's most famous painting is \"Melencolia I\" (1514), a complex and enigmatic work that is widely regarded as one of the most iconic and influential prints of the Renaissance.\n"
     ]
    }
   ],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "@observe()\n",
    "def find_best_painting_from(country=\"France\"):\n",
    "    response = groq_chat_completion(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        max_tokens=1024,\n",
    "        temperature=0.1,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Who is the best painter from {country}? Only provide the name.\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    painter_name = response.choices[0].message.content.strip()\n",
    "\n",
    "    response = groq_chat_completion(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"What is the most famous painting of {painter_name}? Answer in one short sentence.\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(find_best_painting_from(\"Germany\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration-groq/chained-trace.png)\n",
    "\n",
    "*[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/5913c996-84b4-4f75-9043-8db81dd4d0a4?timestamp=2025-01-09T10%3A23%3A42.893Z)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Completions\n",
    "\n",
    "The following example demonstrates how to handle streaming responses from the Groq model using the `@observe(as_type=\"generation\")` decorator. The process is similar to the completion example but includes handling streamed data in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "@observe(as_type=\"generation\")\n",
    "def stream_groq_chat_completion(**kwargs):\n",
    "    kwargs_clone = kwargs.copy()\n",
    "    messages = kwargs_clone.pop('messages', None)\n",
    "    model = kwargs_clone.pop('model', None)\n",
    "    temperature = kwargs_clone.pop('temperature', None)\n",
    "    max_tokens = kwargs_clone.pop('max_tokens', None)\n",
    "    top_p = kwargs_clone.pop('top_p', None)\n",
    "\n",
    "    model_parameters = {\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p\n",
    "    }\n",
    "    model_parameters = {k: v for k, v in model_parameters.items() if v is not None}\n",
    "\n",
    "    langfuse_context.update_current_observation(\n",
    "        input=messages,\n",
    "        model=model,\n",
    "        model_parameters=model_parameters,\n",
    "        metadata=kwargs_clone,\n",
    "    )\n",
    "\n",
    "    stream = groq_client.chat.completions.create(stream=True, **kwargs)\n",
    "    final_response = \"\"\n",
    "    for chunk in stream:\n",
    "        content = str(chunk.choices[0].delta.content)\n",
    "        final_response += content\n",
    "        yield content\n",
    "\n",
    "    langfuse_context.update_current_observation(\n",
    "        usage_details={\n",
    "            \"total_tokens\": len(final_response.split())\n",
    "        },\n",
    "        output=final_response\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a great question! Spain has a rich artistic heritage, and choosing just five painters is a challenge. However, here's a list of five of the most renowned Spanish painters, along with their most famous works:\n",
      "\n",
      "1. **Diego Vel치zquez** (1599-1660)\n",
      "\t* Most famous painting: \"Las Meninas\" (1656) - a masterpiece of Baroque art, showcasing the Spanish royal family and the artist himself.\n",
      "\n",
      "2. **Pablo Picasso** (1881-1973)\n",
      "\t* Most famous painting: \"Guernica\" (1937) - a powerful anti-war artwork responding to the bombing of the town of Guernica during the Spanish Civil War.\n",
      "\n",
      "3. **El Greco** (1541-1614)\n",
      "\t* Most famous painting: \"The Burial of the Count of Orgaz\" (1588) - a stunning example of Mannerist art, blending Spanish and Greek influences.\n",
      "\n",
      "4. **Francisco Goya** (1746-1828)\n",
      "\t* Most famous painting: \"The Third of May 1808\" (1814) - a haunting depiction of the brutal suppression of a rebellion against Napoleon's army.\n",
      "\n",
      "5. **Joan Mir칩** (1893-1983)\n",
      "\t* Most famous painting: \"The Birth of the World\" (1925) - a seminal work of Surrealist art, showcasing the artist's unique blend of abstract forms and vibrant colors.\n",
      "\n",
      "These five painters have not only contributed significantly to the development of Spanish art but also left an indelible mark on the global art scene.None"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What a great question! Spain has a rich artistic heritage, and choosing just five painters is a challenge. However, here\\'s a list of five of the most renowned Spanish painters, along with their most famous works:\\n\\n1. **Diego Vel치zquez** (1599-1660)\\n\\t* Most famous painting: \"Las Meninas\" (1656) - a masterpiece of Baroque art, showcasing the Spanish royal family and the artist himself.\\n\\n2. **Pablo Picasso** (1881-1973)\\n\\t* Most famous painting: \"Guernica\" (1937) - a powerful anti-war artwork responding to the bombing of the town of Guernica during the Spanish Civil War.\\n\\n3. **El Greco** (1541-1614)\\n\\t* Most famous painting: \"The Burial of the Count of Orgaz\" (1588) - a stunning example of Mannerist art, blending Spanish and Greek influences.\\n\\n4. **Francisco Goya** (1746-1828)\\n\\t* Most famous painting: \"The Third of May 1808\" (1814) - a haunting depiction of the brutal suppression of a rebellion against Napoleon\\'s army.\\n\\n5. **Joan Mir칩** (1893-1983)\\n\\t* Most famous painting: \"The Birth of the World\" (1925) - a seminal work of Surrealist art, showcasing the artist\\'s unique blend of abstract forms and vibrant colors.\\n\\nThese five painters have not only contributed significantly to the development of Spanish art but also left an indelible mark on the global art scene.None'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@observe()\n",
    "def stream_find_best_five_painter_from(country=\"France\"):\n",
    "    response_chunks = stream_groq_chat_completion(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Who are the best five painters from {country}? Give me a list of names and their most famous painting.\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    final_response = \"\"\n",
    "    for chunk in response_chunks:\n",
    "        final_response += str(chunk)\n",
    "        print(chunk, end=\"\")\n",
    "\n",
    "    return final_response\n",
    "\n",
    "stream_find_best_five_painter_from(\"Spain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration-groq/streaming-trace.png)\n",
    "\n",
    "*[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/c21544f3-d837-4441-9a0c-a47b3fd5dcaf?timestamp=2025-01-09T13%3A02%3A14.362Z&observation=c0d9e820-377c-4c4d-b6cb-19dd6951bfa4)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "If you have any feedback or requests, please create a GitHub [Issue](https://langfuse.com/issue) or share your ideas with the community on [Discord](https://langfuse.com/discord)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

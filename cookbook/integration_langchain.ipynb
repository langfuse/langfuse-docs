{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlceIPalN3QR"
      },
      "source": [
        "---\n",
        "description: Cookbook with examples of the Langfuse Integration for Langchain (Python).\n",
        "category: Integrations\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqBspBzuRk9C"
      },
      "source": [
        "# Cookbook: Langchain Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1oaA7XYGOfX"
      },
      "source": [
        "This is a cookbook with examples of the Langfuse Integration for Langchain (Python).\n",
        "\n",
        "Follow the [integration guide](https://langfuse.com/integrations/frameworks/langchain) to add this integration to your Langchain project. The integration also supports Langchain JS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbSpd5EiZouE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNyU6IzCZouE",
        "outputId": "234c71fb-f822-4b48-f4c0-94efe5f79305"
      },
      "outputs": [],
      "source": [
        "%pip install langfuse langchain langchain_openai langchain_community --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpE57ujJZouE"
      },
      "source": [
        "Initialize the Langfuse client with your API keys from the project settings in the Langfuse UI and add them to your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dEdF-668ZouF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
        "\n",
        "# Your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-..\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "divRadPqZouF"
      },
      "outputs": [],
      "source": [
        "from langfuse.langchain import CallbackHandler\n",
        " \n",
        "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
        "langfuse_handler = CallbackHandler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZXRf2FZXEXV"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvRWPsZ-NoAr"
      },
      "source": [
        "### Sequential Chain in Langchain Expression Language (LCEL)\n",
        "\n",
        "![Trace of Langchain LCEL](https://langfuse.com/images/cookbook/integration_langchain/langchain_LCEL.png)\n",
        "\n",
        "[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/dbe646b2b67957d22e8780c429b2d20f?timestamp=2025-06-11T09%3A09%3A58.823Z&display=details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3-HEia6gNoAr",
        "outputId": "ab223b99-4719-420c-ffe7-5444e4b67806"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Barack Obama es de la ciudad de Chicago, Illinois, en los Estados Unidos.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "prompt1 = ChatPromptTemplate.from_template(\"what is the city {person} is from?\")\n",
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"what country is the city {city} in? respond in {language}\"\n",
        ")\n",
        "model = ChatOpenAI()\n",
        "chain1 = prompt1 | model | StrOutputParser()\n",
        "chain2 = (\n",
        "    {\"city\": chain1, \"language\": itemgetter(\"language\")}\n",
        "    | prompt2\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain2.invoke({\"person\": \"obama\", \"language\": \"spanish\"}, config={\"callbacks\":[langfuse_handler]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlBSpILFXEXV"
      },
      "source": [
        "#### Runnable methods\n",
        "\n",
        "Runnables are units of work that can be invoked, batched, streamed, transformed and composed.\n",
        "\n",
        "The examples below show how to use the following methods with Langfuse:\n",
        "\n",
        "- invoke/ainvoke: Transforms a single input into an output.\n",
        "- batch/abatch: Efficiently transforms multiple inputs into outputs.\n",
        "- stream/astream: Streams output from a single input as itâ€™s produced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8N8pybGXEXV",
        "outputId": "df6d23fc-ed65-4fd2-d0d6-3b9f97e3a497"
      },
      "outputs": [],
      "source": [
        "# Async Invoke\n",
        "await chain2.ainvoke({\"person\": \"biden\", \"language\": \"german\"}, config={\"callbacks\":[langfuse_handler]})\n",
        "\n",
        "# Batch\n",
        "chain2.batch([{\"person\": \"elon musk\", \"language\": \"english\"}, {\"person\": \"mark zuckerberg\", \"language\": \"english\"}], config={\"callbacks\":[langfuse_handler]})\n",
        "\n",
        "# Async Batch\n",
        "await chain2.abatch([{\"person\": \"jeff bezos\", \"language\": \"english\"}, {\"person\": \"tim cook\", \"language\": \"english\"}], config={\"callbacks\":[langfuse_handler]})\n",
        "\n",
        "# Stream\n",
        "for chunk in chain2.stream({\"person\": \"steve jobs\", \"language\": \"english\"}, config={\"callbacks\":[langfuse_handler]}):\n",
        "    print(\"Streaming chunk:\", chunk)\n",
        "\n",
        "# Async Stream\n",
        "async for chunk in chain2.astream({\"person\": \"bill gates\", \"language\": \"english\"}, config={\"callbacks\":[langfuse_handler]}):\n",
        "    print(\"Async Streaming chunk:\", chunk)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5avhNb3TBH"
      },
      "source": [
        "### RetrievalQA\n",
        "\n",
        "![Trace of Langchain QA Retrieval in Langfuse](https://langfuse.com/images/cookbook/integration_langchain/langchain_qa_retrieval.png)\n",
        "\n",
        "[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/84e1ac07dedbce3b2a236b6ece6950d9?timestamp=2025-06-11T09:29:10.248Z&display=details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wjiWEkRUFzCf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0CgEPSlEpkC",
        "outputId": "36c800af-025d-407e-eca1-c215bba62cd2"
      },
      "outputs": [],
      "source": [
        "%pip install unstructured selenium langchain-chroma --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "kHDVa-Ssb-KT",
        "outputId": "efab8170-76b9-412e-c086-365a16f065a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'What did the president say about Ketanji Brown Jackson',\n",
              " 'result': \" The president nominated her to serve on the United States Supreme Court and praised her as one of the nation's top legal minds who will continue the legacy of retiring Justice Stephen Breyer.\"}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import SeleniumURLLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/langfuse/langfuse-docs/main/public/state_of_the_union.txt\",\n",
        "]\n",
        "loader = SeleniumURLLoader(urls=urls)\n",
        "llm = OpenAI()\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = Chroma.from_documents(texts, embeddings)\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 1}),\n",
        ")\n",
        "\n",
        "chain.invoke(query, config={\"callbacks\":[langfuse_handler]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIxwkX9p1ZR7"
      },
      "source": [
        "### AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b43rIMig1ZR7"
      },
      "outputs": [],
      "source": [
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"<Azure OpenAI endpoint>\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"<Azure OpenAI API key>\"\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2023-09-01-preview\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lLdPwnr1ZR7"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langfuse.langchain import CallbackHandler\n",
        " \n",
        "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"what is the city {person} is from?\")\n",
        "model = AzureChatOpenAI(\n",
        "    deployment_name=\"gpt-4o\",\n",
        "    model_name=\"gpt-4o\",\n",
        ")\n",
        "chain = prompt | model\n",
        "\n",
        "chain.invoke({\"person\": \"Satya Nadella\"}, config={\"callbacks\":[langfuse_handler]})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

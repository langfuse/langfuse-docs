{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: LibreChat Observability with Langfuse Tracing\n",
    "sidebarTitle: LibreChat\n",
    "description: Add LLM observability to LibreChat with Langfuse tracing to monitor conversations, debug issues, and analyze model performance\n",
    "category: Integrations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace LibreChat with Langfuse\n",
    "\n",
    "This guide shows you how to integrate [Langfuse](https://langfuse.com) tracing with [LibreChat](https://www.librechat.ai/) to get full observability into your AI conversations.\n",
    "\n",
    "## What is LibreChat?\n",
    "\n",
    "[LibreChat](https://github.com/danny-avila/LibreChat) is an open-source AI chat platform that brings together multiple AI providers (OpenAI, Anthropic, Google, Azure, and more) into a unified interface. It offers features like:\n",
    "\n",
    "- Multi-model support with a single interface\n",
    "- AI Agents with tool/function calling capabilities\n",
    "- Conversation branching and editing\n",
    "- Plugin system for extended functionality\n",
    "- Self-hosted deployment options\n",
    "\n",
    "## What is Langfuse?\n",
    "\n",
    "[Langfuse](https://github.com/langfuse/langfuse) is an open-source LLM engineering platform that provides:\n",
    "\n",
    "- **Tracing**: Capture detailed logs of LLM calls, including inputs, outputs, latencies, and token usage\n",
    "- **Analytics**: Analyze usage patterns, costs, and performance metrics\n",
    "- **Prompt Management**: Version and manage prompts across your applications\n",
    "- **Evaluations**: Score and evaluate LLM outputs\n",
    "\n",
    "## Why Integrate Langfuse with LibreChat?\n",
    "\n",
    "By integrating Langfuse with LibreChat, you can:\n",
    "\n",
    "1. **Monitor all AI conversations** - Track every message exchange, model response, and agent action\n",
    "2. **Debug issues** - Identify problems in agent reasoning, tool calls, or model responses\n",
    "3. **Analyze costs** - Monitor token usage and costs across different models\n",
    "4. **Improve performance** - Identify slow responses and optimize your setup\n",
    "5. **Track user sessions** - Correlate traces with specific users and conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before you begin, ensure you have:\n",
    "\n",
    "1. A running LibreChat instance (see [LibreChat Installation Guide](https://www.librechat.ai/docs/installation))\n",
    "2. A Langfuse account ([sign up for free](https://cloud.langfuse.com))\n",
    "3. Langfuse API keys from your project settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get Your Langfuse API Keys\n",
    "\n",
    "1. Log in to [Langfuse Cloud](https://cloud.langfuse.com) or your self-hosted Langfuse instance\n",
    "2. Navigate to your project (or create a new one)\n",
    "3. Go to **Settings** → **API Keys**\n",
    "4. Create a new API key pair and note down:\n",
    "   - `LANGFUSE_PUBLIC_KEY`\n",
    "   - `LANGFUSE_SECRET_KEY`\n",
    "\n",
    "You'll also need your Langfuse host URL:\n",
    "- **EU Region**: `https://cloud.langfuse.com`\n",
    "- **US Region**: `https://us.cloud.langfuse.com`\n",
    "- **Self-hosted**: Your custom Langfuse URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure LibreChat Environment Variables\n",
    "\n",
    "LibreChat uses environment variables for configuration. Add the following Langfuse-related variables to your `.env` file in your LibreChat installation directory:\n",
    "\n",
    "```bash\n",
    "# Langfuse Configuration\n",
    "LANGFUSE_PUBLIC_KEY=pk-lf-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n",
    "LANGFUSE_SECRET_KEY=sk-lf-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n",
    "LANGFUSE_BASE_URL=https://cloud.langfuse.com\n",
    "```\n",
    "\n",
    "### Environment Variable Reference\n",
    "\n",
    "| Variable | Description | Required |\n",
    "|----------|-------------|----------|\n",
    "| `LANGFUSE_PUBLIC_KEY` | Your Langfuse public API key | Yes |\n",
    "| `LANGFUSE_SECRET_KEY` | Your Langfuse secret API key | Yes |\n",
    "| `LANGFUSE_BASE_URL` | Langfuse API endpoint URL | Yes |\n",
    "\n",
    "> **Note**: For self-hosted Langfuse instances, set `LANGFUSE_BASE_URL` to your custom URL (e.g., `http://localhost:3000` for local development)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Restart LibreChat\n",
    "\n",
    "After adding the environment variables, restart your LibreChat instance to apply the changes.\n",
    "\n",
    "### Docker Compose\n",
    "\n",
    "If you're running LibreChat with Docker Compose:\n",
    "\n",
    "```bash\n",
    "docker compose down\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "### Local Development\n",
    "\n",
    "If you're running LibreChat locally:\n",
    "\n",
    "```bash\n",
    "# Stop the running instance (Ctrl+C)\n",
    "# Then restart\n",
    "npm run backend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Verify the Integration\n",
    "\n",
    "Once LibreChat is restarted with Langfuse configured:\n",
    "\n",
    "1. Open your LibreChat interface\n",
    "2. Start a new conversation with any AI model\n",
    "3. Send a few messages to generate traces\n",
    "4. Open your Langfuse dashboard\n",
    "5. Navigate to **Traces** to see your LibreChat conversations\n",
    "\n",
    "You should see traces appearing with details about:\n",
    "- Model used\n",
    "- Input messages\n",
    "- Output responses\n",
    "- Token usage\n",
    "- Latency metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Traces in Langfuse\n",
    "\n",
    "LibreChat sends traces to Langfuse with the following structure:\n",
    "\n",
    "### Trace Metadata\n",
    "\n",
    "Each trace includes:\n",
    "\n",
    "- **Run Name**: Identifies the type of operation (e.g., `AgentRun`, `MemoryRun`)\n",
    "- **Thread ID**: The LibreChat conversation ID, allowing you to group messages from the same conversation\n",
    "- **User ID**: The LibreChat user ID, enabling user-level analytics\n",
    "\n",
    "### Agent Traces\n",
    "\n",
    "When using LibreChat's AI Agents feature, traces capture:\n",
    "\n",
    "- Agent reasoning steps\n",
    "- Tool/function calls and their results\n",
    "- Multi-turn conversation context\n",
    "- Model switching within agent workflows\n",
    "\n",
    "### Memory Traces\n",
    "\n",
    "LibreChat's memory system also generates traces, allowing you to:\n",
    "\n",
    "- Monitor memory retrieval operations\n",
    "- Debug context injection issues\n",
    "- Analyze memory-related latencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Langfuse Features with LibreChat\n",
    "\n",
    "### Filter Traces by Conversation\n",
    "\n",
    "Use the `thread_id` (conversation ID) to filter traces for a specific conversation:\n",
    "\n",
    "1. In Langfuse, go to **Traces**\n",
    "2. Use the filter: `Metadata → thread_id = <your-conversation-id>`\n",
    "3. View all traces from that conversation in chronological order\n",
    "\n",
    "### Filter Traces by User\n",
    "\n",
    "To analyze traces for a specific LibreChat user:\n",
    "\n",
    "1. In Langfuse, go to **Traces**\n",
    "2. Use the filter: `User ID = <librechat-user-id>`\n",
    "3. View all conversations and interactions for that user\n",
    "\n",
    "### Analyze Costs\n",
    "\n",
    "Langfuse automatically calculates costs based on token usage:\n",
    "\n",
    "1. Go to **Analytics** → **Dashboard**\n",
    "2. View cost breakdowns by model, user, or time period\n",
    "3. Set up alerts for cost thresholds\n",
    "\n",
    "### Monitor Performance\n",
    "\n",
    "Track latency and performance metrics:\n",
    "\n",
    "1. Go to **Analytics** → **Dashboard**\n",
    "2. View latency distributions across models\n",
    "3. Identify slow responses or timeout issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Viewing a Trace\n",
    "\n",
    "Here's what a typical LibreChat trace looks like in Langfuse:\n",
    "\n",
    "```\n",
    "AgentRun\n",
    "├── thread_id: conv_abc123\n",
    "├── user_id: user_xyz789\n",
    "├── LLM Call (gpt-4)\n",
    "│   ├── Input: [system message, user message]\n",
    "│   ├── Output: [assistant response]\n",
    "│   ├── Tokens: 150 input, 200 output\n",
    "│   └── Latency: 2.3s\n",
    "└── Tool Calls (if applicable)\n",
    "    ├── web_search\n",
    "    └── code_interpreter\n",
    "```\n",
    "\n",
    "This hierarchical view helps you understand the full execution flow of each conversation turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Hosted Langfuse Setup\n",
    "\n",
    "If you prefer to self-host both LibreChat and Langfuse, you can run them together using Docker Compose.\n",
    "\n",
    "### Running Langfuse Locally\n",
    "\n",
    "1. Clone the Langfuse repository:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/langfuse/langfuse.git\n",
    "cd langfuse\n",
    "```\n",
    "\n",
    "2. Start Langfuse with Docker Compose:\n",
    "\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "3. Access Langfuse at `http://localhost:3000`\n",
    "\n",
    "4. Create a project and get your API keys\n",
    "\n",
    "5. Update your LibreChat `.env`:\n",
    "\n",
    "```bash\n",
    "LANGFUSE_BASE_URL=http://localhost:3000\n",
    "```\n",
    "\n",
    "For production self-hosted deployments, refer to the [Langfuse Self-Hosting Guide](https://langfuse.com/self-hosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Traces Not Appearing\n",
    "\n",
    "If traces are not appearing in Langfuse:\n",
    "\n",
    "1. **Verify environment variables**: Ensure all three Langfuse variables are set correctly\n",
    "2. **Check API keys**: Confirm your public and secret keys are valid and from the same project\n",
    "3. **Check network connectivity**: Ensure LibreChat can reach the Langfuse API endpoint\n",
    "4. **Review logs**: Check LibreChat logs for any Langfuse-related errors\n",
    "\n",
    "```bash\n",
    "# For Docker deployments\n",
    "docker compose logs -f api\n",
    "```\n",
    "\n",
    "### Missing Trace Data\n",
    "\n",
    "If traces appear but are missing data:\n",
    "\n",
    "1. Ensure you're using a recent version of LibreChat with Langfuse support\n",
    "2. Check that the `@librechat/agents` package is at version 2.4.89 or higher\n",
    "\n",
    "### High Latency\n",
    "\n",
    "If you notice increased latency after enabling Langfuse:\n",
    "\n",
    "1. Traces are sent asynchronously and should not impact response times\n",
    "2. If issues persist, check your network latency to the Langfuse endpoint\n",
    "3. Consider using a self-hosted Langfuse instance for lower latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### 1. Use Meaningful Conversation IDs\n",
    "\n",
    "LibreChat automatically uses conversation IDs as `thread_id` in traces, making it easy to correlate Langfuse traces with LibreChat conversations.\n",
    "\n",
    "### 2. Monitor Costs Regularly\n",
    "\n",
    "Set up Langfuse dashboards to monitor:\n",
    "- Daily/weekly token usage\n",
    "- Cost per user\n",
    "- Model usage distribution\n",
    "\n",
    "### 3. Use Tags for Organization\n",
    "\n",
    "Leverage Langfuse's tagging and metadata features to organize traces by:\n",
    "- Environment (development, staging, production)\n",
    "- Feature area\n",
    "- User segment\n",
    "\n",
    "### 4. Set Up Alerts\n",
    "\n",
    "Configure Langfuse alerts for:\n",
    "- Error rate spikes\n",
    "- Latency thresholds\n",
    "- Cost limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [LibreChat Documentation](https://www.librechat.ai/docs)\n",
    "- [LibreChat GitHub Repository](https://github.com/danny-avila/LibreChat)\n",
    "- [Langfuse Documentation](https://langfuse.com/docs)\n",
    "- [Langfuse GitHub Repository](https://github.com/langfuse/langfuse)\n",
    "- [Langfuse Self-Hosting Guide](https://langfuse.com/self-hosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "If you have any feedback or requests, please create a GitHub [Issue](https://langfuse.com/issue) or share your idea with the community on [Discord](https://discord.langfuse.com/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

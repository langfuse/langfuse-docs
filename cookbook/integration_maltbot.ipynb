{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"âš ï¸ Jupyter Notebook\" title: \"Observability for Maltbot / Clawdbot with Langfuse\" sidebarTitle: \"Maltbot / Clawdbot\" logo: \"/images/integrations/opentelemetry_icon.svg\" description: \"Learn how to trace Maltbot and Clawdbot interactions using Langfuse via OpenTelemetry.\" category: \"Integrations\" -->\n",
    "\n",
    "# Integrate Langfuse with Maltbot / Clawdbot\n",
    "\n",
    "This notebook demonstrates how to integrate **Langfuse** with **Maltbot** (also known as **Clawdbot**) using OpenTelemetry. By the end of this guide, you will be able to trace your Maltbot interactions with Langfuse for improved observability and debugging.\n",
    "\n",
    "> **What is Maltbot / Clawdbot?** [Maltbot](https://molt.bot/) (Clawdbot) is an AI-powered conversational bot framework that exposes OpenTelemetry spans for detailed diagnostics and observability. It allows developers to build intelligent conversational agents while maintaining full visibility into the bot's reasoning and decision-making processes.\n",
    "\n",
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source LLM engineering platform. It provides tracing and monitoring capabilities for LLM applications, helping developers debug, analyze, and optimize their AI systems. Langfuse integrates with various tools and frameworks via native integrations, OpenTelemetry, and API/SDKs.\n",
    "\n",
    "## How it Works\n",
    "\n",
    "Maltbot exposes [OpenTelemetry spans](https://docs.molt.bot/logging#diagnostics-+-opentelemetry) that capture detailed information about bot interactions, including:\n",
    "\n",
    "- Conversation turns and messages\n",
    "- LLM calls and responses\n",
    "- Tool invocations and results\n",
    "- Reasoning steps and decisions\n",
    "\n",
    "Langfuse operates as an [OpenTelemetry Backend](/docs/opentelemetry/get-started) and receives these spans on the `/api/public/otel` endpoint. This integration allows you to leverage Langfuse's powerful tracing UI to analyze and debug your Maltbot conversations.\n",
    "\n",
    "## Get Started\n",
    "\n",
    "We'll walk through the setup and configuration to send Maltbot traces to Langfuse.\n",
    "\n",
    "<!-- STEPS_START -->\n",
    "### Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install maltbot opentelemetry-sdk opentelemetry-exporter-otlp langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Up Environment Variables\n",
    "\n",
    "Get your Langfuse API keys by signing up for [Langfuse Cloud](https://cloud.langfuse.com) or [self-hosting Langfuse](https://langfuse.com/self-hosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "os.environ[\"LANGFUSE_BASE_URL\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_BASE_URL\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the environment variables set, we can now initialize the Langfuse client. `get_client()` initializes the Langfuse client using the credentials provided in the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Configure OpenTelemetry to Export to Langfuse\n",
    "\n",
    "Maltbot uses OpenTelemetry for tracing. We need to configure the OpenTelemetry SDK to export traces to Langfuse's OTel endpoint.\n",
    "\n",
    "First, set up the OTel exporter with Langfuse authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OTel endpoint and authentication for Langfuse\n",
    "LANGFUSE_AUTH = base64.b64encode(\n",
    "    f\"{os.environ.get('LANGFUSE_PUBLIC_KEY')}:{os.environ.get('LANGFUSE_SECRET_KEY')}\".encode()\n",
    ").decode()\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = os.environ.get(\"LANGFUSE_BASE_URL\") + \"/api/public/otel\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, configure the OpenTelemetry TracerProvider with an exporter that sends traces to Langfuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry import trace\n",
    "\n",
    "# Create and configure the tracer provider\n",
    "tracer_provider = TracerProvider()\n",
    "\n",
    "# Add a batch span processor with the OTLP exporter\n",
    "# OTLPSpanExporter() uses the endpoint and headers from environment variables\n",
    "tracer_provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter()))\n",
    "\n",
    "# Set the global tracer provider\n",
    "trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "print(\"OpenTelemetry configured to export traces to Langfuse!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Initialize Maltbot with Tracing Enabled\n",
    "\n",
    "Now initialize Maltbot with OpenTelemetry tracing enabled. Maltbot will automatically emit spans that get exported to Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maltbot import Maltbot, MaltbotConfig\n",
    "\n",
    "# Configure Maltbot with OpenTelemetry tracing enabled\n",
    "config = MaltbotConfig(\n",
    "    enable_telemetry=True,  # Enable OpenTelemetry tracing\n",
    "    telemetry_service_name=\"maltbot-langfuse-example\",\n",
    ")\n",
    "\n",
    "# Initialize the bot\n",
    "bot = Maltbot(config=config)\n",
    "\n",
    "print(\"Maltbot initialized with tracing enabled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run a Conversation and Generate Traces\n",
    "\n",
    "Now let's run a conversation with Maltbot. The OpenTelemetry spans will be automatically sent to Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a sample conversation\n",
    "response = bot.chat(\n",
    "    message=\"What are the key benefits of using observability tools for AI applications?\",\n",
    "    session_id=\"demo-session-001\",\n",
    "    user_id=\"demo-user\"\n",
    ")\n",
    "\n",
    "print(\"Bot response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a more complex multi-turn conversation to see richer traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-turn conversation example\n",
    "session_id = \"demo-session-002\"\n",
    "\n",
    "# First turn\n",
    "response1 = bot.chat(\n",
    "    message=\"I'm building an AI chatbot. What should I consider for production deployment?\",\n",
    "    session_id=session_id,\n",
    "    user_id=\"demo-user\"\n",
    ")\n",
    "print(\"Turn 1 response:\", response1[:200] + \"...\" if len(response1) > 200 else response1)\n",
    "\n",
    "# Second turn - follow-up question\n",
    "response2 = bot.chat(\n",
    "    message=\"Can you elaborate on monitoring and observability specifically?\",\n",
    "    session_id=session_id,\n",
    "    user_id=\"demo-user\"\n",
    ")\n",
    "print(\"\\nTurn 2 response:\", response2[:200] + \"...\" if len(response2) > 200 else response2)\n",
    "\n",
    "# Third turn - specific request\n",
    "response3 = bot.chat(\n",
    "    message=\"What metrics should I track to measure my chatbot's performance?\",\n",
    "    session_id=session_id,\n",
    "    user_id=\"demo-user\"\n",
    ")\n",
    "print(\"\\nTurn 3 response:\", response3[:200] + \"...\" if len(response3) > 200 else response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Flush Traces and View in Langfuse\n",
    "\n",
    "Ensure all traces are sent to Langfuse by flushing the tracer provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush all pending spans to ensure they're exported\n",
    "tracer_provider.force_flush()\n",
    "\n",
    "print(\"All traces have been sent to Langfuse!\")\n",
    "print(f\"View your traces at: {os.environ.get('LANGFUSE_BASE_URL')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: View Traces in Langfuse\n",
    "\n",
    "After running the bot interactions above, navigate to your [Langfuse dashboard](https://cloud.langfuse.com) to view the traces. You'll see detailed information about each conversation turn, including:\n",
    "\n",
    "- **Conversation flow**: The sequence of messages and responses\n",
    "- **LLM calls**: Model inputs, outputs, and token usage\n",
    "- **Latencies**: Time taken for each step in the conversation\n",
    "- **Session grouping**: Related conversations grouped by session ID\n",
    "\n",
    "![Maltbot example trace](https://langfuse.com/images/cookbook/integration-maltbot/maltbot-example-trace.png)\n",
    "<!-- STEPS_END -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Custom Attributes\n",
    "\n",
    "You can add custom attributes to your traces using Langfuse-specific OTel attributes. These allow you to filter and search traces more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a tracer for custom spans\n",
    "tracer = trace.get_tracer(\"maltbot-custom\")\n",
    "\n",
    "# Create a custom span with Langfuse attributes\n",
    "with tracer.start_as_current_span(\"custom-maltbot-interaction\") as span:\n",
    "    # Set Langfuse-specific attributes for better filtering\n",
    "    span.set_attribute(\"langfuse.user.id\", \"user-123\")\n",
    "    span.set_attribute(\"langfuse.session.id\", \"session-456\")\n",
    "    span.set_attribute(\"langfuse.trace.tags\", [\"production\", \"customer-support\"])\n",
    "    span.set_attribute(\"langfuse.trace.metadata.customer_tier\", \"premium\")\n",
    "    span.set_attribute(\"langfuse.trace.metadata.bot_version\", \"1.2.0\")\n",
    "    \n",
    "    # Run the bot within this span context\n",
    "    response = bot.chat(\n",
    "        message=\"Help me understand my billing statement.\",\n",
    "        session_id=\"session-456\",\n",
    "        user_id=\"user-123\"\n",
    "    )\n",
    "    \n",
    "    # Set the output on the span\n",
    "    span.set_attribute(\"langfuse.trace.output\", response)\n",
    "\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Using Environment Variables\n",
    "\n",
    "Instead of configuring OTel in code, you can set environment variables before starting your application. This is useful for production deployments:\n",
    "\n",
    "```bash\n",
    "# Set Langfuse credentials\n",
    "export LANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\n",
    "export LANGFUSE_SECRET_KEY=\"sk-lf-...\"\n",
    "export LANGFUSE_BASE_URL=\"https://cloud.langfuse.com\"\n",
    "\n",
    "# Generate the auth string\n",
    "export LANGFUSE_AUTH=$(echo -n \"${LANGFUSE_PUBLIC_KEY}:${LANGFUSE_SECRET_KEY}\" | base64)\n",
    "\n",
    "# Configure OTel to export to Langfuse\n",
    "export OTEL_EXPORTER_OTLP_ENDPOINT=\"${LANGFUSE_BASE_URL}/api/public/otel\"\n",
    "export OTEL_EXPORTER_OTLP_HEADERS=\"Authorization=Basic ${LANGFUSE_AUTH}\"\n",
    "\n",
    "# Enable Maltbot telemetry\n",
    "export MALTBOT_ENABLE_TELEMETRY=\"true\"\n",
    "export MALTBOT_TELEMETRY_SERVICE_NAME=\"my-maltbot-service\"\n",
    "\n",
    "# Run your application\n",
    "python my_maltbot_app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with OpenTelemetry Collector\n",
    "\n",
    "For more advanced setups, you can use an [OpenTelemetry Collector](https://opentelemetry.io/docs/collector/) to process and route traces. This is useful when you want to send traces to multiple backends or apply transformations.\n",
    "\n",
    "Example Collector configuration to forward Maltbot traces to Langfuse:\n",
    "\n",
    "```yaml\n",
    "receivers:\n",
    "  otlp:\n",
    "    protocols:\n",
    "      grpc:\n",
    "        endpoint: 0.0.0.0:4317\n",
    "      http:\n",
    "        endpoint: 0.0.0.0:4318\n",
    "\n",
    "processors:\n",
    "  batch:\n",
    "\n",
    "exporters:\n",
    "  otlphttp/langfuse:\n",
    "    endpoint: \"https://cloud.langfuse.com/api/public/otel\"\n",
    "    headers:\n",
    "      Authorization: \"Basic ${LANGFUSE_AUTH}\"\n",
    "\n",
    "service:\n",
    "  pipelines:\n",
    "    traces:\n",
    "      receivers: [otlp]\n",
    "      processors: [batch]\n",
    "      exporters: [otlphttp/langfuse]\n",
    "```\n",
    "\n",
    "Then configure Maltbot to send traces to your Collector instead of directly to Langfuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "\n",
    "- [Maltbot Documentation](https://docs.molt.bot/)\n",
    "- [Langfuse OpenTelemetry Integration](/docs/opentelemetry/get-started)\n",
    "- [Langfuse Attribute Mapping](/docs/opentelemetry/get-started#property-mapping)\n",
    "- [OpenTelemetry Python SDK](https://opentelemetry.io/docs/languages/python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- MARKDOWN_COMPONENT name: \"LearnMore\" path: \"@/components-mdx/integration-learn-more.mdx\" -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"âš ï¸ Jupyter Notebook\" title: \"Trace the Microsoft Agent Framework with Langfuse\" sidebarTitle: \"Microsoft Agent Framework\" logo: \"/images/integrations/microsoft_icon.svg\" description: \"Learn how to use Langfuse to monitor Microsoft Agent Framework to debug and evaluate your AI agents\" category: \"Integrations\" -->\n",
    "\n",
    "# Trace the Microsoft Agent Framework with Langfuse\n",
    "\n",
    "This notebook demonstrates how to **integrate Langfuse** into your **Microsoft Agent Framework** workflow to monitor, debug and evaluate your AI agents.\n",
    "\n",
    "> **What is the Microsoft Agent Framework?**: The [Microsoft Agent Framework](https://github.com/microsoft/agent-framework) is an open-source framework for building intelligent agents. It provides a comprehensive set of tools for creating agents that can interact with various services, execute tasks, and handle complex workflows. The framework supports multiple LLM providers including Azure OpenAI and OpenAI, and offers built-in observability through OpenTelemetry.\n",
    "\n",
    "> **What is Langfuse?**: [Langfuse](https://langfuse.com/) is an open-source observability platform for AI agents. It helps you visualize and monitor LLM calls, tool usage, cost, latency, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Below we install the `agent-framework` library (the Microsoft Agent Framework) and `langfuse` for observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agent-framework langfuse --pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Environment & Langfuse Credentials\n",
    "\n",
    "Next, set up your Langfuse API keys. You can get these keys by signing up for a free [Langfuse Cloud](https://cloud.langfuse.com/) account or by [self-hosting Langfuse](https://langfuse.com/self-hosting). These environment variables are essential for the Langfuse client to authenticate and send data to your Langfuse project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "os.environ[\"LANGFUSE_BASE_URL\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_BASE_URL\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
    "\n",
    "# Your Azure OpenAI credentials\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"your-azure-openai-key\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://your-resource.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-5-mini\"\n",
    "os.environ[\"OPENAI_CHAT_MODEL_ID\"] = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Langfuse Client\n",
    "\n",
    "Initialize the Langfuse client to verify the connection. `get_client()` initializes the Langfuse client using the credentials provided in the environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Enable Observability\n",
    "\n",
    "The Microsoft Agent Framework includes built-in observability support through OpenTelemetry. Enable it by calling `setup_observability()` which automatically exports traces to Langfuse.\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"â„¹ï¸\" -->\n",
    "**Note:** Set `enable_sensitive_data=True` to capture full request/response data including function arguments and results.\n",
    "<!-- CALLOUT_END -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.observability import setup_observability\n",
    "\n",
    "setup_observability(enable_sensitive_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hello World Example with Tool\n",
    "\n",
    "Below we create a **weather agent** using the Microsoft Agent Framework with Azure OpenAI. The agent has access to a `get_weather` function tool that it can call to retrieve weather information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from pydantic import Field\n",
    "\n",
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}Â°C.\"\n",
    "\n",
    "async def main():\n",
    "    # Create an agent with Azure OpenAI\n",
    "    async with AzureOpenAIChatClient().create_agent(\n",
    "        instructions=\"You are a helpful weather agent.\",\n",
    "        tools=get_weather,\n",
    "    ) as agent:\n",
    "        query = \"What's the weather like in Seattle?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Agent: {result}\\n\")\n",
    "\n",
    "# Run the agent\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using OpenAI Directly\n",
    "\n",
    "The Microsoft Agent Framework also supports using OpenAI directly (not through Azure). Simply use `OpenAIResponsesClient` instead of `AzureOpenAIChatClient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for OpenAI API access\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"sk-proj-...\"\n",
    "os.environ[\"OPENAI_RESPONSES_MODEL_ID\"]=\"gpt-5-mini\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.openai import OpenAIResponsesClient\n",
    "\n",
    "async def main():\n",
    "    async with OpenAIResponsesClient().create_agent(\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "        tools=get_weather,\n",
    "    ) as agent:\n",
    "        query = \"What's the weather in Tokyo?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Agent: {result}\\n\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. See Traces in Langfuse\n",
    "\n",
    "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration_microsoft-agent-framework/microsoft-agent-framework-example-trace.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

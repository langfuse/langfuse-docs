{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Pydantic AI Integration via OpenTelemetry\n",
        "description: Open Source Observability for Pydantic AI. Example cookbook for the Pydantic AI Langfuse integration using OpenTelemetry.\n",
        "category: Integrations\n",
        "---\n",
        "\n",
        "# Pydantic AI Integration via OpenTelemetry\n",
        "\n",
        "Langfuse offers an [OpenTelemetry backend](https://langfuse.com/docs/opentelemetry/) that ingests trace data from a variety of OpenTelemetry instrumentation libraries. In this guide, we demonstrate how to use the Pydantic Logfire instrumentation library to instrument your Pydantic AI agents.\n",
        "\n",
        "> **About PydanticAI:** [PydanticAI](https://pydantic-ai.readthedocs.io/en/latest/) is a Python agent framework designed to simplify the development of production-grade generative AI applications. It brings the same type-safety, ergonomic API design, and developer experience found in FastAPI to the world of GenAI app development. \n",
        "\n",
        "## Step 1: Install Dependencies\n",
        "\n",
        "Before you begin, install the necessary Python packages. The command below will install the `pydantic-ai` package along with Logfire support, which is required for trace ingestion via Langfuse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p7zqVoQVAzii",
        "outputId": "69c960b8-7645-42ee-ce2c-a615653678e1"
      },
      "outputs": [],
      "source": [
        "%pip install pydantic-ai[logfire]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configure Environment Variables\n",
        "\n",
        "To forward trace data to Langfuse, you must set up the required environment variables. This includes providing your Langfuse API keys and the proper OpenTelemetry exporter endpoint. Additionally, you need to specify your OpenAI API key if you are using OpenAI for your generative tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vhj-dTnXBii3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "\n",
        "LANGFUSE_PUBLIC_KEY = \"pk-lf-...\"\n",
        "LANGFUSE_SECRET_KEY = \"sk-lf-...\"\n",
        "LANGFUSE_AUTH = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
        "\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel\" # EU data region\n",
        "# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel\" # US data region\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
        "\n",
        "# your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Initialize Instrumentation\n",
        "\n",
        "Now, initialize Logfire’s instrumentation and define a sample Pydantic AI agent that makes use of dependency injection and tool registration. In this example, we create a \"roulette\" agent. The agent is configured to call a tool function (`roulette_wheel`), which checks if a given square is a winner. The agent is type-safe, ensuring that the dependency (`deps_type`) and the output (`result_type`) have defined types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mYU7iIWACUyC"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysE9xblmBv2V",
        "outputId": "80168afd-6470-4cb1-8cb4-d4a0ae59c85e"
      },
      "outputs": [],
      "source": [
        "import logfire\n",
        "\n",
        "logfire.configure(\n",
        "    service_name='my_logfire_service',\n",
        "\n",
        "    # Sending to Logfire is on by default regardless of the OTEL env vars.\n",
        "    send_to_logfire=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ozWO44i8AxV3"
      },
      "outputs": [],
      "source": [
        "from pydantic_ai import Agent, RunContext\n",
        "\n",
        "roulette_agent = Agent(\n",
        "    'openai:gpt-4o',\n",
        "    deps_type=int,\n",
        "    result_type=bool,\n",
        "    system_prompt=(\n",
        "        'Use the `roulette_wheel` function to see if the '\n",
        "        'customer has won based on the number they provide.'\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "@roulette_agent.tool\n",
        "async def roulette_wheel(ctx: RunContext[int], square: int) -> str:\n",
        "    \"\"\"check if the square is a winner\"\"\"\n",
        "    return 'winner' if square == ctx.deps else 'loser'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run the Agent\n",
        "\n",
        "Finally, run your Pydantic AI agent and generate trace data that will be sent to Langfuse. In the example below, the agent is executed with a dependency value (the winning square) and natural language input. The output from the tool function is then printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4Ic6U7DB7vO",
        "outputId": "756da737-7c58-4c46-a578-941815ca5d2a"
      },
      "outputs": [],
      "source": [
        "# Run the agent\n",
        "success_number = 18\n",
        "result = roulette_agent.run_sync('Put my money on square eighteen', deps=success_number)\n",
        "print(result.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Explore Traces in Langfuse\n",
        "\n",
        "With the instrumentation in place, all trace data generated by the agent will be sent to Langfuse. You can view detailed trace logs—including operation timings, debugging information, and performance metrics—by accessing your Langfuse dashboard. For example, check out a [sample trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/0194c8b3c1fbb67529f717d4009a310b?timestamp=2025-02-02T22%3A06%3A51.387Z) to see the flow of a Pydantic AI request."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXjZqGq6tUso"
      },
      "source": [
        "[Example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/0194c8b3c1fbb67529f717d4009a310b?timestamp=2025-02-02T22%3A06%3A51.387Z)\n",
        "\n",
        "![Pydantic AI OpenAI Trace](https://langfuse.com/images/cookbook/otel-integration-pydantic-ai/pydanticai-openai-trace-tree.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "851sPORkCKQl",
        "outputId": "327666e0-5f34-48d6-b2f4-2e9f773f8c1f"
      },
      "outputs": [],
      "source": [
        "result = roulette_agent.run_sync('I bet five is the winner', deps=success_number)\n",
        "print(result.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRvogldEta2f"
      },
      "source": [
        "[Example trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/0194c8b3d11a9a66859edb3fade14760?timestamp=2025-02-02T22%3A06%3A55.258Z)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

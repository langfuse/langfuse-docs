{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Observability for Pydantic AI with Langfuse Integration\" description: \"Discover how to integrate Langfuse with Pydantic AI for enhanced LLM application monitoring, debugging, and tracing. Improve your AI development workflow today.\" category: \"Integrations\" -->\n",
        "\n",
        "# Integrate Langfuse with Pydantic AI\n",
        "\n",
        "This notebook provides a step-by-step guide on integrating **Langfuse** with **Pydantic AI** to achieve observability and debugging for your LLM applications.\n",
        "\n",
        "> **About PydanticAI:** [PydanticAI](https://pydantic-ai.readthedocs.io/en/latest/) is a Python agent framework designed to simplify the development of production-grade generative AI applications. It brings the same type-safety, ergonomic API design, and developer experience found in FastAPI to the world of GenAI app development. \n",
        "\n",
        "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source LLM engineering platform. It offers tracing and monitoring capabilities for AI applications. Langfuse helps developers debug, analyze, and optimize their AI systems by providing detailed insights and integrating with a wide array of tools and Pydantic AIs through native integrations, OpenTelemetry, and dedicated SDKs.\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "Let's walk through a practical example of using Pydantic AI and integrating it with Langfuse for comprehensive tracing.\n",
        "\n",
        "<!-- STEPS_START -->\n",
        "### Step 1: Install Dependencies\n",
        "\n",
        "<!-- CALLOUT_START type: \"info\" emoji: \"âš ï¸\" -->\n",
        "_**Note:** This notebook utilizes the Langfuse OTel Python SDK v3. For users of Python SDK v2, please refer to our [legacy Pydantic AI integration guide](https://github.com/langfuse/langfuse-docs/blob/fdea27dd5d3f4a110a4f79c0ec1b7b381b48d091/cookbook/integration_pydantic_ai.ipynb)._\n",
        "<!-- CALLOUT_END -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install langfuse pydantic-ai -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Step 2: Configure Langfuse SDK\n",
        "\n",
        "Next, set up your Langfuse API keys. You can get these keys by signing up for a free [Langfuse Cloud](https://cloud.langfuse.com/) account or by [self-hosting Langfuse](https://langfuse.com/self-hosting). These environment variables are essential for the Langfuse client to authenticate and send data to your Langfuse project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
        "\n",
        "# Your OpenAI key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "With the environment variables set, we can now initialize the Langfuse client. `get_client()` initializes the Langfuse client using the credentials provided in the environment variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langfuse import get_client\n",
        " \n",
        "langfuse = get_client()\n",
        " \n",
        "# Verify connection\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse client is authenticated and ready!\")\n",
        "else:\n",
        "    print(\"Authentication failed. Please check your credentials and host.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Step 3: Initialize Pydantic AI Instrumentation\n",
        "\n",
        "Now, we initialize the [Pydantic AI Instrumentation](https://ai.pydantic.dev/logfire/#logfire-with-an-alternative-otel-backend). This  automatically captures Pydantic AI operations and exports OpenTelemetry (OTel) spans to Langfuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic_ai.agent import Agent\n",
        "\n",
        "# Initialize Pydantic AI instrumentation\n",
        "Agent.instrument_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Step 4: Basic Pydantic AI Application\n",
        "\n",
        "Finally, run your Pydantic AI agent and generate trace data that will be sent to Langfuse. In the example below, the agent is executed with a dependency value (the winning square) and natural language input. The output from the tool function is then printed.\n",
        "\n",
        "Make sure to pass `instrument=True` while configuring the `Agent`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic_ai import Agent, RunContext\n",
        "\n",
        "roulette_agent = Agent(\n",
        "    'openai:gpt-4o',\n",
        "    deps_type=int,\n",
        "    result_type=bool,\n",
        "    system_prompt=(\n",
        "        'Use the `roulette_wheel` function to see if the '\n",
        "        'customer has won based on the number they provide.'\n",
        "    ),\n",
        "    instrument=True\n",
        ")\n",
        "\n",
        "@roulette_agent.tool\n",
        "async def roulette_wheel(ctx: RunContext[int], square: int) -> str:\n",
        "    \"\"\"check if the square is a winner\"\"\"\n",
        "    return 'winner' if square == ctx.deps else 'loser'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the agent - using await since we're in a Jupyter notebook\n",
        "success_number = 18\n",
        "result = await roulette_agent.run('Put my money on square eighteen', deps=success_number)\n",
        "print(result.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Step 5: View Traces in Langfuse\n",
        "\n",
        "After executing the application, navigate to your [Langfuse Trace Table](https://cloud.langfuse.com). You will find detailed traces of the application's execution, providing insights into the LLM calls, retrieval operations, inputs, outputs, and performance metrics. \n",
        "\n",
        "![Example Trace in Langfuse](https://langfuse.com/images/cookbook/otel-integration-pydantic-ai/pydanticai-openai-trace-tree.png)\n",
        "\n",
        "[Example Trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/25f4bdeebaab60e6e1bee7e8469554bc?display=details%3Ftimestamp%3D2025-06-06T14%3A39%3A55.786Z%3Ftimestamp%3D2025-06-06T14%3A37%3A30.656Z%3Ftimestamp%3D2025-06-06T14%3A39%3A55.786Z?timestamp=2025-06-06T14%3A40%3A28.562Z)\n",
        "<!-- STEPS_END -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- MARKDOWN_COMPONENT name: \"LearnMore\" path: \"@/components-mdx/integration-learn-more.mdx\" -->"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

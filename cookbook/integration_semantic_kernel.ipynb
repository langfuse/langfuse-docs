{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"Jupyter Notebook\" title: \"Observability for Semantic Kernel with Langfuse Integration\" description: \"Discover how to integrate Langfuse with Semantic Kernel for enhanced LLM application monitoring, debugging, and tracing. Improve your AI development workflow today.\" category: \"Integrations\" -->\n",
    "\n",
    "# Integrate Langfuse with Semantic Kernel\n",
    "\n",
    "This notebook provides a step-by-step guide on integrating **Langfuse** with **Semantic Kernel** to achieve superior observability and debugging for your Large Language Model (LLM) applications. By following this tutorial, you will learn how to effectively trace your Semantic Kernel applications using Langfuse, gaining deeper insights into their performance and behavior.\n",
    "\n",
    "> **What is Semantic Kernel?** [Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) ([GitHub](https://github.com/microsoft/semantic-kernel)) is a powerful open-source SDK from Microsoft. It facilitates the combination of LLMs with popular programming languages like C#, Python, and Java. Semantic Kernel empowers developers to build sophisticated AI applications by seamlessly integrating AI services, data sources, and custom logic, accelerating the delivery of enterprise-grade AI solutions.\n",
    "\n",
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is a leading open-source platform dedicated to LLM observability. It offers robust tracing and monitoring capabilities tailored for AI applications. Langfuse helps developers debug, analyze, and optimize their AI systems by providing detailed insights and integrating with a wide array of tools and frameworks through native integrations, OpenTelemetry, and dedicated SDKs.\n",
    "\n",
    "_**Note:** This guide focuses on the Python implementation. However, the principles of this Langfuse integration apply to other languages supported by Semantic Kernel, including [C#](https://learn.microsoft.com/en-us/semantic-kernel/concepts/enterprise-readiness/observability/?pivots=programming-language-csharp) and [Java](https://learn.microsoft.com/en-us/semantic-kernel/concepts/enterprise-readiness/observability/?pivots=programming-language-java)._\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Let's walk through a practical example of using Semantic Kernel and integrating it with Langfuse for comprehensive tracing.\n",
    "\n",
    "### Step 1: Install Dependencies\n",
    "\n",
    "_**Note:** This notebook utilizes the Langfuse OTel Python SDK v3. For users of Python SDK v2, a previous version of this guide is available [here](https://github.com/langfuse/langfuse-docs/blob/4bba7985939469dab76b04513221995a203ac3c7/cookbook/integration_semantic_kernel.ipynb#L4)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"langfuse>=3.0.0b2\" openlit semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2: Configure Langfuse SDK\n",
    "\n",
    "Next, set up your Langfuse API keys. You can obtain these keys by signing up for a free [Langfuse Cloud](https://cloud.langfuse.com/) account or by [self-hosting Langfuse](https://langfuse.com/self-hosting). These environment variables are essential for the Langfuse client to authenticate and send data to your Langfuse project.\n",
    "\n",
    "The code below demonstrates how to set these environment variables. Remember to replace the placeholder values with your actual Langfuse public key, secret key, and host, as well as your OpenAI API key and desired model ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get keys for your project from the project settings page at https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region\n",
    "\n",
    "# Your OpenAI key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "os.environ[\"OPENAI_CHAT_MODEL_ID\"] = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the environment variables set, we can now initialize the Langfuse client. This client will be used to interact with the Langfuse API.\n",
    "The `get_client()` function initializes the Langfuse client using the credentials provided in the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse client is authenticated and ready!\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initialize OpenLit for Instrumentation\n",
    "\n",
    "Now, we initialize the [OpenLit instrumentation SDK](https://docs.openlit.io/latest/sdk-configuration). OpenLit automatically instruments Semantic Kernel and exports OpenTelemetry (OTel) spans to Langfuse. This allows for seamless tracing of your Semantic Kernel operations.\n",
    "\n",
    "The `openlit.init()` function is configured to use the Langfuse OTel tracer and disables batching (`disable_batch=True`) to ensure traces are processed and sent immediately, which is useful for development and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openlit\n",
    "\n",
    "# Initialize OpenLIT instrumentation. The disable_batch flag is set to true to process traces immediately. Also set the langfuse tracer to use the langfuse tracer.\n",
    "openlit.init(tracer=langfuse._otel_tracer, disable_batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Basic Semantic Kernel Application\n",
    "\n",
    "Let's create a straightforward Semantic Kernel application. In this example, an Assistant agent will answer a user's question. This will serve as the foundation for demonstrating Langfuse tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "\n",
    "prompt = \"\"\"{{$input}}\n",
    "Answer the question above.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"summarize\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user input\", is_required=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "summarize = kernel.add_function(\n",
    "    function_name=\"summarizeFunc\",\n",
    "    plugin_name=\"summarizePlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run the Application\n",
    "\n",
    "With the Semantic Kernel application set up, let's invoke it with a sample question and print the response. OpenLit will automatically capture this interaction and send the trace data to Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse is a platform designed to help developers and companies monitor, debug, and improve applications that utilize large language models (LLMs) and generative AI. It provides features for tracking the performance of LLM applications, analyzing their behavior during production, and collecting data for continued model improvement. Langfuse facilitates better understanding and management of AI applications by offering insights and tools tailored to the needs of modern AI products.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is Langfuse?\"\n",
    "\n",
    "summary = await kernel.invoke(summarize, input=input_text)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 6: View Traces in Langfuse\n",
    "\n",
    "After executing the Semantic Kernel application, navigate to your Langfuse Trace Table. You will find detailed traces of the application's execution, providing insights into the LLM calls, inputs, outputs, and performance metrics. Below is an example screenshot illustrating how a trace appears in Langfuse:\n",
    "\n",
    "![Langfuse Trace of Semantic Kernel Application](https://langfuse.com/images/cookbook/integration-semantic-kernel/sematric-kernel-example-trace.png)\n",
    "\n",
    "For a live example, you can explore this public trace: [Langfuse Semantic Kernel Trace Example](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/51d7ea51af5cf9048f607ac6abb79b4f?timestamp=2025-06-04T08:17:14.026Z&display=details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Additional Attributes\n",
    "\n",
    "Langfuse allows you to pass additional attributes to your spans. These can include `user_id`, `tags`, `session_id`, and custom `metadata`. Enriching traces with these details is important for effective analysis, debugging, and monitoring of your application's behavior across different users or sessions.\n",
    "\n",
    "The following code demonstrates how to start a custom span with `langfuse.start_as_current_span` and then update the trace associated with this span using `span.update_trace()`. This allows you to log specific inputs, outputs, and other relevant information directly to Langfuse.\n",
    "\n",
    "â†’ Learn more about [Updating Trace and Span Attributes](https://langfuse.com/docs/sdk/python/sdk-v3#updating-observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse is a platform designed for observability of LLM (Large Language Model) applications. It allows developers and organizations to monitor, debug, and gain insights into their AI applications that utilize large language models. By providing tools for tracking application performance, errors, and user interactions, Langfuse aims to enhance the development and maintenance of AI-driven projects. Additionally, it helps in understanding the behavior of language models in production environments, ensuring that they operate efficiently and effectively.\n"
     ]
    }
   ],
   "source": [
    "with langfuse.start_as_current_span(\n",
    "    name=\"semantic-kernel-trace\",\n",
    "    ) as span:\n",
    "    \n",
    "    # Run your application here\n",
    "    question = \"What is Langfuse?\"\n",
    "    response = await kernel.invoke(summarize, input=question)\n",
    "    response = response.value[0].items[0].text\n",
    "    print(response)\n",
    "\n",
    "    # Pass additional attributes to the span\n",
    "    span.update_trace(\n",
    "        input=question,\n",
    "        output=response,\n",
    "        user_id=\"user_123\",\n",
    "        session_id=\"session_abc\",\n",
    "        tags=[\"agent\", \"semantic-kernel\"],\n",
    "        metadata={\"email\": \"user@langfuse.com\"},\n",
    "        version=\"1.0.0\"\n",
    "        )\n",
    "\n",
    "# Flush events in short-lived applications\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Traces and Spans\n",
    "\n",
    "Langfuse lets you can ingest custom scores for individual spans or entire traces. This scoring workflow enables you to implement custom quality checks at runtime or facilitate human-in-the-loop evaluation processes.\n",
    "\n",
    "In the example below, we demonstrate how to score a specific span for `conciseness` (a numeric score) and the overall trace for `feedback` (a categorical score). This helps in systematically assessing and improving your application.\n",
    "\n",
    "â†’ Learn more about [Custom Scores in Langfuse](https://langfuse.com/docs/scores/custom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse is a platform designed to help developers and businesses monitor and troubleshoot their large language model (LLM) applications. It provides tools for observability and performance tracking, enabling users to understand how their applications are interacting with language models and performing in real-time. By offering insights into model use, error analysis, and user interactions, Langfuse aims to enhance the efficiency and reliability of applications that depend on LLMs.\n"
     ]
    }
   ],
   "source": [
    "with langfuse.start_as_current_span(\n",
    "    name=\"semantic-kernel-trace\",\n",
    "    ) as span:\n",
    "    \n",
    "    # Run your application here\n",
    "    question = \"What is Langfuse?\"\n",
    "    response = await kernel.invoke(summarize, input=question)\n",
    "    response = response.value[0].items[0].text\n",
    "    print(response)\n",
    "    \n",
    "    # Score this specific span\n",
    "    span.score(name=\"conciseness\", value=0.8, data_type=\"NUMERIC\")\n",
    "\n",
    "    # Score the overall trace\n",
    "    span.score_trace(name=\"feedback\", value=\"positive\", data_type=\"CATEGORICAL\")\n",
    "\n",
    "# Flush events in short-lived applications\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Prompts with Langfuse\n",
    "\n",
    "Langfuse Prompt Management allows you to collaboratively create, version, and deploy prompts. You can manage prompts either through the Langfuse SDK or directly within the Langfuse UI. These managed prompts can then be fetched into your application at runtime and automatically linked to the traces that utilize them, ensuring traceability and facilitating A/B testing or version control.\n",
    "\n",
    "The code below illustrates fetching a prompt named `answer-question` from Langfuse, compiling it with an input variable (`country`), and then using this compiled prompt in our Semantic Kernel application. The resulting generation is then linked back to the specific Langfuse prompt version used.\n",
    "\n",
    "â†’ Get started with [Langfuse Prompt Management](https://langfuse.com/docs/prompts/get-started)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: What is the capital of France?\n",
      "response: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# Fetch the prompt from langfuse\n",
    "langfuse_prompt = langfuse.get_prompt(name=\"answer-question\")\n",
    "\n",
    "# Compile the prompt with the input\n",
    "compiled_prompt = langfuse_prompt.compile(country = \"France\")\n",
    "\n",
    "# Run your application\n",
    "with langfuse.start_as_current_span(\n",
    "    name=\"semantic-kernel-trace\",\n",
    "    ) as span:\n",
    "    \n",
    "    # Run your application here\n",
    "    question = compiled_prompt\n",
    "    print(\"question:\", question)\n",
    "    response = await kernel.invoke(summarize, input=question)\n",
    "    response = response.value[0].items[0].text\n",
    "    print(\"response:\", response)\n",
    "\n",
    "    # Link the prompt to the trace\n",
    "    langfuse.update_current_generation(prompt = langfuse_prompt)\n",
    "\n",
    "# Flush events in short-lived applications\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Experiments\n",
    "\n",
    "Offline evaluation using datasets is a critical part of the LLM development lifecycle. Langfuse supports this through Dataset Experiments. The typical workflow involves:\n",
    "\n",
    "1.  **Benchmark Dataset**: Defining a dataset with input prompts and their corresponding expected outputs.\n",
    "2.  **Application Run**: Running your LLM application against each item in the dataset.\n",
    "3.  **Evaluation**: Comparing the generated outputs against the expected results or using other scoring mechanisms (e.g., model-based evaluation) to assess performance.\n",
    "\n",
    "The following example demonstrates how to use a pre-existing dataset containing countries and their capitals to run an experiment.\n",
    "\n",
    "â†’ Learn more about [Langfuse Dataset Experiments](https://langfuse.com/docs/datasets/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'country': 'USA'}, Expected: Washington, D.C.\n",
      "Input: {'country': 'Egypt'}, Expected: Cairo\n",
      "Input: {'country': 'South Africa'}, Expected: Pretoria\n",
      "Input: {'country': 'Argentina'}, Expected: Buenos Aires\n",
      "Input: {'country': 'South Korea'}, Expected: Seoul\n",
      "Input: {'country': 'Canada'}, Expected: Ottawa\n",
      "Input: {'country': 'India'}, Expected: New Delhi\n",
      "Input: {'country': 'Japan'}, Expected: Tokyo\n",
      "Input: {'country': 'Brazil'}, Expected: BrasÃ­lia\n",
      "Input: {'country': 'Spain'}, Expected: Madrid\n",
      "Input: {'country': 'Italy'}, Expected: Rome\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    " \n",
    "# Fetch an existing dataset\n",
    "dataset = langfuse.get_dataset(name=\"capital_cities_11\")\n",
    "for item in dataset.items:\n",
    "    print(f\"Input: {item.input}, Expected: {item.expected_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we iterate through each item in the dataset, run our Semantic Kernel application (`your_application`) with the item's input, and log the results as a run associated with that dataset item in Langfuse. This allows for structured evaluation and comparison of different application versions or prompt configurations.\n",
    "\n",
    "The `item.run()` context manager is used to create a new trace for each dataset item processed in the experiment. Optionally you can score the dataset runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for item: cm3mzglxi011hrnvfsumtkkzx (Input: {'country': 'USA'})\n",
      "  Item cm3mzglxi011hrnvfsumtkkzx processed. Trace ID: ff9cc54daee1aeac7d7f619348c31a37\n",
      "Running evaluation for item: f7d97f1a-e2ba-4e32-9f85-974f81e36614 (Input: {'country': 'Egypt'})\n",
      "  Item f7d97f1a-e2ba-4e32-9f85-974f81e36614 processed. Trace ID: 7b19329266b4338a728a28869524b8fa\n",
      "Running evaluation for item: b8cb5991-3384-48cd-9bd1-160d8233c687 (Input: {'country': 'South Africa'})\n",
      "  Item b8cb5991-3384-48cd-9bd1-160d8233c687 processed. Trace ID: f2b3dbe1aaf23f510beb0db2129fe420\n",
      "Running evaluation for item: 96c7d3c8-9aa7-46c7-a4b9-85640694660b (Input: {'country': 'Argentina'})\n",
      "  Item 96c7d3c8-9aa7-46c7-a4b9-85640694660b processed. Trace ID: 97a860f42fb2f77f84bf351b00757c5d\n",
      "Running evaluation for item: 3de354e6-4c8d-4ea7-98ab-f2794233d6d7 (Input: {'country': 'South Korea'})\n",
      "  Item 3de354e6-4c8d-4ea7-98ab-f2794233d6d7 processed. Trace ID: bd90a77c101ebf2c5a6c172648e6b386\n",
      "Running evaluation for item: 5bb3cecd-ab56-4d53-ba46-eb27f0b82755 (Input: {'country': 'Canada'})\n",
      "  Item 5bb3cecd-ab56-4d53-ba46-eb27f0b82755 processed. Trace ID: 0ed8f7066775607a4631af6921cfd7a1\n",
      "Running evaluation for item: 46dc47db-6f77-42b0-b0cf-48cb42a3cb26 (Input: {'country': 'India'})\n",
      "  Item 46dc47db-6f77-42b0-b0cf-48cb42a3cb26 processed. Trace ID: 07ef85a26bcaa5ebb48c9e5f1879ca06\n",
      "Running evaluation for item: 5d08adbd-b013-4e00-81ea-2359544f81d7 (Input: {'country': 'Japan'})\n",
      "  Item 5d08adbd-b013-4e00-81ea-2359544f81d7 processed. Trace ID: aaf9678592d05504a4ec0bb6787d159a\n",
      "Running evaluation for item: 70384a90-3163-4eaa-9769-0218ad39375d (Input: {'country': 'Brazil'})\n",
      "  Item 70384a90-3163-4eaa-9769-0218ad39375d processed. Trace ID: 820aa7d40ad174b86890c840a1ac95b1\n",
      "Running evaluation for item: 7f03c37f-71ed-4e9a-8de8-573503a49710 (Input: {'country': 'Spain'})\n",
      "  Item 7f03c37f-71ed-4e9a-8de8-573503a49710 processed. Trace ID: 92a77a446df2888a1515b69a9a6639eb\n",
      "Running evaluation for item: d66bb581-4e76-4e41-9c89-2e9ec4ec32f8 (Input: {'country': 'Italy'})\n",
      "  Item d66bb581-4e76-4e41-9c89-2e9ec4ec32f8 processed. Trace ID: 5217b77af4c77cead6f573661c3aea46\n",
      "\n",
      "Finished processing dataset 'capital_cities_11' for run 'capital_cities_run_01'.\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    " \n",
    "langfuse = get_client()\n",
    "dataset_name = \"capital_cities_11\"\n",
    "current_run_name = \"capital_cities_run_01\" # Identifies this specific evaluation run\n",
    "current_run_metadata={\"model_provider\": \"OpenAI\", \"temperature_setting\": 0.7},\n",
    "current_run_description=\"Evaluation run for Q&A model on June 4th\"\n",
    " \n",
    "# Assume 'your_application' is your instrumented application function\n",
    "async def your_application(question):\n",
    "    with langfuse.start_as_current_span(name=\"semantic-kernel-trace\") as span:\n",
    "\n",
    "        answer = await kernel.invoke(summarize, input=question)\n",
    "        answer = answer.value[0].items[0].text\n",
    " \n",
    "        # Update the trace with the input and output\n",
    "        span.update_trace(\n",
    "            input=  question,\n",
    "            output= answer,\n",
    "        )\n",
    " \n",
    "        return answer\n",
    " \n",
    "dataset = langfuse.get_dataset(name=dataset_name) # Fetch your pre-populated dataset\n",
    " \n",
    "for item in dataset.items:\n",
    "    print(f\"Running evaluation for item: {item.id} (Input: {item.input})\")\n",
    " \n",
    "    # Use the item.run() context manager\n",
    "    with item.run(\n",
    "        run_name=current_run_name,\n",
    "        run_metadata=current_run_metadata,\n",
    "        run_description=current_run_description\n",
    "    ) as root_span: \n",
    "        # All subsequent langfuse operations within this block are part of this trace.\n",
    "        generated_answer = await your_application(\n",
    "            question=\"What is the capital of \" + item.input[\"country\"] + \"? Just answer with the name of the city.\",\n",
    "            item_id=item.id,\n",
    "            run_name=current_run_name\n",
    "        )\n",
    " \n",
    "        print(f\"  Item {item.id} processed. Trace ID: {root_span.trace_id}\")\n",
    " \n",
    "        # Optionally, score the result against the expected output\n",
    "        if item.expected_output and generated_answer == item.expected_output:\n",
    "            root_span.score_trace(name=\"exact_match\", value=1.0)\n",
    "        else:\n",
    "            root_span.score_trace(name=\"exact_match\", value=0.0)\n",
    " \n",
    "print(f\"\\nFinished processing dataset '{dataset_name}' for run '{current_run_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore More Langfuse Features\n",
    "\n",
    "Langfuse offers more features to enhance your LLM development and observability workflow:\n",
    "\n",
    "- [LLM-as-a-Judge Evaluators](https://langfuse.com/docs/evaluation/llm-judge): Automate evaluations using LLMs as judges.\n",
    "- [Custom Dashboards](https://langfuse.com/docs/dashboards): Create tailored visualizations for your key metrics.\n",
    "- [LLM Playground](https://langfuse.com/docs/playground): Experiment with different models and prompts interactively.\n",
    "- [Prompt Management](https://langfuse.com/docs/prompts): Collaboratively manage and version your prompts.\n",
    "- [Prompt Experiments](https://langfuse.com/docs/prompts/experiments): Systematically test and compare different prompt versions.\n",
    "- [Further Integrations](https://langfuse.com/docs/integrations): Discover more ways to connect Langfuse with your MLOps stack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

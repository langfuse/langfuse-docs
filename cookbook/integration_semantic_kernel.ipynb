{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Observability for Semantic Kernel with Langfuse\n",
    "description: Learn how to integrate Langfuse with Semantic Kernel for improved monitoring and debugging\n",
    "category: Integrations\n",
    "---\n",
    "\n",
    "# Integrate Langfuse with Semantic Kernel\n",
    "\n",
    "This notebook demonstrates how to integrate **Langfuse** with **Semantic Kernel** for improved observability and debugging. By the end of this notebook, you will be able to trace your Semantic Kernel applications with Langfuse.\n",
    "\n",
    "> **What is Semantic Kernel?** [Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) [(GitHub)](https://github.com/microsoft/semantic-kernel) is an open-source SDK developed by Microsoft that combines LLMs with programming languages like C#, Python, and Java. It allows developers to create AI applications by integrating AI services, data sources, and logic, enabling rapid delivery of enterprise-grade solutions.\n",
    "\n",
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source platform for LLM observability. It provides tracing and monitoring capabilities for AI applications, helping developers debug, analyze, and optimize their AI systems. Langfuse integrates with various tools and frameworks via native integrations, OpenTelemetry, and SDKs.\n",
    "\n",
    "_**Note:** This notebook uses Python. However, this integration also works with other languages supported by Semantic Kernel, such as [C#](https://learn.microsoft.com/en-us/semantic-kernel/concepts/enterprise-readiness/observability/?pivots=programming-language-csharp) and [Java](https://learn.microsoft.com/en-us/semantic-kernel/concepts/enterprise-readiness/observability/?pivots=programming-language-java)._\n",
    "\n",
    "## Get Started\n",
    "\n",
    "We'll walk through a simple example of using Semantic Kernel and integrating it with Langfuse.\n",
    "\n",
    "### Step 1: Install Dependencies\n",
    "\n",
    "Install the necessary packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langfuse openlit semantic-kernel\n",
    "%pip install opentelemetry-sdk opentelemetry-exporter-otlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2: Set Up Environment Variables\n",
    "\n",
    "Set your Langfuse API keys and configure the Langfuse SDK. Replace the placeholders with your actual API keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "# Get your own keys from https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\" \n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # ðŸ‡ªðŸ‡º EU region example\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"  # ðŸ‡ºðŸ‡¸ US region example\n",
    "\n",
    "LANGFUSE_AUTH = base64.b64encode(\n",
    "    f\"{os.environ.get('LANGFUSE_PUBLIC_KEY')}:{os.environ.get('LANGFUSE_SECRET_KEY')}\".encode()\n",
    ").decode()\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = os.environ.get(\"LANGFUSE_HOST\") + \"/api/public/otel\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
    "\n",
    "# your openai key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "os.environ[\"OPENAI_CHAT_MODEL_ID\"] = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure `tracer_provider` and add a span processor to export traces to Langfuse. `OTLPSpanExporter()` uses the endpoint and headers from the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "trace_provider = TracerProvider()\n",
    "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
    "\n",
    "# Sets the global default tracer provider\n",
    "from opentelemetry import trace\n",
    "trace.set_tracer_provider(trace_provider)\n",
    "\n",
    "# Creates a tracer from the global tracer provider\n",
    "tracer = trace.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initialize OpenLit\n",
    "\n",
    "Initialize the [OpenLit instrumentation SDK](https://docs.openlit.io/latest/sdk-configuration) to start capturing OpenTelemetry traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openlit\n",
    "\n",
    "# Initialize OpenLIT instrumentation. The disable_batch flag is set to true to process traces immediately.\n",
    "openlit.init(tracer=tracer, disable_batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a Simple Semantic Kernel Application\n",
    "\n",
    "We'll create a simple Semantic Kernel application where an Assistant agent answers a user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings, OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "\n",
    "prompt = \"\"\"{{$input}}\n",
    "Answer the question above.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"summarize\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user input\", is_required=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "summarize = kernel.add_function(\n",
    "    function_name=\"summarizeFunc\",\n",
    "    plugin_name=\"summarizePlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"What is Langfuse?\"\n",
    "\n",
    "summary = await kernel.invoke(summarize, input=input_text)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Pass Additional Attributes (Optional)\n",
    "\n",
    "Opentelemetry lets you attach a set of attributes to all spans by setting [`set_attribute`](https://opentelemetry.io/docs/languages/python/instrumentation/#add-attributes-to-a-span). This allows you to set properties like a Langfuse Session ID, to group traces into Langfuse Sessions or a User ID, to assign traces to a specific user. You can find a list of all supported attributes in the [here](/docs/opentelemetry/get-started#property-mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Semantic-Kernel-Trace\") as span:\n",
    "    span.set_attribute(\"langfuse.user.id\", \"user-123\")\n",
    "    span.set_attribute(\"langfuse.session.id\", \"123456789\")\n",
    "    span.set_attribute(\"langfuse.tags\", [\"semantic-kernel\", \"demo\"])\n",
    "\n",
    "    input = \"What is Langfuse?\"\n",
    "    output = await kernel.invoke(summarize, input=input_text)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, OpenTelemetry traces in Langfuse can also be modified using the [Python low-level SDK](https://langfuse.com/docs/sdk/python/low-level-sdk). For this, we create a new parent span and fetch the OpenTelemetry `trace_id`. This trace_id is then used to modify the span. Have a look at the [Python low-level SDK](https://langfuse.com/docs/sdk/python/low-level-sdk) for more examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.trace import format_trace_id\n",
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()\n",
    "\n",
    "with tracer.start_as_current_span(\"Semantic-Kernel-Trace\") as span:\n",
    "\n",
    "    input = \"What is Langfuse?\"\n",
    "    output = await kernel.invoke(summarize, input=input_text)\n",
    "    print(output)  \n",
    "    \n",
    "    # Get the trace_id from the Otel span\n",
    "    current_span = trace.get_current_span()\n",
    "    span_context = current_span.get_span_context()\n",
    "    trace_id = span_context.trace_id\n",
    "    formatted_trace_id = format_trace_id(trace_id)\n",
    "\n",
    "    # Update the trace using the low-level Python SDK.\n",
    "    langfuse.trace(\n",
    "        id=formatted_trace_id, \n",
    "        input=input, \n",
    "        output=output,\n",
    "        name = \"docs-retrieval\",\n",
    "        user_id = \"user__935d7d1d-8625-4ef4-8651-544613e7bd22\",\n",
    "        metadata = {\"email\": \"user@langfuse.com\"},\n",
    "        tags = [\"production\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 6: See Traces in Langfuse\n",
    "\n",
    "After running the agent above, you can log in to your Langfuse dashboard and view the traces generated by your Semantic Kernel application. Here is an example screenshot of a trace in Langfuse:\n",
    "\n",
    "![Langfuse Trace](https://langfuse.com/images/cookbook/integration-semantic-kernel/sematric-kernel-example-trace.png)\n",
    "\n",
    "You can also view the public trace here: [Langfuse Trace Example](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/14c7a9f1cc0d7ff16ac1a057a3d45be9?timestamp=2025-02-04T18%3A00%3A53.475Z&observation=cb3f0fb8a2369414)\n",
    "\n",
    "## References\n",
    "\n",
    "- [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started)\n",
    "- [Semantic Kernel OpenTelemetry Docs](https://github.com/microsoft/semantic-kernel/blob/main/dotnet/docs/TELEMETRY.md)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

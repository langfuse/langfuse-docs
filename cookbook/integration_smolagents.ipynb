{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Observability for smolagents with Langfuse\n",
    "description: Learn how to integrate Langfuse with Hugging Face smolagents using OpenTelemetry. This lets you trace and debug your AI agents.\n",
    "category: Integrations\n",
    "---\n",
    "\n",
    "# Integrate Langfuse with smolagents\n",
    "\n",
    "This notebook shows how to monitor and debug your Hugging Face **smolagents** with **Langfuse** using the `SmolagentsInstrumentor`. By the end of this guide, you will be able to trace your smolagents applications with Langfuse.\n",
    "\n",
    "> **What are smolagents?** [smolagents](https://github.com/huggingface/smolagents) is a minimalist and open source AI agent framework developed by Hugging Face, designed to simplify the creation and deployment of powerful agents with just a few lines of code. It focuses on simplicity and efficiency, making it easy for developers to leverage LLMs for various applications.\n",
    "\n",
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open source platform for LLM engineering. It provides tracing and monitoring capabilities for AI agents, helping developers debug, analyze, and optimize their products. Langfuse integrates with various tools and frameworks via native integrations, OpenTelemetry, and SDKs.\n",
    "\n",
    "## Get Started\n",
    "\n",
    "We'll walk through a simple example of using smolagents and integrating it with Langfuse.\n",
    "\n",
    "### Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'smolagents[telemetry]'\n",
    "%pip install opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-smolagents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Up Environment Variables\n",
    "\n",
    "Set your Langfuse API keys and configure the OpenTelemetry endpoint to send traces to Langfuse. Get your Langfuse API keys by signing up for [Langfuse Cloud](https://cloud.langfuse.com) or [self-hosting Langfuse](https://langfuse.com/self-hosting).\n",
    "\n",
    "Also, add your [Hugging Face token](https://huggingface.co/settings/tokens) (`HF_TOKEN`) as an environment variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\n",
    "LANGFUSE_SECRET_KEY=\"sk-lf-...\"\n",
    "LANGFUSE_AUTH=base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel\" # EU data region\n",
    "# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel\" # US data region\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
    "\n",
    "# your Hugging Face token\n",
    "os.environ[\"HF_TOKEN\"] = \"hf_...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initialize the `SmolagentsInstrumentor`\n",
    "\n",
    "Initialize the `SmolagentsInstrumentor` before your application code. Configure `tracer_provider` and add a span processor to export traces to Langfuse. `OTLPSpanExporter()` uses the endpoint and headers from the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "trace_provider = TracerProvider()\n",
    "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
    "\n",
    "SmolagentsInstrumentor().instrument(tracer_provider=trace_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run your smolagent\n",
    "\n",
    "This smolagent example has a manager `CodeAgent` that orchestrates the `managed_agent`, which can perform web searches to gather data. By using tools like `DuckDuckGoSearchTool` and `VisitWebpageTool`, it retrieves the U.S. 2024 growth rate and calculates how many years it will take for the GDP to double.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import (\n",
    "    CodeAgent,\n",
    "    ToolCallingAgent,\n",
    "    DuckDuckGoSearchTool,\n",
    "    VisitWebpageTool,\n",
    "    HfApiModel,\n",
    ")\n",
    "\n",
    "model = HfApiModel(\n",
    "    model_id=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"\n",
    ")\n",
    "\n",
    "search_agent = ToolCallingAgent(\n",
    "    tools=[DuckDuckGoSearchTool(), VisitWebpageTool()],\n",
    "    model=model,\n",
    "    name=\"search_agent\",\n",
    "    description=\"This is an agent that can do web search.\",\n",
    ")\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    managed_agents=[search_agent],\n",
    ")\n",
    "manager_agent.run(\n",
    "    \"How can Langfuse be used to monitor and improve the reasoning and decision-making of smolagents when they execute multi-step tasks, like dynamically adjusting a recipe based on user feedback or available ingredients?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Pass Additional Attributes (Optional)\n",
    "\n",
    "Opentelemetry lets you attach a set of attributes to all spans by setting [`set_attribute`](https://opentelemetry.io/docs/languages/python/instrumentation/#add-attributes-to-a-span). This allows you to set properties like a Langfuse Session ID, to group traces into Langfuse Sessions or a User ID, to assign traces to a specific user. You can find a list of all supported attributes in the [here](/docs/opentelemetry/get-started#property-mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the global default tracer provider\n",
    "from opentelemetry import trace\n",
    "trace.set_tracer_provider(trace_provider)\n",
    "\n",
    "# Creates a tracer from the global tracer provider\n",
    "tracer = trace.get_tracer(\"my.tracer.name\")\n",
    "\n",
    "with tracer.start_as_current_span(\"Smolagent-Trace\") as span:\n",
    "    span.set_attribute(\"langfuse.user.id\", \"user-123\")\n",
    "    span.set_attribute(\"langfuse.session.id\", \"123456789\")\n",
    "    span.set_attribute(\"langfuse.tags\", [\"smolagents\", \"demo\"])\n",
    "    span.set_attribute(\"langfuse.prompt.name\", \"test-1\")\n",
    "\n",
    "    # Create agent\n",
    "    model = HfApiModel()\n",
    "    agent = ToolCallingAgent(\n",
    "        tools=[DuckDuckGoSearchTool()],\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    # Run your agent - the span attributes will be carried through\n",
    "    result = agent.run(\"How can Langfuse be used to monitor and improve the reasoning and decision-making of smolagents when they execute multi-step tasks, like dynamically adjusting a recipe based on user feedback or available ingredients?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: View Traces in Langfuse\n",
    "\n",
    "After running the agent, you can view the traces generated by your smolagents application in [Langfuse](https://cloud.langfuse.com). You should see detailed steps of the LLM interactions, which can help you debug and optimize your AI agent.\n",
    "\n",
    "![smolagents example trace](https://langfuse.com/images/cookbook/integration-smolagents/smolagent_example_trace.png)\n",
    "\n",
    "_[Public example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/ce5160f9bfd5a6cd63b07d2bfcec6f54?timestamp=2025-02-11T09%3A25%3A45.163Z&display=details)_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Experiments\n",
    "\n",
    "You can also test your smolagents using [Langfuse Dataset Experiments](https://langfuse.com/docs/datasets/overview):\n",
    "\n",
    "1. Create a benchmark dataset (with prompt and expected output pairs)\n",
    "2. Run your agent on that dataset\n",
    "3. Compare outputs to the expected results or use an additional scoring mechanism\n",
    "\n",
    "Below, we demonstrate this approach with the [GSM8K dataset](https://huggingface.co/datasets/gsm8k), which contains math questions and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Fetch GSM8K from Hugging Face\n",
    "dataset = load_dataset(\"openai/gsm8k\", 'main', split='train')\n",
    "df = pd.DataFrame(dataset)\n",
    "print(\"First few rows of GSM8K dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a dataset entity in Langfuse to track the runs. Then, we add each item from the dataset to the system. (If youâ€™re not using Langfuse, you might simply store these in your own database or local file for analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "langfuse = Langfuse()\n",
    "\n",
    "langfuse_dataset_name = \"gsm8k_dataset_huggingface\"\n",
    "\n",
    "# Create a dataset in Langfuse\n",
    "langfuse.create_dataset(\n",
    "    name=langfuse_dataset_name,\n",
    "    description=\"GSM8K benchmark dataset uploaded from Huggingface\",\n",
    "    metadata={\n",
    "        \"date\": \"2025-03-10\", \n",
    "        \"type\": \"benchmark\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=langfuse_dataset_name,\n",
    "        input={\"text\": row[\"question\"]},\n",
    "        expected_output={\"text\": row[\"answer\"]},\n",
    "        metadata={\"source_index\": idx}\n",
    "    )\n",
    "    if idx >= 9: # Upload only the first 10 items for demonstration\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Agent on the Dataset\n",
    "\n",
    "We define a helper function `run_smolagent()` that:\n",
    "1. Starts an OpenTelemetry span\n",
    "2. Runs our agent on the prompt\n",
    "3. Records the trace ID in Langfuse\n",
    "\n",
    "Then, we loop over each dataset item, run the agent, and link the trace to the dataset item. We can also attach a quick evaluation score if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.trace import format_trace_id\n",
    "from smolagents import (CodeAgent, HfApiModel, LiteLLMModel)\n",
    "\n",
    "# Example: using HfApiModel or LiteLLMModel to access openai, anthropic, gemini, etc. models:\n",
    "model = HfApiModel()\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    add_base_tools=True\n",
    ")\n",
    "\n",
    "def run_smolagent(question):\n",
    "    with tracer.start_as_current_span(\"Smolagent-Trace\") as span:\n",
    "        span.set_attribute(\"langfuse.tag\", \"dataset-run\")\n",
    "        output = agent.run(question)\n",
    "\n",
    "        current_span = trace.get_current_span()\n",
    "        span_context = current_span.get_span_context()\n",
    "        trace_id = span_context.trace_id\n",
    "        formatted_trace_id = format_trace_id(trace_id)\n",
    "\n",
    "        langfuse_trace = langfuse.trace(\n",
    "            id=formatted_trace_id, \n",
    "            input=question, \n",
    "            output=output\n",
    "        )\n",
    "    return langfuse_trace, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = langfuse.get_dataset(langfuse_dataset_name)\n",
    "\n",
    "# Run our agent against each dataset item (limited to first 10 above)\n",
    "for item in dataset.items:\n",
    "    langfuse_trace, output = run_smolagent(item.input[\"text\"])\n",
    "\n",
    "    # Link the trace to the dataset item for analysis\n",
    "    item.link(\n",
    "        langfuse_trace,\n",
    "        run_name=\"smolagent-notebook-run-01\",\n",
    "        run_metadata={ \"model\": model.model_id }\n",
    "    )\n",
    "\n",
    "    # Optionally, store a quick evaluation score for demonstration\n",
    "    langfuse_trace.score(\n",
    "        name=\"<example_eval>\",\n",
    "        value=1,\n",
    "        comment=\"This is a comment\"\n",
    "    )\n",
    "\n",
    "# Flush data to ensure all telemetry is sent\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat this process with different:\n",
    "- Models (OpenAI GPT, local LLM, etc.)\n",
    "- Tools (search vs. no search)\n",
    "- Prompts (different system messages)\n",
    "\n",
    "Then compare them side-by-side in your observability tool:\n",
    "\n",
    "![Dataset run overview](https://langfuse.com/images/cookbook/huggingface-agent-course/dataset_runs.png)\n",
    "![Dataset run comparison](https://langfuse.com/images/cookbook/huggingface-agent-course/dataset-run-comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started)\n",
    "- [smolagents Documentation](https://huggingface.co/docs/smolagents/en/index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Observability for smolagents with Langfuse\n",
    "description: Learn how to integrate Langfuse with Hugging Face smolagents using OpenTelemetry. This lets you trace and debug your AI agents.\n",
    "---\n",
    "\n",
    "# Integrate Langfuse with smolagents\n",
    "\n",
    "This notebook shows how to monitor and debug your Hugging Face **smolagents** with **Langfuse** using the `SmolagentsInstrumentor`. By the end of this guide, you will be able to trace your smolagents applications with Langfuse.\n",
    "\n",
    "> **What are smolagents?** [smolagents](https://github.com/huggingface/smolagents) is a minimalist and open-source AI agent framework developed by Hugging Face, designed to simplify the creation and deployment of powerful agents with just a few lines of code. It focuses on simplicity and efficiency, making it easy for developers to leverage LLMs for various applications.\n",
    "\n",
    "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open-source platform for LLM engineering. It provides tracing and monitoring capabilities for AI agents, helping developers debug, analyze, and optimize their products. Langfuse integrates with various tools and frameworks via native integrations, OpenTelemetry, and SDKs.\n",
    "\n",
    "## Get Started\n",
    "\n",
    "We'll walk through a simple example of using smolagents and integrating it with Langfuse.\n",
    "\n",
    "### Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'smolagents[telemetry]' arize-phoenix-otel\n",
    "%pip install opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-smolagents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Up Environment Variables\n",
    "\n",
    "Set your Langfuse API keys and configure the OpenTelemetry endpoint to send traces to Langfuse. Get your Langfuse API keys by signing up for [Langfuse Cloud](https://cloud.langfuse.com) or [self-hosting Langfuse](https://langfuse.com/self-hosting).\n",
    "\n",
    "Also, add your [Hugging Face token](https://huggingface.co/settings/tokens) (`HF_TOKEN`) as an environment variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY = \"pk-lf-...\"\n",
    "LANGFUSE_SECRET_KEY = \"sk-lf-...\"\n",
    "LANGFUSE_AUTH = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "\n",
    "# your Hugging Face token\n",
    "os.environ[\"HF_TOKEN\"] = \"hf_...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initialize the `SmolagentsInstrumentor`\n",
    "\n",
    "Initialize the Arize Phoenix module [`register()`](https://docs.arize.com/phoenix/tracing/how-to-tracing/setup-tracing-python) by passing in the protocol, endpoint, and headers. The use the `SmolagentsInstrumentor` to instrument your smolagents application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Phoenix Project: default\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: https://cloud.langfuse.com/api/public/otel/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {'authorization': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "\n",
    "register(protocol=\"http/protobuf\", \n",
    "         endpoint = \"https://cloud.langfuse.com/api/public/otel/v1/traces\", \n",
    "         headers = {\"Authorization\": f\"Basic {LANGFUSE_AUTH}\"}\n",
    "         )\n",
    "\n",
    "SmolagentsInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run your smolagent\n",
    "\n",
    "This smolagent example has a manager `CodeAgent` that orchestrates the `managed_agent`, which can perform web searches to gather data. By using tools like `DuckDuckGoSearchTool` and `VisitWebpageTool`, it retrieves the U.S. 2024 growth rate and calculates how many years it will take for the GDP to double.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import (\n",
    "    CodeAgent,\n",
    "    ToolCallingAgent,\n",
    "    DuckDuckGoSearchTool,\n",
    "    VisitWebpageTool,\n",
    "    HfApiModel,\n",
    ")\n",
    "\n",
    "model = HfApiModel(\n",
    "    model_id=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"\n",
    ")\n",
    "\n",
    "search_agent = ToolCallingAgent(\n",
    "    tools=[DuckDuckGoSearchTool(), VisitWebpageTool()],\n",
    "    model=model,\n",
    "    name=\"search_agent\",\n",
    "    description=\"This is an agent that can do web search.\",\n",
    ")\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    managed_agents=[search_agent],\n",
    ")\n",
    "manager_agent.run(\n",
    "    \"How can Langfuse be used to monitor and improve the reasoning and decision-making of smolagents when they execute multi-step tasks, like dynamically adjusting a recipe based on user feedback or available ingredients?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: View Traces in Langfuse\n",
    "\n",
    "After running the agent, you can view the traces generated by your smolagents application in [Langfuse](https://cloud.langfuse.com). You should see detailed steps of the LLM interactions, which can help you debug and optimize your AI agent.\n",
    "\n",
    "![smolagents example trace](https://langfuse.com/images/cookbook/integration-smolagents/smolagent_example_trace.png)\n",
    "\n",
    "_[Public example trace in Langfuse](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/ce5160f9bfd5a6cd63b07d2bfcec6f54?timestamp=2025-02-11T09%3A25%3A45.163Z&display=details)_\n",
    "\n",
    "## References\n",
    "\n",
    "- [Langfuse OpenTelemetry Docs](https://langfuse.com/docs/opentelemetry/get-started)\n",
    "- [smolagents Documentation](https://huggingface.co/docs/smolagents/en/index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

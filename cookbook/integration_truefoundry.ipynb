{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCa73sP93xSj"
      },
      "source": [
        "<!-- NOTEBOOK_METADATA source: \"âš ï¸ Jupyter Notebook\" title: \"Integrate Portkey LLM Gateway with Langfuse\" sidebarTitle: \"Portkey\" logo: \"/images/integrations/portkey_icon.svg\" description: \"Guide on using Portkey's AI gateway to access 250+ LLM models with Langfuse via the OpenAI SDK.\" category: \"Integrations\" -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nHaHc3b3xSk"
      },
      "source": [
        "# Truefoundry AI Gateway Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaXrsG8Q3xSl"
      },
      "source": [
        "This guide shows you how to integrate Truefoundry's AI gateway with Langfuse. Truefoundry's API endpoints are fully [compatible](https://docs.truefoundry.com/gateway/chat-completions-overview) with the OpenAI SDK, allowing you to trace and monitor your AI applications seamlessly.\n",
        "\n",
        "We will access the TrueFoundry gateway through the Langfuse SDK layer, which will send your traces to Langfuse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpK4ctfAsVYs"
      },
      "source": [
        "## What is Truefoundry?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVKtUonV3xSl"
      },
      "source": [
        "> [TrueFoundry](https://www.truefoundry.com/) is an enterprise-grade AI Gateway and control plane that lets you deploy, govern, and monitor any LLM or Gen-AI workload behind a single OpenAI-compatible APIâ€”bringing rate-limiting, cost controls, observability, and on-prem support to production AI applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT7e2ers3xSl"
      },
      "source": [
        "> **What is Langfuse?** [Langfuse](https://langfuse.com) is an open source LLM engineering platform that helps teams trace LLM calls, monitor performance, and debug issues in their AI applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K352a8ShtBJv"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqu2TXK5s-DC"
      },
      "source": [
        "Before integrating Langfuse with TrueFoundry, ensure you have:\n",
        "1. TrueFoundry Account: Create a [Truefoundry account](https://www.truefoundry.com/register) with atleast one model provider and generate a Personal Access Token by following the instructions in [quick start](https://docs.truefoundry.com/gateway/quick-start) and [generating tokens](https://docs.truefoundry.com/gateway/authentication)\n",
        "2. Langfuse Account: Sign up for a free [Langfuse Cloud account](https://cloud.langfuse.com/) or self-host Langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install openai langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHm1jDq23xSm"
      },
      "source": [
        "## Step 2: Set Up Environment Variables\n",
        "\n",
        "Next, set up your Langfuse API keys. You can get these keys by signing up for a free [Langfuse Cloud](https://cloud.langfuse.com/) account or by [self-hosting Langfuse](https://langfuse.com/self-hosting). These environment variables are essential for the Langfuse client to authenticate and send data to your Langfuse project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w5z-wci23xSm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Langfuse Configuration\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # ðŸ‡ªðŸ‡º EU region\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"  # ðŸ‡ºðŸ‡¸ US region\n",
        "\n",
        "# TrueFoundry Configuration\n",
        "os.environ[\"TRUEFOUNDRY_API_KEY\"] = \"your-truefoundry-token\"\n",
        "os.environ[\"TRUEFOUNDRY_BASE_URL\"] = \"https://your-control-plane.truefoundry.cloud/api/llm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NJuNI3KB3xSm",
        "outputId": "c1b24c54-1ba3-46fb-f5e5-0658e016ecbb"
      },
      "outputs": [
        {
          "ename": "UnauthorizedError",
          "evalue": "status_code: 401, body: {'message': \"Invalid credentials. Confirm that you've configured the correct host.\"}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnauthorizedError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangfuse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_client\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Test Langfuse authentication\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m get_client()\u001b[38;5;241m.\u001b[39mauth_check()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langfuse/_client/client.py:1769\u001b[0m, in \u001b[0;36mLangfuse.auth_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check if the provided credentials (public and secret key) are valid.\u001b[39;00m\n\u001b[1;32m   1761\u001b[0m \n\u001b[1;32m   1762\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;124;03m    This method is blocking. It is discouraged to use it in production code.\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1769\u001b[0m     projects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mprojects\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m   1770\u001b[0m     langfuse_logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1771\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuth check successful, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(projects\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m projects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1772\u001b[0m     )\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(projects\u001b[38;5;241m.\u001b[39mdata) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langfuse/api/resources/projects/client.py:69\u001b[0m, in \u001b[0;36mProjectsClient.get\u001b[0;34m(self, request_options)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(pydantic_v1\u001b[38;5;241m.\u001b[39mparse_obj_as(typing\u001b[38;5;241m.\u001b[39mAny, _response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedError(\n\u001b[1;32m     70\u001b[0m         pydantic_v1\u001b[38;5;241m.\u001b[39mparse_obj_as(typing\u001b[38;5;241m.\u001b[39mAny, _response\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m     71\u001b[0m     )  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AccessDeniedError(\n\u001b[1;32m     74\u001b[0m         pydantic_v1\u001b[38;5;241m.\u001b[39mparse_obj_as(typing\u001b[38;5;241m.\u001b[39mAny, _response\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m     75\u001b[0m     )  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
            "\u001b[0;31mUnauthorizedError\u001b[0m: status_code: 401, body: {'message': \"Invalid credentials. Confirm that you've configured the correct host.\"}"
          ]
        }
      ],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "# Test Langfuse authentication\n",
        "get_client().auth_check()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT023zjp3xSn"
      },
      "source": [
        "## Step 3: Use Langfuse OpenAI Drop-in Replacement\n",
        "\n",
        "Use Langfuse's OpenAI-compatible client to capture and trace every request routed through the TrueFoundry AI Gateway. Detailed steps for configuring the gateway and generating virtual LLM keys are available in the [TrueFoundry documentation](https://docs.truefoundry.com/gateway/langfuse)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mje3Ste3xSn"
      },
      "outputs": [],
      "source": [
        "from langfuse.openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Initialize OpenAI client with TrueFoundry Gateway\n",
        "client = OpenAI(\n",
        "    api_key=os.environ[\"TRUEFOUNDRY_API_KEY\"],\n",
        "    base_url=os.environ[\"TRUEFOUNDRY_BASE_URL\"]  # Base URL from unified code snippet\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snT4qt-e3xSn"
      },
      "source": [
        "## Step 4: Run an Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwTS3Z3_3xSn"
      },
      "outputs": [],
      "source": [
        "# Make a request through TrueFoundry Gateway with Langfuse tracing\n",
        "response = client.chat.completions.create(\n",
        "    model=\"openai-main/gpt-4o\",  # Paste the model ID you copied from TrueFoundry Gateway\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant specialized in explaining AI concepts.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Why does an AI gateway help enterprises?\"},\n",
        "    ],\n",
        "    max_tokens=500,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "# Ensure all traces are sent to Langfuse\n",
        "langfuse = get_client()\n",
        "langfuse.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwVNFN_u3xSn"
      },
      "source": [
        "## Step 5: See Traces in Langfuse\n",
        "\n",
        "After running the example, log in to Langfuse to view the detailed traces, including:\n",
        "\n",
        "- Request parameters\n",
        "- Response content\n",
        "- Token usage and latency metrics\n",
        "- LLM model information through Truefoundry gateway\n",
        "\n",
        "![Langfuse Trace Example](https://drive.google.com/uc?export=view&id=1oJ2AX893rvCoWc4ybEG-MvFCzevCF11q)\n",
        "\n",
        "> **Note**: All other features of Langfuse will work as expected, including prompt management, evaluations, custom dashboards, and advanced observability features. The TrueFoundry integration seamlessly supports the full Langfuse feature set.\n",
        "<!-- STEPS_END -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6yXrarr3xSn"
      },
      "source": [
        "<!-- MARKDOWN_COMPONENT name: \"LearnMore\" path: \"@/components-mdx/integration-learn-more.mdx\" -->"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

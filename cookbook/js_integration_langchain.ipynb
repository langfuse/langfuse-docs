{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec41aeab-9670-478d-a093-438eeb39883f",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"⚠️ Jupyter Notebook\" title: \"Cookbook - Langchain Integration (JS/TS)\" sidebarTitle: \"Langchain Integration (JS/TS)\" description: \"Cookbook with examples of the Langfuse Integration for Langchain (JS/TS).\" category: \"Examples\" -->\n",
    "\n",
    "# Cookbook: Langchain Integration (JS/TS)\n",
    "\n",
    "This is a cookbook with examples of the Langfuse integration for Langchain (JS/TS).\n",
    "\n",
    "Follow the [integration guide](https://langfuse.com/integrations/frameworks/langchain) to add this integration to your Langchain project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cd090-63d3-450c-ae95-8c16239cdff8",
   "metadata": {},
   "source": [
    "<!-- STEPS_START -->\n",
    "## Set Up Environment\n",
    "\n",
    "Get your Langfuse API keys by signing up for [Langfuse Cloud](https://cloud.langfuse.com/) or [self-hosting Langfuse](https://langfuse.com/self-hosting). You’ll also need your OpenAI API key.\n",
    "\n",
    "> **Note**: This cookbook uses **Deno.js** for execution, which requires different syntax for importing packages and setting environment variables. For Node.js applications, the setup process is similar but uses standard `npm` packages and `process.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e512873",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Langfuse authentication keys\n",
    "Deno.env.set(\"LANGFUSE_PUBLIC_KEY\", \"pk-lf-***\");\n",
    "Deno.env.set(\"LANGFUSE_SECRET_KEY\", \"sk-lf-***\");\n",
    "\n",
    "// Langfuse host configuration\n",
    "// For US data region, set this to \"https://us.cloud.langfuse.com\"\n",
    "Deno.env.set(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "\n",
    "// Set environment variables using Deno-specific syntax\n",
    "Deno.env.set(\"OPENAI_API_KEY\", \"sk-proj-***\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1310a",
   "metadata": {},
   "source": [
    "With the environment variables set, we can now initialize the `langfuseSpanProcessor` which is passed to the main OpenTelemetry SDK that orchestrates tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import required dependencies\n",
    "import 'npm:dotenv/config';\n",
    "import { NodeSDK } from \"npm:@opentelemetry/sdk-node\";\n",
    "import { LangfuseSpanProcessor } from \"npm:@langfuse/otel\";\n",
    " \n",
    "// Export the processor to be able to flush it later\n",
    "// This is important for ensuring all spans are sent to Langfuse\n",
    "export const langfuseSpanProcessor = new LangfuseSpanProcessor({\n",
    "    publicKey: process.env.LANGFUSE_PUBLIC_KEY!,\n",
    "    secretKey: process.env.LANGFUSE_SECRET_KEY!,\n",
    "    baseUrl: process.env.LANGFUSE_HOST ?? 'https://cloud.langfuse.com', // Default to cloud if not specified\n",
    "    environment: process.env.NODE_ENV ?? 'development', // Default to development if not specified\n",
    "  });\n",
    " \n",
    "// Initialize the OpenTelemetry SDK with our Langfuse processor\n",
    "const sdk = new NodeSDK({\n",
    "  spanProcessors: [langfuseSpanProcessor],\n",
    "});\n",
    " \n",
    "// Start the SDK to begin collecting telemetry\n",
    "// The warning about crypto module is expected in Deno and doesn't affect basic tracing functionality. Media upload features will be disabled, but all core tracing works normally\n",
    "sdk.start();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f633097-159f-4d3a-9db4-f01f76b95990",
   "metadata": {},
   "source": [
    "## Step 2: Instantiate the CallbackHandler\n",
    "\n",
    "Instantiate the CallbackHandler and pass it to your chain’s `.invoke()` or `.stream()` method in the callbacks array. All operations within the chain will be traced as nested observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d93516c9-ec31-4ddf-9fcb-fbbdb6274d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { CallbackHandler } from \"npm:@langfuse/langchain\";\n",
    " \n",
    "// 1. Initialize the Langfuse callback handler\n",
    "const langfuseHandler = new CallbackHandler({\n",
    "  sessionId: \"user-session-123\",\n",
    "  userId: \"user-abc\",\n",
    "  tags: [\"langchain-test\"],\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59615d2d-179e-4234-848f-41db0a6ddd85",
   "metadata": {},
   "source": [
    "## Step 3: Langchain interfaces\n",
    "\n",
    "Langfuse supports the following Langchain JS interfaces\n",
    "\n",
    "- invoke\n",
    "- stream\n",
    "\n",
    "For this section we will use a very simple example prompt (from Langchain JS [docs](https://js.langchain.com/docs/expression_language/interface)) and ChatOpenAI. Langfuse works with any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f73d1028-810f-47e2-a026-6e67330adc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"npm:@langchain/openai\"\n",
    "import { PromptTemplate } from \"npm:@langchain/core/prompts\"\n",
    "\n",
    "const model = new ChatOpenAI({});\n",
    "const promptTemplate = PromptTemplate.fromTemplate(\n",
    "  \"Tell me a joke about {topic}\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11f504-7780-47b0-8b87-c6858a632c3d",
   "metadata": {},
   "source": [
    "### using `invoke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7b4c3-3894-485e-8bb2-2efbeb94bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableSequence } from \"npm:@langchain/core/runnables\";\n",
    "\n",
    "const chain = RunnableSequence.from([promptTemplate, model]);\n",
    "\n",
    "const res = await chain.invoke(\n",
    "    { topic: \"bears\" },\n",
    "    { callbacks: [langfuseHandler] }\n",
    ");\n",
    "\n",
    "console.log(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e1865-3cef-4f11-84dc-cf2377851ae3",
   "metadata": {},
   "source": [
    "### using `stream`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d68757-98aa-499c-a5b8-b8cc6a45e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "const chain = promptTemplate.pipe(model);\n",
    "const stream = await chain.stream(\n",
    "    { topic: \"bears\" },\n",
    "    { callbacks: [langfuseHandler] }\n",
    ");\n",
    "for await (const chunk of stream) {\n",
    "  console.log(chunk?.content);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f65da",
   "metadata": {},
   "source": [
    "## Step 4: Explore the trace in Langfuse\n",
    "\n",
    "In the Langfuse interface, you can see a detailed trace of all steps in the Langchain application.\n",
    "\n",
    "![Langfuse Trace](https://langfuse.com/images/cookbook/example-js-sdk/js_integration_langchain_trace.png)\n",
    "\n",
    "[Public trace in the Langfuse UI](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/8633501eb9ad671eb65c7b131c52c427?display=details%3Ftimestamp%3D2025-08-25T13%3A26%3A28.319Z&observation=6a6e9b25ddfe845f)\n",
    "<!-- STEPS_END -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

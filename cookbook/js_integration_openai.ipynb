{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf4e4bd-070f-42d2-8aeb-427fd8b509cf",
   "metadata": {},
   "source": [
    "<!-- NOTEBOOK_METADATA source: \"⚠️ Jupyter Notebook\" title: \"Cookbook - OpenAI Integration (JS/TS)\" sidebarTitle: \"OpenAI Integration (JS/TS)\" description: \"Learn how to use Langfuse for open source observability/tracing of the OpenAI JS SDK by adding `observeOpenAI`.\" category: \"Examples\" -->\n",
    "\n",
    "# Cookbook: OpenAI Integration (JS/TS)\n",
    "\n",
    "This cookbook provides examples of the Langfuse Integration for OpenAI (JS/TS). Follow the [integration guide](https://langfuse.com/integrations/model-providers/openai-js) to add this integration to your OpenAI project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecf9cd-490a-4f85-803a-b2155677f581",
   "metadata": {},
   "source": [
    "<!-- STEPS_START -->\n",
    "## Set Up Environment\n",
    "\n",
    "Get your Langfuse API keys by signing up for [Langfuse Cloud](https://cloud.langfuse.com/) or [self-hosting Langfuse](https://langfuse.com/self-hosting). You’ll also need your OpenAI API key.\n",
    "\n",
    "\n",
    "> **Note**: This cookbook uses **Deno.js** for execution, which requires different syntax for importing packages and setting environment variables. For Node.js applications, the setup process is similar but uses standard `npm` packages and `process.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf83d5-7a20-4ae1-a5be-4a8f276a213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Langfuse authentication keys\n",
    "Deno.env.set(\"LANGFUSE_PUBLIC_KEY\", \"pk-lf-***\");\n",
    "Deno.env.set(\"LANGFUSE_SECRET_KEY\", \"sk-lf-***\");\n",
    "\n",
    "// Langfuse host configuration\n",
    "// For US data region, set this to \"https://us.cloud.langfuse.com\"\n",
    "Deno.env.set(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "\n",
    "// Set environment variables using Deno-specific syntax\n",
    "Deno.env.set(\"OPENAI_API_KEY\", \"sk-proj-***\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c354d",
   "metadata": {},
   "source": [
    "With the environment variables set, we can now initialize the `langfuseSpanProcessor` which is passed to the main OpenTelemetry SDK that orchestrates tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad25652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import required dependencies\n",
    "import 'npm:dotenv/config';\n",
    "import { NodeSDK } from \"npm:@opentelemetry/sdk-node\";\n",
    "import { LangfuseSpanProcessor } from \"npm:@langfuse/otel@^4.0.0-beta.8\";\n",
    " \n",
    "// Export the processor to be able to flush it later\n",
    "// This is important for ensuring all spans are sent to Langfuse\n",
    "export const langfuseSpanProcessor = new LangfuseSpanProcessor({\n",
    "    publicKey: process.env.LANGFUSE_PUBLIC_KEY!,\n",
    "    secretKey: process.env.LANGFUSE_SECRET_KEY!,\n",
    "    baseUrl: process.env.LANGFUSE_HOST ?? 'https://cloud.langfuse.com', // Default to cloud if not specified\n",
    "    environment: process.env.NODE_ENV ?? 'development', // Default to development if not specified\n",
    "  });\n",
    " \n",
    "// Initialize the OpenTelemetry SDK with our Langfuse processor\n",
    "const sdk = new NodeSDK({\n",
    "  spanProcessors: [langfuseSpanProcessor],\n",
    "});\n",
    " \n",
    "// Start the SDK to begin collecting telemetry\n",
    "// The warning about crypto module is expected in Deno and doesn't affect basic tracing functionality. Media upload features will be disabled, but all core tracing works normally\n",
    "sdk.start();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e2da1c-ea23-493e-9c74-d212fcf7b2ec",
   "metadata": {},
   "source": [
    "## Example 1: Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db6bdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenAI from \"npm:openai@^4.0.0\";\n",
    "import { observeOpenAI } from \"npm:@langfuse/openai@^4.0.0-beta.8\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0db9215-4fa9-4e3a-aeb5-bddf48192ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Initialize OpenAI client with observerOpenAI wrapper\n",
    "const openai = observeOpenAI(new OpenAI());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a00305-0209-4de7-83c5-b87953833a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenAI from \"npm:openai\";\n",
    "import { observeOpenAI } from \"npm:@langfuse/openai\";\n",
    "\n",
    "// Configured via environment variables, see above\n",
    "const openai = observeOpenAI(new OpenAI());\n",
    "\n",
    "const completion = await openai.chat.completions.create({\n",
    "  model: 'gpt-4o',\n",
    "  messages: [{ role: \"system\", content: \"Tell me a joke.\" }],\n",
    "  max_tokens: 100,\n",
    "});\n",
    "\n",
    "console.log(completion.choices[0]?.message.content);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d16d9-de98-4f10-8212-fdf43891bf05",
   "metadata": {},
   "source": [
    "![Langfuse Trace](https://langfuse.com/images/cookbook/example-js-sdk/js_integration_openai_simple.png)\n",
    "\n",
    "[Public trace in the Langfuse UI](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/a3568a4051958f944016ad65ffed0fdc?timestamp=2025-08-25T14%3A19%3A17.724Z&display=details&observation=bbb60b9338f261ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce01c8-cca2-4e7f-b4ef-15640b89a45a",
   "metadata": {},
   "source": [
    "## Example 2: Chat completion (streaming)\n",
    "\n",
    "Simple example using OpenAI streaming, passing custom parameters to rename the generation and add a tag to the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b727de-67bf-44c5-93bf-2a9c562794ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenAI from \"npm:openai\";\n",
    "import { observeOpenAI } from \"npm:@langfuse/openai\";\n",
    "\n",
    "// Initialize OpenAI SDK with Langfuse\n",
    "const openaiWithLangfuse = observeOpenAI(new OpenAI(), { generationName: \"OpenAI Stream Trace\", tags: [\"stream\"]} )\n",
    "\n",
    "// Call OpenAI\n",
    "const stream = await openaiWithLangfuse.chat.completions.create({\n",
    "  model: 'gpt-4o',\n",
    "  messages: [{ role: \"system\", content: \"Tell me a joke.\" }],\n",
    "  stream: true,\n",
    "});\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "    const content = chunk.choices[0]?.delta?.content || '';\n",
    "    console.log(content);\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93ac08-70b1-4d10-b402-5a766918199d",
   "metadata": {},
   "source": [
    "[Public trace in the Langfuse UI](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/5be1f917ea127f535ddf39d84b42bbf9?timestamp=2025-08-25T14:22:44.892Z&display=details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b0944-ab82-4769-9e6c-a5dda0e5ad9b",
   "metadata": {},
   "source": [
    "## Example 3: Add additional metadata and parameters\n",
    "\n",
    "The trace is a core object in Langfuse, and you can add rich metadata to it. Refer to the JS/TS SDK documentation and the [reference](https://js.reference.langfuse.com/functions/langfuse.observeOpenAI.html) for comprehensive details.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "- Assigning a custom name to identify a specific trace type\n",
    "- Enabling user-level tracking\n",
    "- Tracking experiments through versions and releases\n",
    "- Adding custom metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd7c881-6ead-45e8-a118-090defd8f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenAI from \"npm:openai\";\n",
    "import { observeOpenAI } from \"npm:langfuse\";\n",
    "\n",
    "// Initialize OpenAI SDK with Langfuse and custom parameters\n",
    "const openaiWithLangfuse = observeOpenAI(new OpenAI(), {\n",
    "    generationName: \"OpenAI Custom Trace\",\n",
    "    metadata: {env: \"dev\"},\n",
    "    sessionId: \"session-id\",\n",
    "    userId: \"user-id\",\n",
    "    tags: [\"custom\"],\n",
    "    version: \"0.0.1\",\n",
    "    release: \"beta\",\n",
    "})\n",
    "\n",
    "// Call OpenAI\n",
    "const completion = await openaiWithLangfuse.chat.completions.create({\n",
    "  model: 'gpt-4o',\n",
    "  messages: [{ role: \"system\", content: \"Tell me a joke.\" }],\n",
    "  max_tokens: 100,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657fc32-c4de-481c-8862-f6168c065f9f",
   "metadata": {},
   "source": [
    "[Public trace in the Langfuse UI](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/5aba0399-d640-4fc1-8cbc-42ebf688b189?timestamp=2025-08-25T14:23:43.007Z&display=details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df27fc5-98ca-404d-bdd4-fec06445360a",
   "metadata": {},
   "source": [
    "## Example 4: Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f47eaa4f-e30d-40d4-a264-15796f3fd74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20degC\n"
     ]
    }
   ],
   "source": [
    "import OpenAI from \"npm:openai\";\n",
    "import { observeOpenAI } from \"npm:@langfuse/openai\";\n",
    "\n",
    "// Initialize OpenAI SDK with Langfuse\n",
    "const openaiWithLangfuse = observeOpenAI(new OpenAI(), { generationName: \"OpenAI FunctionCall Trace\", tags: [\"function\"]} )\n",
    "\n",
    "// Define custom function\n",
    "async function getWeather(location: string) {\n",
    "  if (location === \"Berlin\")\n",
    "    {return \"20degC\"}\n",
    "  else \n",
    "    {return \"unknown\"}\n",
    "}\n",
    "\n",
    "// Create function specification required for OpenAI API\n",
    "const functions = [{\n",
    "    type: \"function\",\n",
    "    function: {\n",
    "        name: \"getWeather\",\n",
    "        description: \"Get the current weather in a given location\",\n",
    "        parameters: {\n",
    "            type: \"object\",\n",
    "            properties: {\n",
    "                location: {\n",
    "                    type: \"string\",\n",
    "                    description: \"The city, e.g. San Francisco\",\n",
    "                },\n",
    "            },\n",
    "            required: [\"location\"],\n",
    "        },\n",
    "    },\n",
    "}]\n",
    "\n",
    "// Call OpenAI\n",
    "const res = await openaiWithLangfuse.chat.completions.create({\n",
    "    model: 'gpt-4o',\n",
    "    messages: [{ role: 'user', content: \"What's the weather like in Berlin today\"}],\n",
    "    tool_choice: \"auto\",\n",
    "    tools: functions,\n",
    "})\n",
    "\n",
    "const tool_call = res.choices[0].message.tool_calls;\n",
    "if (tool_call[0].function.name === \"getWeather\") {\n",
    "    const argsStr = tool_call[0].function.arguments;\n",
    "    const args = JSON.parse(argsStr); \n",
    "    const answer = await getWeather(args[\"location\"]);\n",
    "    console.log(answer);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448017d3-b925-483f-b16b-e5c735d7e0c6",
   "metadata": {},
   "source": [
    "[Public trace in the Langfuse UI](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/8efcae3385d3ecff4c6f5a8ef9ca8e60?timestamp=2025-08-25T14%3A24%3A59.978Z&display=details&observation=e3f0e48874fdfa83)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84acbae-90c9-4a46-9ad4-130d64406318",
   "metadata": {},
   "source": [
    "## Example 5: Group multiple generations into a single trace\n",
    "\n",
    "Use the context manager of the Langfuse TypeScript SDK to group two OpenAI generations together and update the top level span. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f73952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { startObservation, startActiveObservation } from \"npm:@langfuse/tracing@^4.0.0-beta.8\";\n",
    "import OpenAI from \"npm:openai\";\n",
    "import { observeOpenAI } from \"npm:@langfuse/openai\";\n",
    "\n",
    "const country = \"Germany\";\n",
    " \n",
    "await startActiveObservation(\"user-request\", async (span) => {\n",
    " \n",
    "  const capital = (\n",
    "    await observeOpenAI(new OpenAI(), {\n",
    "      parent: span,\n",
    "      generationName: \"get-capital\",\n",
    "    }).chat.completions.create({\n",
    "      model: \"gpt-4o\",\n",
    "      messages: [\n",
    "        { role: \"system\", content: \"What is the capital of the country?\" },\n",
    "        { role: \"user\", content: country },\n",
    "      ],\n",
    "    })\n",
    "  ).choices[0].message.content;\n",
    " \n",
    "  const poem = (\n",
    "    await observeOpenAI(new OpenAI(), {\n",
    "      parent: span,\n",
    "      generationName: \"generate-poem\",\n",
    "    }).chat.completions.create({\n",
    "      model: \"gpt-4o\",\n",
    "      messages: [\n",
    "        {\n",
    "          role: \"system\",\n",
    "          content: \"You are a poet. Create a poem about this city.\",\n",
    "        },\n",
    "        { role: \"user\", content: capital },\n",
    "      ],\n",
    "    })\n",
    "  ).choices[0].message.content;\n",
    "\n",
    "  // Update trace\n",
    "  span.updateTrace({\n",
    "    name:\"City poem generator\",\n",
    "    tags: [\"updated\"],\n",
    "    metadata: {\"env\": \"development\"},\n",
    "    release: \"v0.0.2\",\n",
    "    input: country,\n",
    "    output: poem,\n",
    "  });\n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b2361-9df6-4160-95a5-1f3eab7af9bd",
   "metadata": {},
   "source": [
    "![Langfuse Trace](https://langfuse.com/images/cookbook/example-js-sdk/js_integration_openai_grouped.png)\n",
    "\n",
    "[Public trace in the Langfuse UI](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e0a2f2b374a58cf9b4548240f879fc71?timestamp=2025-08-25T14:39:41.599Z&display=details)\n",
    "<!-- STEPS_END -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

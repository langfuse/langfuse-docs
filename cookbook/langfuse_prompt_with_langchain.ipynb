{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "description: Examplel on how to use Langfuse Prompt Management in Langchain applications in Python\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc7JQAashNea"
      },
      "source": [
        "# Example: Langfuse Prompt Management with Langchain in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qGbaVDEiK6o"
      },
      "source": [
        "[Langfuse Prompt Management](https://langfuse.com/docs/prompts) helps to version control and manage prompts collaboratively in one place. This example demostrates how to use prompts managed in Langfuse to run Langchain applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwyrmsWZhsFW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJzIBAVKKdoD",
        "outputId": "842bf588-0203-4961-d818-5d17ef5cf86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langfuse in /usr/local/lib/python3.10/dist-packages (2.18.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from langfuse) (2.2.1)\n",
            "Requirement already satisfied: chevron<0.15.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from langfuse) (0.14.0)\n",
            "Requirement already satisfied: httpx<0.26.0,>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from langfuse) (0.25.2)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langfuse) (23.2)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from langfuse) (2.6.1)\n",
            "Requirement already satisfied: wrapt==1.14 in /usr/local/lib/python3.10/dist-packages (from langfuse) (1.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.24)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.27)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.10)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.15.4->langfuse) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.15.4->langfuse) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.26.0,>=0.15.4->langfuse) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Installing collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.0.8 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse langchain langchain-openai openai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f8m2HYAKfJz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# get keys for your project from https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"\"\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"\"\n",
        "\n",
        "# your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# if you do not use Langfuse Cloud\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"http://localhost:3000\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ABMEWVCKsPW",
        "outputId": "eb8abbd4-985b-48a6-84de-815b39d5c2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "from langfuse import Langfuse\n",
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "langfuse = Langfuse()\n",
        "\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# optional, verify that Langfuse is configured correctly\n",
        "print(langfuse.auth_check())\n",
        "print(langfuse_handler.auth_check())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdHpmb6vLAiW"
      },
      "source": [
        "## Create Prompt in Langfuse\n",
        "\n",
        "- `Name` that identifies the prompt in Langfuse Prompt Management\n",
        "- Prompt with prompt template incl. `{{input variables}}`\n",
        "- Config including `model_name` and `temperature`\n",
        "- `is_active` to immediately use prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX54t3k0gM5w",
        "outputId": "ac24d2bb-5150-4f24-87b1-18e2c02615ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langfuse.model.PromptClient at 0x7ae4159fdbd0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "langfuse.create_prompt(\n",
        "    name=\"event-planner\",\n",
        "    prompt=\n",
        "    \"Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. \"\n",
        "    \"The event will be held in {{Location}} on {{Date}}. \"\n",
        "    \"Consider the following factors: audience, budget, venue, catering options, and entertainment. \"\n",
        "    \"Provide a detailed plan including potential vendors and logistics.\",\n",
        "    config={\n",
        "        \"model\":\"gpt-3.5-turbo-1106\",\n",
        "        \"temperature\": 0,\n",
        "    },\n",
        "    is_active=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INsgUGXEICYP"
      },
      "source": [
        "## Get current prompt version from Langfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0nYuMLzIJeb",
        "outputId": "589a5013-b59f-4f70-8f2b-7e0801dacf45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. The event will be held in {{Location}} on {{Date}}. Consider the following factors: audience, budget, venue, catering options, and entertainment. Provide a detailed plan including potential vendors and logistics.\n"
          ]
        }
      ],
      "source": [
        "# Get current production version of prompt\n",
        "langfuse_prompt = langfuse.get_prompt(\"event-planner\")\n",
        "print(langfuse_prompt.prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahvMYvS1RsF9"
      },
      "source": [
        "## Extract Langfuse prompt template prompt and config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQwfPI42IZM0"
      },
      "source": [
        "As you saw earlier, Langfuse declares input variables of prompt templates with double brackets (`{{input variable}}`). Langchain, on the other side, uses single brackets for declaring input variables in PromptTemplates (`{input variable}`). Hence, we need to edit the template before declaring the Langchain template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0PHfX_QMWHM",
        "outputId": "ff14e6ae-6a40-4ed9-a3af-5c068cf43863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plan an event titled {Event Name}. The event will be about: {Event Description}. The event will be held in {Location} on {Date}. Consider the following factors: audience, budget, venue, catering options, and entertainment. Provide a detailed plan including potential vendors and logistics.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Replace double brackets with single brackets\n",
        "single_bracket_prompt = re.sub(r'\\{\\{(.*?)\\}\\}', r'{\\1}', langfuse_prompt.prompt)\n",
        "print(single_bracket_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZWWnEVyN9AK"
      },
      "source": [
        "The other configurations can be extracted straightforward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4FNbRwROCab",
        "outputId": "b751864a-b472-47fa-87f2-a05347c1a812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt model configurations\n",
            "Model: gpt-3.5-turbo-1106\n",
            "Temperature: 0\n"
          ]
        }
      ],
      "source": [
        "model = langfuse_prompt.config[\"model\"]\n",
        "temperature = str(langfuse_prompt.config[\"temperature\"])\n",
        "print(f\"Prompt model configurations\\nModel: {model}\\nTemperature: {temperature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGCZnwK4CI31"
      },
      "source": [
        "## Build Langchain application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Phi3qcusC0Aa"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "langchain_prompt = ChatPromptTemplate.from_template(single_bracket_prompt)\n",
        "model = ChatOpenAI(model=model, temperature=temperature)\n",
        "\n",
        "chain = langchain_prompt | model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEzzzavik9g8"
      },
      "source": [
        "## Use Langchain chain with Langfuse callback handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkYxEDX_TaLe"
      },
      "outputs": [],
      "source": [
        "response = chain.invoke(\n",
        "    input={\n",
        "      \"Event Name\": \"Wedding\",\n",
        "      \"Event Description\": \"The wedding of Julia and Alex, a charming couple \"\n",
        "      \" who share a love for art and nature. This special day will celebrate \"\n",
        "      \"their journey together with a blend of traditional and contemporary elements, \"\n",
        "      \"reflecting their unique personalities.\",\n",
        "      \"Location\": \"Central Park, New York City\",\n",
        "      \"Date\": \"June 5, 2024\"\n",
        "    },\n",
        "    config={\n",
        "        \"callbacks\":[langfuse_handler]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZVE_F_8WELq",
        "outputId": "40eb2d97-16a1-43db-be8a-28246d3e6957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event Title: Julia and Alex's Artful Nature Wedding\n",
            "\n",
            "Audience: Family, friends, and loved ones of Julia and Alex, as well as art and nature enthusiasts.\n",
            "\n",
            "Budget: $30,000\n",
            "\n",
            "Venue: Central Park, New York City\n",
            "\n",
            "Catering Options: \n",
            "- Organic and locally sourced menu options\n",
            "- Vegetarian and vegan options\n",
            "- Artfully presented dishes\n",
            "- Champagne toast and signature cocktails\n",
            "\n",
            "Entertainment:\n",
            "- Live acoustic music during the ceremony\n",
            "- DJ for the reception\n",
            "- Interactive art stations for guests to create their own masterpieces\n",
            "- Nature-inspired photo booth\n",
            "\n",
            "Logistics:\n",
            "- Ceremony and reception to be held in a secluded area of Central Park, surrounded by lush greenery and blooming flowers\n",
            "- Tents and seating to be set up for guests\n",
            "- Art installations and sculptures to be placed around the venue\n",
            "- Transportation for guests to and from the park\n",
            "- Permits and permissions for the event in Central Park\n",
            "\n",
            "Potential Vendors:\n",
            "- Catering: Farm-to-table catering company\n",
            "- Music: Local acoustic musician and DJ\n",
            "- Art installations: Local artists and galleries\n",
            "- Photography: Nature and art-focused photographer\n",
            "- Transportation: Eco-friendly shuttle service\n",
            "\n",
            "Overall, the wedding will be a beautiful blend of art and nature, with a focus on sustainability and creativity. The event will showcase the couple's love for each other and their shared passions, creating a memorable and unique experience for all in attendance.\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQlOxtZGhKN7"
      },
      "source": [
        "## View Trace in Langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFBmiR-agkb7"
      },
      "source": [
        "Now we can see that the trace incl. the prompt template have been logged to Langfuse\n",
        "\n",
        "(TODO: Replace with CleanShot screenshot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD6C146mjCsF"
      },
      "source": [
        "## Iterate on prompt in Langfuse\n",
        "We can now continue adapting our prompt template in the Langfuse UI and continuously update the prompt template in our Langchain application via the script above."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

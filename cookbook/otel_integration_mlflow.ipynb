{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: MLflow Integration via OpenTelemetry\n",
        "description: Example cookbook for the MLflow Langfuse integration using OpenTelemetry.\n",
        "category: Integrations\n",
        "---\n",
        "\n",
        "# MLflow Integration via OpenTelemetry\n",
        "\n",
        "Langfuse is an [OpenTelemetry backend](https://langfuse.com/docs/opentelemetry/get-started), allowing trace ingestion from various OpenTelemetry instrumentation libraries. This guide demonstrates how to use the [MLflow](https://mlflow.org/docs/latest/tracing/integrations/) instrumentation library to instrument a compatible framework or LLM provider.\n",
        "\n",
        "## Step 1: Install Dependencies\n",
        "\n",
        "Install the necessary Python packages: `openai`, `langfuse`, and `mlflow`. These will allow you to interact with OpenAI as well as setup the instrumentation for tracing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8xR_verv0yp8",
        "outputId": "1bf27d03-bc6a-4fda-e486-a049534cdc09"
      },
      "outputs": [],
      "source": [
        "%pip install mlflow openai opentelemetry-exporter-otlp-proto-http langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Configure Environment Variables\n",
        "\n",
        "Before sending any requests, you need to configure your credentials and endpoints. First, set up the Langfuse authentication by providing your public and secret keys. Then, configure the OpenTelemetry exporter endpoint and headers to point to Langfuse's backend. You should also specify your OpenAI API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1-vH4lFi6t-D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "\n",
        "LANGFUSE_PUBLIC_KEY = \"pk-lf-...\"\n",
        "LANGFUSE_SECRET_KEY = \"sk-lf-...\"\n",
        "LANGFUSE_AUTH = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
        "\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_TRACES_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel/v1/traces\"  # ðŸ‡ªðŸ‡º EU data region\n",
        "# os.environ[\"OTEL_EXPORTER_OTLP_TRACES_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel/v1/traces\"  # ðŸ‡ºðŸ‡¸ US data region\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_TRACES_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
        "os.environ['OTEL_EXPORTER_OTLP_TRACES_PROTOCOL']= \"http/protobuf\"\n",
        "\n",
        "# Set your OpenAI API key.\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configure `tracer_provider` and add a span processor to export traces to Langfuse. `OTLPSpanExporter()` uses the endpoint and headers from the environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "\n",
        "trace_provider = TracerProvider()\n",
        "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
        "\n",
        "# Sets the global default tracer provider\n",
        "from opentelemetry import trace\n",
        "trace.set_tracer_provider(trace_provider)\n",
        "\n",
        "# Creates a tracer from the global tracer provider\n",
        "tracer = trace.get_tracer(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Explanation:* This block configures the necessary environment variables. The Langfuse keys are combined and base64 encoded to form an authentication token that is then set in the OTLP headers. Additionally, the OpenTelemetry endpoint is provided to direct trace data to Langfuse's backend.\n",
        "\n",
        "## Step 3: Initialize Instrumentation\n",
        "\n",
        "With the environment set up, import the needed libraries and initialize MLflow instrumentation. Have a look at all avaliable instrumentation modules [here](https://mlflow.org/docs/latest/tracing/integrations/). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "# Enable the MLflow instrumentation for tracing OpenAI\n",
        "mlflow.openai.autolog()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Make a Chat Completion Request\n",
        "\n",
        "For this example, we will make a simple chat completion request to the OpenAI Chat API. This will generate trace data that you can later view in the Langfuse dashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMaAjHXSi0Kr",
        "outputId": "277ddaa5-8de1-47f8-b5d1-d4df5dbd448a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-BD7XRulRhULb7NjGfeOkhN3BB9zud', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I don't have real-time data access to provide current weather conditions. I recommend checking a reliable weather website or a weather app for the most accurate and up-to-date information.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1742466941, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b8bc95a0ac', usage=CompletionUsage(completion_tokens=35, prompt_tokens=23, total_tokens=58, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# Use OpenAI Python SDK as usual\n",
        "openai.OpenAI().chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a chatbot.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What is the weather like today?\"},\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Pass Additional Attributes (Optional)\n",
        "\n",
        "Opentelemetry lets you attach a set of attributes to all spans by setting [`set_attribute`](https://opentelemetry.io/docs/languages/python/instrumentation/#add-attributes-to-a-span). This allows you to set properties like a Langfuse Session ID, to group traces into Langfuse Sessions or a User ID, to assign traces to a specific user. You can find a list of all supported attributes in the [here](/docs/opentelemetry/get-started#property-mapping)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/20 11:36:03 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during openai autologging: the JSON object must be str, bytes or bytearray, not NoneType\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enhanced observability in Large Language Models (LLMs) plays a crucial role in AI debugging by providing deeper insights into the behavior, performance, and decision-making processes of these models. Here are some key ways in which improved observability aids in debugging:\n",
            "\n",
            "1. **Monitoring Performance Metrics**: Enhanced observability allows for real-time tracking of various performance metrics such as accuracy, response time, and model drift. By continuously monitoring these indicators, developers can quickly identify when an LLM deviates from expected behavior, enabling timely interventions.\n",
            "\n",
            "2. **Traceability of Inputs and Outputs**: Improved observability enables the logging and tracking of inputs and outputs, which helps in understanding how specific inputs influence model outputs. This traceability allows engineers to pinpoint the source of unexpected behavior or errors in the model's responses.\n",
            "\n",
            "3. **Contextual Analysis**: By incorporating contextual information, observability tools can provide insights into the model's processing of input data, including how it interprets the context or nuances. Understanding the reasoning behind a model's output helps identify when and why it may misinterpret queries or generate inappropriate responses.\n",
            "\n",
            "4. **Understanding Model Decisions**: Enhanced observability often involves explainable AI techniques such as feature importance analysis and attention visualization. These tools help in understanding which parts of the input were most influential in the model's decision-making process, thus revealing biases or weaknesses in the model.\n",
            "\n",
            "5. **Anomaly Detection**: By establishing baselines for normal model behavior, enhanced observability systems can detect anomalies in responses. This capability helps in identifying potential issues that may not be apparent through traditional testing methods or user feedback alone.\n",
            "\n",
            "6. **Testing and Validation**: Enhanced observability can support ongoing testing and validation of LLMs by providing insights into how the model performs across different scenarios and datasets. This testing can help identify gaps in training data or areas where the model may require additional fine-tuning.\n",
            "\n",
            "7. **Feedback Loops**: Observability facilitates the creation of feedback loops where user interactions and model performance data can be used to continuously improve the model. This iterative process helps rectify shortcomings and refine the model's outputs over time.\n",
            "\n",
            "8. **Collaboration and Communication**: Enhanced observability provides a shared understanding of model behavior among teams. This improved visibility fosters better communication between data scientists, engineers, and stakeholders, leading to more informed decision-making regarding model improvements and debugging efforts.\n",
            "\n",
            "9. **Compliance and Ethical Considerations**: With enhanced observability, it becomes easier to assess models against compliance and ethical standards. Debugging efforts can include the identification of biases or harmful outputs, ensuring the model adheres to ethical AI principles.\n",
            "\n",
            "In summary, enhanced observability in LLMs significantly improves AI debugging by providing comprehensive insights into model behavior, facilitating the identification of issues, and enabling more effective interventions. This ultimately leads to the development of more reliable, robust, and ethical AI systems.\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "input = \"How does enhanced LLM observability improve AI debugging?\"\n",
        "\n",
        "with tracer.start_as_current_span(\"OpenAI-Trace\") as span:\n",
        "    span.set_attribute(\"langfuse.user.id\", \"user-123\")\n",
        "    span.set_attribute(\"langfuse.session.id\", \"123456789\")\n",
        "    span.set_attribute(\"langfuse.tags\", [\"staging\", \"demo\"])\n",
        "\n",
        "    # You application code below:\n",
        "    response = openai.OpenAI().chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": input,\n",
        "            }\n",
        "        ],\n",
        "        model=\"gpt-4o-mini\",\n",
        "    )\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "    # Add input and output values to the new parent span\n",
        "    span.set_attribute(\"input.value\", input)\n",
        "    span.set_attribute(\"output.value\", response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: See Traces in Langfuse\n",
        "\n",
        "You can view the generated trace data in Langfuse. You can view this [example trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/6dea86b6feae03db538e248b38e124e1?timestamp=2025-03-20T10%3A35%3A41.217Z&display=details&observation=948b7a084327d5e6) in the Langfuse UI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWrLi7RltrrK"
      },
      "source": [
        "m![MLflow OpenAI Trace](https://langfuse.com/images/cookbook/otel-integration-mlflow/mlflow-openai-trace.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

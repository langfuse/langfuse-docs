{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24b5jqb5sXOL"
      },
      "source": [
        "---\n",
        "description: Example cookbook for the OpenLLMetry Langfuse integration using OpenTelemetry.\n",
        "category: Integrations\n",
        "---\n",
        "\n",
        "# OpenLLMetry Integration via OpenTelemetry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "tsziF7Z7-9ck",
        "outputId": "9d99f0ab-2a41-478d-90fb-1cf9121de0d8"
      },
      "outputs": [],
      "source": [
        "%pip install openai traceloop-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-u8TzbYhAMzs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import base64\n",
        "\n",
        "LANGFUSE_PUBLIC_KEY=\"\"\n",
        "LANGFUSE_SECRET_KEY=\"\"\n",
        "LANGFUSE_AUTH=base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
        "\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel\" # EU data region\n",
        "# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel\" # US data region\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
        "\n",
        "# your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHYYPKKGsTmt"
      },
      "source": [
        "## OpenAI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS9RbpCb_CU4",
        "outputId": "e70ee013-39b8-45e1-abc9-c99e0ff34ba3"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from traceloop.sdk import Traceloop\n",
        "\n",
        "Traceloop.init(disable_batch=True)\n",
        "\n",
        "openai_client = OpenAI()\n",
        "\n",
        "chat_completion = openai_client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": \"What is LLM Observability?\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-4o-mini\",\n",
        ")\n",
        "\n",
        "print(chat_completion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_kOwnq1sf3b"
      },
      "source": [
        "[Example Trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/e417c49b4044725e48aa0e089534fa12?timestamp=2025-02-02T22%3A04%3A04.487Z)\n",
        "\n",
        "![OpenLLMetry OpenAI Trace](https://langfuse.com/images/cookbook/otel-integration-openllmetry/openllmetry-openai-trace.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

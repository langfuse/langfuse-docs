{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "description: Example of Open Source Prompt Management for Langchain applications using Langfuse.\n",
        "category: Prompt Management\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc7JQAashNea"
      },
      "source": [
        "# Example: Langfuse Prompt Management with Langchain (Python)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qGbaVDEiK6o"
      },
      "source": [
        "[Langfuse Prompt Management](https://langfuse.com/docs/prompts) helps to version control and manage prompts collaboratively in one place. This example demostrates how to use prompts managed in Langchain applications.\n",
        "\n",
        "_In addition, we use [Langfuse Tracing](https://langfuse.com/docs/tracing) via the native [Langchain integration](https://langfuse.com/docs/integrations/langchain) to inspect and debug the Langchain application._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwyrmsWZhsFW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJzIBAVKKdoD",
        "outputId": "842bf588-0203-4961-d818-5d17ef5cf86a"
      },
      "outputs": [],
      "source": [
        "%pip install langfuse langchain langchain-openai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f8m2HYAKfJz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# get keys for your project from https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"\"\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"\"\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"\n",
        "\n",
        "# your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ABMEWVCKsPW",
        "outputId": "eb8abbd4-985b-48a6-84de-815b39d5c2ed"
      },
      "outputs": [],
      "source": [
        "from langfuse import Langfuse\n",
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "# Initialize Langfuse client (prompt management)\n",
        "langfuse = Langfuse()\n",
        "\n",
        "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
        "langfuse_callback_handler = CallbackHandler()\n",
        "\n",
        "# Optional, verify that Langfuse is configured correctly\n",
        "assert langfuse.auth_check()\n",
        "assert langfuse_callback_handler.auth_check()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdHpmb6vLAiW"
      },
      "source": [
        "## Add prompt to Langfuse Prompt Management\n",
        "\n",
        "We add the prompt used in this example via the SDK. Alternatively, you can also edit and version the prompt in the Langfuse UI.\n",
        "\n",
        "- `Name` that identifies the prompt in Langfuse Prompt Management\n",
        "- Prompt with prompt template incl. `{{input variables}}`\n",
        "- Config including `model_name` and `temperature`\n",
        "- `is_active` to immediately use prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX54t3k0gM5w",
        "outputId": "ac24d2bb-5150-4f24-87b1-18e2c02615ca"
      },
      "outputs": [],
      "source": [
        "langfuse.create_prompt(\n",
        "    name=\"event-planner\",\n",
        "    prompt=\n",
        "    \"Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. \"\n",
        "    \"The event will be held in {{Location}} on {{Date}}. \"\n",
        "    \"Consider the following factors: audience, budget, venue, catering options, and entertainment. \"\n",
        "    \"Provide a detailed plan including potential vendors and logistics.\",\n",
        "    config={\n",
        "        \"model\":\"gpt-3.5-turbo-1106\",\n",
        "        \"temperature\": 0,\n",
        "    },\n",
        "    is_active=True\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prompt in Langfuse UI\n",
        "\n",
        "![Created prompt in Langfuse UI](https://langfuse.com/images/docs/prompt-management-langchain-prompt.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example application\n",
        "\n",
        "### Get current prompt version from Langfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0nYuMLzIJeb",
        "outputId": "589a5013-b59f-4f70-8f2b-7e0801dacf45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. The event will be held in {{Location}} on {{Date}}. Consider the following factors: audience, budget, venue, catering options, and entertainment. Provide a detailed plan including potential vendors and logistics.\n"
          ]
        }
      ],
      "source": [
        "# Get current production version of prompt\n",
        "langfuse_prompt = langfuse.get_prompt(\"event-planner\")\n",
        "print(langfuse_prompt.prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahvMYvS1RsF9"
      },
      "source": [
        "### Transform into Langchain PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQwfPI42IZM0"
      },
      "source": [
        "Use the utility method `.get_langchain_prompt()` to transform the Langfuse prompt into a string that can be used in Langchain.\n",
        "\n",
        "Context: Langfuse declares input variables in prompt templates using double brackets (`{{input variable}}`). Langchain uses single brackets for declaring input variables in PromptTemplates (`{input variable}`). The utility method `.get_langchain_prompt()` replaces the double brackets with single brackets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0PHfX_QMWHM",
        "outputId": "ff14e6ae-6a40-4ed9-a3af-5c068cf43863"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "langchain_prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZWWnEVyN9AK"
      },
      "source": [
        "Extract the configuration options from `prompt.config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4FNbRwROCab",
        "outputId": "b751864a-b472-47fa-87f2-a05347c1a812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt model configurations\n",
            "Model: gpt-3.5-turbo-1106\n",
            "Temperature: 0\n"
          ]
        }
      ],
      "source": [
        "model = langfuse_prompt.config[\"model\"]\n",
        "temperature = str(langfuse_prompt.config[\"temperature\"])\n",
        "print(f\"Prompt model configurations\\nModel: {model}\\nTemperature: {temperature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGCZnwK4CI31"
      },
      "source": [
        "### Create Langchain chain based on prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Phi3qcusC0Aa"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=model, temperature=temperature)\n",
        "\n",
        "chain = langchain_prompt | model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEzzzavik9g8"
      },
      "source": [
        "## Invoke chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_input = {\n",
        "    \"Event Name\": \"Wedding\",\n",
        "    \"Event Description\": \"The wedding of Julia and Alex, a charming couple who share a love for art and nature. This special day will celebrate their journey together with a blend of traditional and contemporary elements, reflecting their unique personalities.\",\n",
        "    \"Location\": \"Central Park, New York City\",\n",
        "    \"Date\": \"June 5, 2024\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZVE_F_8WELq",
        "outputId": "40eb2d97-16a1-43db-be8a-28246d3e6957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Event Title: Julia and Alex's Artful Nature Wedding\n",
            "\n",
            "Audience: Family, friends, and loved ones of Julia and Alex, as well as art and nature enthusiasts.\n",
            "\n",
            "Budget: $30,000\n",
            "\n",
            "Venue: Central Park, New York City\n",
            "\n",
            "Catering Options: \n",
            "- Organic and locally sourced menu options\n",
            "- Vegetarian and vegan options\n",
            "- Artfully presented dishes\n",
            "- Champagne toast and signature cocktails\n",
            "\n",
            "Entertainment:\n",
            "- Live acoustic music during the ceremony\n",
            "- DJ for the reception\n",
            "- Interactive art stations for guests to create their own masterpieces\n",
            "- Nature-inspired photo booth\n",
            "\n",
            "Logistics:\n",
            "- Ceremony and reception to be held in a secluded area of Central Park, surrounded by lush greenery and blooming flowers\n",
            "- Tents and seating to be set up for guests\n",
            "- Art installations and sculptures to be placed around the venue\n",
            "- Transportation for guests to and from the park\n",
            "- Permits and permissions for the event in Central Park\n",
            "\n",
            "Potential Vendors:\n",
            "- Catering: Farm-to-table catering company\n",
            "- Music: Local acoustic musician and DJ\n",
            "- Art installations: Local artists and galleries\n",
            "- Photography: Nature and art-focused photographer\n",
            "- Transportation: Eco-friendly shuttle service\n",
            "\n",
            "Overall, the wedding will be a beautiful blend of art and nature, with a focus on sustainability and creativity. The event will showcase the couple's love for each other and their shared passions, creating a memorable and unique experience for all in attendance.\n"
          ]
        }
      ],
      "source": [
        "# we pass the callback handler to the chain to trace the run in Langfuse\n",
        "response = chain.invoke(input=example_input,config={\"callbacks\":[langfuse_callback_handler]})\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQlOxtZGhKN7"
      },
      "source": [
        "## View Trace in Langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFBmiR-agkb7"
      },
      "source": [
        "Now we can see that the trace incl. the prompt template have been logged to Langfuse\n",
        "\n",
        "![Trace of prompt used in Langchain in Langfuse](https://langfuse.com/images/docs/prompt-management-langchain-trace.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD6C146mjCsF"
      },
      "source": [
        "## Iterate on prompt in Langfuse\n",
        "We can now continue adapting our prompt template in the Langfuse UI and continuously update the prompt template in our Langchain application via the script above."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

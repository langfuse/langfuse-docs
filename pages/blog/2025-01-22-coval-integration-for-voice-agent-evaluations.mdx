---
title: "How to Integrate Langfuse + Coval into Your Voice AI Stack: A Complete Guide to Voice Agent Evaluation"
date: 2025/01/22
description: "Discover how to integrate Coval and Langfuse into your Voice AI development workflow for comprehensive voice agent testing and optimization."
ogImage: /images/blog/2025-01-22-coval-integration/2025-01-22-coval-integration.png
tag: announcement
author: Brooke
---

# Langfuse ü§ù Coval: A Complete Guide to Voice Agent Evaluation

As Voice AI applications continue to advance, developers are met with complex challenges in testing, evaluating, and monitoring their voice agents. Many Langfuse users already use **Coval** to evaluate their voice agents. Brooke Hopkins, founder of Coval, chatted with Marc Klingen, CEO of Langfuse, to delve into how developers are leveraging both platforms‚Äîfrom integration testing to unit testing (full video [here](https://www.youtube.com/watch?v=hPrPqry1yQQ)).

In this blog post, we'll explore how combining [Langfuse](/) and [Coval](https://www.coval.dev/) can help you create more robust and reliable voice applications. We'll draw insights from our customer experiences and the recent discussion between Brooke and Marc to provide a comprehensive guide on Voice AI evaluation.

## The Evolution of Voice AI Testing

Voice AI applications present complexities that extend beyond traditional LLM implementations. In addition to [challenges](/faq/all/llm-observability) caused by the non-deterministic nature of language models, developers must also handle:

- Audio Quality and Metrics
- User Interruptions
- Speech-to-Text (STT) Accuracy
- Text-to-Speech (TTS) Output Quality
- Real-Time Streaming Interactions

As voice applications mature, the need for both high-level integration testing and detailed component evaluation becomes critical. This is where the synergy between Langfuse and Coval becomes invaluable in the Voice AI development process.

## Understanding the Voice AI Testing Pyramid

<CloudflareVideo
  videoId="9cf37aecb7402def322be7641923bc1c"
  aspectRatio={10.26 / 10.26}
  title="Unit Testing vs. Simulation: Evolving Testing Needs for Mature Voice Agents"
/>

Developing effective voice applications requires a dual approach to evaluation strategies:

- **Online Evaluation:** Focuses on real-time production monitoring, performance tracking, and analyzing user interactions.
- **Offline Evaluation:** Involves development testing, ranging from end-to-end agent testing to granular unit tests and validating conversation flows.

Using this testing pyramid is essential for effective Voice AI testing, ensuring your voice agents perform optimally in live environments.

## Evaluations of Single Messages vs. Conversation Level

<CloudflareVideo
  videoId="9cf37aecb7402def322be7641923bc1c"
  aspectRatio={10.26 / 10.26}
  title="Evaluations: Single Messages vs. Conversation Level"
/>

Langfuse provides tracing and observability tools that give teams insight into the inner workings of their voice applications. Its strengths include:

- Step-by-Step Execution [Tracing](https://langfuse.com/docs/tracing)
- Detailed LLM Call Visibility
- Monitoring [Costs and Latency](https://langfuse.com/docs/model-usage-and-cost)
- Stream-Based Interaction Analysis

Coval offers conversation level voice agent testing, allowing for integration testing with agent phone numbers and providing voice-specific metrics and evaluations. Langfuse customers use it for:

- End-to-End Simulation Testing
- Regression Testing
- Conversation Flow Validation

## Integration Best Practices

<CloudflareVideo
  videoId="844937f4a920cf2bf29a00e23b9acec5"
  aspectRatio={10.26 / 10.26}
  title="Single-Turn vs. Multi-Turn Evaluations"
/>

What we often see from users developing voice applications is this approach:

**Early development stages:**
  - Use **Coval** for quick integration tests and online evaluations.
  - Employ **Langfuse** to trace and debug individual components.

**Application running in production:**
  - Implement specific unit tests.
  - Use **Langfuse** for detailed performance monitoring.
  - Use **Coval** for ongoing regression testing.

### **Use Cases**

**Transactional Voice Applications (e.g., Appointment Scheduling):**
  - **Langfuse:** Trace individual function calls and apply evaluations to single messages.
  - **Coval:** Perform end-to-end testing of complete user journeys.

**Complex Applications (e.g., Virtual Assistants):**
  - **Coval:** Focus on conversation-level testing and monitor conversation arcs.
  - **Langfuse:** Monitor tool calls and application logic.

## üí• Upcoming: Native Langfuse Integration in Coval

We are excited that Coval launches a native integration with Langfuse. This aims to make testing and evaluating Voice AI applications more seamless and efficient than ever before. 

## Resources

- Watch the full video [here](https://www.youtube.com/watch?v=hPrPqry1yQQ).
- Learn more about LLM-as-a-Judge evaluations in Langfuse [here](https://langfuse.com/docs/scores/model-based-evals).   
- Explore the Coval docs [here](https://docs.coval.dev/getting_started/welcome).

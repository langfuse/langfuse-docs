---
title: "Will you be my ~~valentine~~ CLI? Making Agents fall in love with Langfuse."
date: 2026/02/13
description: How we optimized Langfuse for AI agents with llms.txt, markdown endpoints, OpenAPI-based API documentation, public search, and MCP servers. A love letter to agents that need great developer tools.
tag: engineering, agents
author: Marc
ogImage: /images/blog/2026-02-13-will-you-be-my-cli/will-you-be-my-cli.png
---

import { BlogHeader } from "@/components/blog/BlogHeader";

<BlogHeader
  title="Will you be my ~~valentine~~ CLI? Making Agents fall in love with Langfuse."
  description="How we optimized Langfuse for AI agents with llms.txt, markdown endpoints, OpenAPI-based API documentation, public search, and MCP servers. A love letter to agents that need great developer tools."
  authors={["Marc"]}
/>

Valentine's Day is here, and while most people are thinking about flowers and chocolates, we've been thinking about something more romantic: **making AI agents fall in love with Langfuse**. 

Over the past months, we've shipped a series of features designed specifically to make Langfuse the perfect companion for AI agents, whether they're coding in your IDE, running in the terminal, or helping you debug your LLM applications. This post walks through our "agent love language": the technical decisions and implementations that make Langfuse easy for agents to discover, understand, and integrate with.

## Why Agents Need Love Too

AI agents are increasingly doing real work: writing code, debugging applications, searching documentation, and even building entire features. But here's the thing: **agents are only as good as the tools they can use**.

When an agent encounters your product, it needs to quickly:

1. **Discover** what you do and what's possible
2. **Understand** how to integrate and use your APIs
3. **Access** documentation in machine-readable formats
4. **Search** efficiently for specific information
5. **Execute** operations through well-defined interfaces
6. **Interact** from their native environment (terminal or IDE)

We realized that if we wanted agents to successfully integrate Langfuse into codebases, we needed to optimize for these needs. So we did. Here's what we built.

### The Features We Shipped

1. **llms.txt** - A machine-readable documentation index
2. **Markdown Endpoints** - Docs as raw markdown, not just HTML
3. **OpenAPI-First API** - Comprehensive, machine-readable API documentation
4. **Public Search** - Semantic search available to everyone
5. **Langfuse CLI** - Terminal-based API access auto-generated from OpenAPI
6. **Authenticated MCP Server** - Full access to your Langfuse project data
7. **Docs MCP Server** - Public documentation access for agents

Let's dive into each one.

---

## llms.txt: The Discovery Layer

**Problem:** How does an agent quickly understand what Langfuse is and what documentation is available?

**Solution:** We implemented [llms.txt](https://langfuse.com/llms.txt), a standard proposed by [llmstxt.org](https://llmstxt.org/) that provides a machine-readable index of your documentation.

### What is llms.txt?

It's a simple markdown file that gives LLMs a high-level overview and links to detailed documentation‚Äîall in one place. Here's what ours looks like:

```markdown
# Langfuse

> Langfuse is an **open-source LLM engineering platform** that helps teams 
> collaboratively debug, analyze, and iterate on their LLM applications.

## Langfuse Docs MCP Server

Connect to the Langfuse Docs MCP server to access documentation...

## Docs

- [Observability Overview](/docs/observability/overview.md)
- [Prompt Management](/docs/prompt-management/overview.md)
- [Evaluation](/docs/evaluation/overview.md)
...
```

### Implementation

We auto-generate this file from our sitemap using a [simple Node.js script](https://github.com/langfuse/langfuse-docs/blob/main/scripts/generate_llms_txt.js) that runs at build time:

```javascript
// scripts/generate_llms_txt.js
async function generateLLMsList() {
  const sitemapContent = fs.readFileSync('public/sitemap-0.xml', 'utf-8');
  const result = await parser.parseStringPromise(sitemapContent);
  
  let markdownContent = `# Langfuse\n\n`;
  markdownContent += `> ${INTRO_DESCRIPTION}\n\n`;
  
  // Group URLs by section (docs, self-hosting, etc.)
  urls.forEach(url => {
    const section = new URL(url).pathname.split('/')[1];
    // ... categorize and format
  });
  
  fs.writeFileSync('public/llms.txt', markdownContent);
}
```

**Why it matters:** When an agent first encounters Langfuse, it can immediately fetch `langfuse.com/llms.txt` and understand the entire documentation structure without crawling hundreds of pages.

---

## Markdown Endpoints: Native Content for Agents

**Problem:** Agents work better with raw markdown than rendered HTML. How do we serve documentation in agent-friendly formats?

**Solution:** Every documentation page can now be accessed as markdown, either by appending `.md` to the URL or by sending an `Accept: text/markdown` header.

### How It Works

We use Next.js rewrites and static file serving to provide markdown versions of all docs. This was a fun technical challenge that required converting our MDX pages to plain markdown at build time and serving them efficiently.

The implementation uses Next.js rewrites in [`next.config.mjs`](https://github.com/langfuse/langfuse-docs/blob/main/next.config.mjs#L146-L177):

```javascript
// next.config.mjs
async rewrites() {
  return {
    beforeFiles: [
      // Content negotiation via Accept header
      {
        source: "/:path((?!api|_next|md-src)(?!.*\\.md$).*)",
        has: [{ type: "header", key: "accept", value: ".*text/markdown.*" }],
        destination: "/md-src/:path.md",
      },
    ],
    afterFiles: [
      // Manual .md access
      {
        source: "/:path*.md",
        destination: "/md-src/:path*.md",
      },
    ],
  };
}
```

### Usage Examples

```bash
# Fetch markdown by URL extension
curl https://langfuse.com/docs/observability/overview.md

# Or use content negotiation
curl -H "Accept: text/markdown" https://langfuse.com/docs/observability/overview
```

**Why it matters:** Agents can now directly consume documentation content without parsing HTML. This powers:
- The "Copy as Markdown" feature in our docs
- The `getLangfuseDocsPage` tool in our MCP server
- Agent-driven integrations in IDEs like Cursor

---

## OpenAPI-First API Design

**Problem:** How do agents understand what API endpoints are available and how to use them?

**Solution:** We maintain a comprehensive OpenAPI specification that serves as both documentation and a contract for our API.

### API Reference

Our API is fully documented at [api.reference.langfuse.com](https://api.reference.langfuse.com) with:

- Complete endpoint descriptions
- Request/response schemas
- Authentication examples
- Error handling documentation

The OpenAPI spec is available at:

```bash
# Download the full OpenAPI specification
curl https://cloud.langfuse.com/generated/api/openapi.yml
```

### Using the API

Authentication is straightforward with Basic Auth:

```bash
# Fetch traces from your project
curl -u pk-your-public-key:sk-your-secret-key \
  https://cloud.langfuse.com/api/public/traces

# Create a new score via API
curl -u pk-your-public-key:sk-your-secret-key \
  -X POST https://cloud.langfuse.com/api/public/scores \
  -H "Content-Type: application/json" \
  -d '{
    "traceId": "trace-123",
    "name": "quality",
    "value": 0.95
  }'
```

### SDK Access

Both Python and TypeScript SDKs provide strongly-typed wrappers around the API:

```python
from langfuse import get_client

langfuse = get_client()

# Fetch a trace - fully typed with intellisense
trace = langfuse.api.trace.get("trace-123")

# List all prompts in your project
prompts = langfuse.api.prompts.list()
```

**Why it matters:** Agents can read the OpenAPI spec to understand all available operations, then execute them confidently with proper types and error handling.

---

## Public Search Endpoint

**Problem:** How can agents quickly find relevant information across all documentation?

**Solution:** We exposed our semantic search as a public REST API.

### The Search API

Any agent (or human) can now search Langfuse docs without authentication:

```bash
curl "https://langfuse.com/api/search-docs?query=How%20do%20I%20trace%20LangGraph%20agents"
```

Response:

```json
{
  "query": "How do I trace LangGraph agents",
  "answer": "To trace LangGraph agents with Langfuse, use the native integration...",
  "metadata": {
    "sources": [
      {
        "title": "LangGraph Integration",
        "url": "https://langfuse.com/docs/integrations/langgraph"
      }
    ]
  }
}
```

### Implementation

The endpoint uses [Inkeep's RAG API](https://docs.inkeep.com/ai-api/rag-mode/http-request) under the hood:

```typescript
// pages/api/search-docs.ts
export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  const query = req.query.query as string;
  
  if (!query) {
    return res.status(400).json({ error: "Missing query parameter" });
  }

  const inkeepResult = await searchLangfuseDocsWithInkeep(query);

  return res.status(200).json({
    query,
    answer: inkeepResult.answer,
    metadata: inkeepResult.metadata,
  });
}
```

**Why it matters:** Instead of reading through dozens of documentation pages, agents can ask natural language questions and get synthesized answers with source citations.

---

## Langfuse CLI: Direct API Access from the Terminal

**Problem:** Agents often work in terminal environments. How can they interact with Langfuse without writing HTTP requests manually?

**Solution:** We built `langfuse-cli`, a command-line interface that wraps the entire Langfuse API, auto-generated from our OpenAPI spec.

### What is langfuse-cli?

It's a CLI tool built on [specli](https://github.com/vercel-labs/specli) that generates commands directly from the OpenAPI specification. Every API endpoint becomes a CLI command with proper flags, validation, and help text.

### Installation & Usage

```bash
# Run directly with npx
npx langfuse-cli traces list --limit 10

# Or install globally
npm install -g langfuse-cli
langfuse prompts get --name my-prompt

# Configure with environment variables
export LANGFUSE_PUBLIC_KEY=pk-lf-...
export LANGFUSE_SECRET_KEY=sk-lf-...
export LANGFUSE_HOST=https://cloud.langfuse.com

# List all available resources
langfuse __schema

# Get help for any resource
langfuse traces --help

# JSON output for scripting
langfuse traces list --limit 5 --json

# Preview the curl command
langfuse scores list --curl
```

### Examples

```bash
# Fetch recent traces
langfuse traces list --limit 10

# Get a specific trace by ID
langfuse traces get <trace-id>

# List all prompts
langfuse prompts list

# Get a prompt by name
langfuse prompts get --name "customer-support-v1"

# List dataset items
langfuse dataset-items list --dataset-name "qa-examples"

# Create a score
langfuse scores create \
  --trace-id abc123 \
  --name quality \
  --value 0.95
```

### For Agents: The Skill File

Here's what makes this especially agent-friendly: we include a **skill file** at `skill/langfuse-cli.md` that teaches AI agents how to use the CLI:

```markdown
# Langfuse CLI Skill

The Langfuse CLI provides command-line access to the Langfuse API.

## Installation
npx langfuse-cli <resource> <action>

## Common Operations

### Traces
- List traces: langfuse traces list --limit 10
- Get trace: langfuse traces get <id>
- Search: langfuse traces list --user-id <user> --json

### Prompts  
- List: langfuse prompts list
- Get: langfuse prompts get --name <name>

... [full skill documentation]
```

Agents can read this file to understand all available commands, flags, and usage patterns.

### Why Auto-Generate from OpenAPI?

By generating the CLI from the OpenAPI spec, we get:

1. **Always in sync** - CLI updates automatically when the API changes
2. **Complete coverage** - Every endpoint becomes a command
3. **Proper validation** - Request schemas enforce correct input
4. **Built-in help** - Auto-generated help text for every command
5. **Type safety** - Flags match the API parameter types exactly

### Technical Implementation

The CLI is built using a patched OpenAPI spec. We flatten discriminated unions (`oneOf` with `allOf`) into plain objects so specli can generate proper command flags:

```typescript
// scripts/patch-openapi.ts
// Flattens complex union types for CLI generation
export function patchOpenAPI(spec: OpenAPISpec) {
  // Convert oneOf/allOf patterns to flat object schemas
  // This makes endpoints like `prompts create` generate proper flags
  return flattenedSpec;
}
```

**Why it matters:** Agents working in terminal environments can now interact with Langfuse using natural command-line syntax. They can list traces, fetch prompts, create scores, and manage datasets, all without writing API client code. The skill file provides the knowledge, and the CLI provides the interface.

---

## Authenticated MCP Server

**Problem:** How can agents interact with your Langfuse project data directly from their IDE?

**Solution:** We built an authenticated MCP server that provides full access to your Langfuse data through the [Model Context Protocol](https://modelcontextprotocol.io/).

### What It Does

The authenticated MCP server lets agents:
- Fetch and analyze traces from your projects
- Read and manage prompts
- Access datasets and experiments
- Create and query scores
- Interact with all Langfuse resources

This is powered by the same infrastructure as our REST API, ensuring consistency and reliability.

### Authentication

The MCP server uses your Langfuse API keys (public and secret key) to authenticate and access your project data. This gives agents the same level of access you have through the web UI or API.

```json
{
  "mcpServers": {
    "langfuse": {
      "url": "https://cloud.langfuse.com/api/mcp",
      "transport": "streamableHttp",
      "auth": {
        "username": "pk-lf-...",
        "password": "sk-lf-..."
      }
    }
  }
}
```

**Why it matters:** Agents can now query your production data, analyze traces, fetch prompts for testing, and interact with your Langfuse projects without leaving their coding environment.

[Read the full guide](/docs/api-and-data-platform/features/mcp-server) ¬∑ [How we built it](/blog/2025-12-09-building-langfuse-mcp-server)

---

## Docs MCP Server

**Problem:** How can agents quickly access Langfuse documentation while coding?

**Solution:** We built a public, unauthenticated MCP server specifically for documentation access.

### What It Provides

The docs MCP server exposes three tools:

1. **`searchLangfuseDocs`** - Semantic search over all documentation
2. **`getLangfuseDocsPage`** - Fetch specific pages as markdown
3. **`getLangfuseOverview`** - Get the documentation index (llms.txt)

### Installation

No authentication required. Works in Cursor, VS Code, Claude Desktop, and any MCP-compatible client:

```json
{
  "mcpServers": {
    "langfuse-docs": {
      "url": "https://langfuse.com/api/mcp",
      "transport": "streamableHttp"
    }
  }
}
```

### Example Usage

```
User: "Add Langfuse tracing to my LangGraph application"

Agent: [Calls searchLangfuseDocs with query: "LangGraph integration"]
Agent: [Calls getLangfuseDocsPage with path: "/docs/integrations/langgraph"]
Agent: Based on the documentation, here's how to add tracing...
```

**Why it matters:** Agents can search and read documentation without requiring API keys, making it easy to learn about and integrate Langfuse.

[Read the installation guide](/docs/docs-mcp)

---

## So, Will You Be My CLI? üíò

We've put a lot of love into making Langfuse agent-friendly. Whether you're an AI coding assistant, an autonomous agent, or a developer using these tools, we want you to have the best possible experience integrating and using Langfuse.

Try it out and let us know what you think. And if you build something cool with these capabilities, we'd love to hear about it!

**Happy Valentine's Day from the Langfuse team! ‚ù§Ô∏è**

---

## Resources

- [Langfuse CLI on npm](https://www.npmjs.com/package/langfuse-cli)
- [Langfuse Docs MCP Server](/docs/docs-mcp)
- [Authenticated MCP Server](/docs/api-and-data-platform/features/mcp-server)
- [llms.txt](https://langfuse.com/llms.txt)
- [API Reference](https://api.reference.langfuse.com)
- [OpenAPI Spec](https://cloud.langfuse.com/generated/api/openapi.yml)
- [Public Search API](https://langfuse.com/api/search-docs)
- [GitHub Repository](https://github.com/langfuse/langfuse)

---

*Building tools for agents? We'd love to compare notes. Join our [Discord community](https://discord.langfuse.com) or reach out on [Twitter/X](https://x.com/langfuse).*

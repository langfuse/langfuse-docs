---
date: 2024-04-15
title: OpenAI SDK integration for JS/TS SDK
description: Langfuse now provides a simple to adopt wrapper for the OpenAI JS/TS SDK for you to seemlessly trace your OpenAI calls.
author: Hassieb
---

import { ChangelogHeader } from "@/components/changelog/ChangelogHeader";

<ChangelogHeader />

LLM observability just got a lot easier for users of the OpenAI JS SDK. Langfuse now provides a wrapper for the OpenAI SDK that gives you all the benefits of tracing your OpenAI calls with only minor code changes. Import the `observeOpenAI` function from `langfuse` and pass your OpenAI SDK instance to it. The wrapper will automatically track all your OpenAI calls and provide you with insights into your model usage, cost, and performance in the Langfuse UI.


### Quickstart

```typescript
import OpenAI from 'openai';
import { observeOpenAI } from "langfuse";

const openai = new OpenAI();

observeOpenAI(openai)
  .chat.completions.create({
    messages: [{ role: "system", content: "Tell me a story about a dog." }],
  })
  .then((res) => console.log(res));

```

Langfuse will automatically capture the following information for you:

- All prompts/completions with support for streaming and function calling
- Total latencies and time-to-first-token
- OpenAI API Errors
- Model usage (tokens) and cost (USD) ([learn more](/docs/model-usage-and-cost))

### ðŸ“š Docs

[Get started with the OpenAI SDK integration](/docs/integrations/openai/js/get-started)


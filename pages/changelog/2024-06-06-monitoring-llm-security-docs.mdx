---
date: 2024-06-06
title: "New Docs and Cookbook: Monitoring LLM Security"
description: LLM security requires effective run-time checks and ex-post monitoring and evaluation. We have added new documentation and a cookbook on how to effectively leverage popular LLM security tools while evaluating them in Langfuse.
author: Marc
ogCloudflareVideo: 723473a1698bddb26327f22c463b1105
---

import { ChangelogHeader } from "@/components/changelog/ChangelogHeader";

<ChangelogHeader />

LLM Security can be addressed with a combination of

- strong run-time security measures by LLM security libraries
- and asynchrounous evaluations of the effectiveness of these measures in Langfuse

Check out the new documentation and cookbook to get started!

## Learn more

import { FileCode, BookOpen } from "lucide-react";

<Cards num={3}>
  <Card title="Docs" href="/docs/security/overview" icon={<BookOpen />} />
  <Card
    title="Example Notebook"
    href="/docs/security/example-python"
    icon={<FileCode />}
  />
</Cards>

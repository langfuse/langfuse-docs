---
date: 2025-01-23
title: Configure additional HTTP headers for LLM API keys
description: Configure additional HTTP headers for LLM API keys to include custom headers in requests to provider endpoints, particularly useful for OpenAI-compliant LLM proxies.
author: Hassieb
---

import { ChangelogHeader } from "@/components/changelog/ChangelogHeader";

<ChangelogHeader />

You can now configure LLM API keys used for the Langfuse playground and evaluations to include additional HTTP headers in all requests to the configured provider endpoint.

This is especially useful when using an OpenAI-compliant LLM proxy to power Langfuse features such as the playground or LLM-as-a-judge on your traces.

This feature is currently available for the `openai` adapter only. If you require support for extra HTTP headers for other adapters as well, please open a [Github issue](https://github.com/orgs/langfuse/discussions/new?category=ideas) .

**Learn more**

- [LLM playground](/docs/playground)
- [LLM-as-a-judge](/docs/scores/model-based-evals)

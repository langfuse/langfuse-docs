---
title: OTEL-based Python SDK
description: The latest generation of the Langfuse Python SDK, built on the OpenTelemetry framework.
date: 2025-05-23
author: Hassieb
---

import { ChangelogHeader } from "@/components/changelog/ChangelogHeader";

<ChangelogHeader />

On Day 5 of our [Launch Week #3](/blog/2025-05-19-launch-week-3), we're introducing the Langfuse Python SDK v3 (OpenTelemetry-based) in beta.

This is a significant update to our Python SDK as it is now built on the [OpenTelemetry (OTEL) standard](https://opentelemetry.io/) and designed to improve developer experience and enhance integration capabilities for tracing your LLM applications.

**Key Improvement: OpenTelemetry Integration**

The foundation of the v3 SDK is OpenTelemetry, which brings several practical advantages:

- **Standardized Context Propagation**: OTEL automatically handles the propagation of trace and span context. This means when you create a new span or generation, it correctly nests under the currently active operation.
- **Third-Party Library Compatibility**: Libraries already instrumented with OpenTelemetry will integrate with the Langfuse SDK, with their spans being captured and correctly nested within your Langfuse traces.

**Simplified Tracing and Global Client Access**

The new SDK aims to make tracing more straightforward. Here's an example of how tracing can be implemented across different modules, leveraging automatic context propagation and global client access:

```python
# main_app.py
from langfuse import Langfuse, observe
import other_module

# Initialize once, perhaps at your application's entry point
langfuse = Langfuse()

@observe(name="user-request-pipeline")
def handle_user_request(user_query: str, user_id: str):
    # This span is now active. Enrich the trace with user info.
    langfuse.update_current_trace(user_id=user_id, tags=["experimental"])

    # Call a function from another module
    processed_data = other_module.process_data(user_query)

    # Update the root span
    langfuse.update_current_span(output={"final_result": processed_data})
    return processed_data

handle_user_request("Tell me a joke about OpenTelemetry", "user_123")
```

```python
# other_module.py
from langfuse import get_client, observe

# Access the initialized Langfuse client globally
# If no client is initialized, it will be initialized with the default configuration
# from the environment variables
langfuse_client = get_client()

@observe(name="data-processing-step")
def process_data(query: str):
    # This span is automatically a child of "user-request-pipeline".

    with langfuse_client.start_as_current_generation(
        name="joke-generation-llm",
        model="gpt-4o",
        input=[{"role": "user", "content": query}]
    ) as generation:
        # Simulate LLM call
        joke = "Why did the OpenTelemetry collector break up with the span? It needed more space for its attributes!"
        generation.update(output=joke, usage_details={"input_tokens": 10, "output_tokens": 25})

    return joke
```

In this example:

- `Langfuse` is initialized once.
- The `@observe` decorator creates spans for `handle_user_request` and `process_data`.
- `other_module.py` accesses the same client instance via `get_client()`.
- Spans are automatically nested due to OTEL's context propagation.
- Trace and span updates can be done contextually.

**Key Changes and Improvements:**

- **Context Management**: OpenTelemetry now handles context propagation automatically, reducing the need to manually pass IDs.
- **API for Observations**:
  - Traces are implicitly created by the first (root) span or generation.
  - Use `langfuse.start_as_current_span()` or `langfuse.start_as_current_generation()` with context managers for automatic lifecycle management.
  - Manual creation via `langfuse.start_span()` or `langfuse.start_generation()` requires an explicit `.end()` call.
  - The `name` parameter is now required when creating spans and generations.
- **Observation IDs**: Trace and Observation (Span) IDs adhere to the W3C Trace Context format. Use `langfuse.create_trace_id()` for generating IDs, including deterministic ones using a `seed`.
- **Updating Observations**:
  - Use the `.update()` method on `LangfuseSpan` or `LangfuseGeneration` objects.
  - Update the currently active observation via `langfuse.update_current_span()` or `langfuse.update_current_generation()`.
  - Update trace-level attributes via `span_obj.update_trace()` or `langfuse.update_current_trace()`.
- **Integrations (OpenAI, Langchain)**: Trace-level attributes (like `user_id`, `session_id`) are now managed by creating an enclosing Langfuse span around the integrated library calls.
- **LlamaIndex**: There is no longer a Langfuse-specific LlamaIndex integration; use third-party OTEL-based instrumentations.

We encourage you to try the new Python SDK v3 beta and welcome your feedback on [GitHub](https://github.com/langfuse/langfuse/issues).

**Learn more**

- [Python SDK V3 docs](/docs/sdk/python/otel_based_sdk_v3)
- [OpenTelemetry Specification](https://opentelemetry.io/docs/specs/otel/trace/api/)
- [OpenTelemetry Python SDK docs](https://opentelemetry-python.readthedocs.io/en/latest/)

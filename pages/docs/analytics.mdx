---
description: Langfuse analytics derives actionable insights from production data. Currently in closed alpha.
---

# Analytics

import { Callout } from "nextra/components";
import { Frame } from "@/components/Frame";
import Image from "next/image";

<Callout type="info" emoji="ℹ️">
  Langfuse analytics is currently in alpha.
</Callout>

Langfuse analytics derives actionable insights from production data.

People use Langfuse analytics to answer questions such as:

- _How helpful are my LLM app's outputs?_
- _What is my LLM API spend by customer?_
- _What do latencies look like across geographies and steps of LLM chains?_
- _Did the quality of the application improve in newer versions? What was the impact of switching from zero-shotting GPT4 to using chained few-shotted Llama calls?_

_Example: time series of core metrics incl tracking of releases_

<Frame>![Analytics Screen](/images/docs/analytics.png)</Frame>

## Metrics

- **Quality** is measured through user feedback, model-based scoring and human-in-the-loop scored samples. Quality is assessed over time as well as across prompt versions, LLMs and users.
- **Cost and Latency** are accurately measured and broken down by user, session, geography, feature, model and prompt version.

## Insights

- **Monitor quality/cost/latency tradeoffs** by version to facilitate product and engineering decisions
- **Cluster use cases** by employing a classifier to understand what users are doing
- Break down **LLM usage by customer** for usage-based billing and profitability analysis

## Get early-access

Langfuse analytics is currently in a closed alpha as the core team works with a group of users to build the most useful analytics platform for LLM apps.

Reach out if you are interested in early access: early-access@langfuse.com

## Why is this an alpha?

Why is this an alpha program? We rely on some closed source software to make this work in order to move fast and focus on what's most interesting for most of you. We'll soon bring these features to all users since we currently plan a migration to an OLAP database and flexible modeling structure to power these features.

---
title: Core Features
description: Overview of all core features in Langfuse across the different product areas.
---

# Feature Overview

Langfuse consists of tooling for LLM Application tracing, evaluation, and prompt engineering.
See [general overview](/docs) to learn more about them.

## Tracing

Instrument your app and start ingesting [traces](/docs/tracing) to Langfuse, thereby tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions. Inspect and debug complex logs and user sessions.

import TracingOverview from "@/components-mdx/tracing-overview-gifs.mdx";

<div className="h-6" />
<TracingOverview />

## Prompt Management

[Langfuse Prompt Management](/docs/prompts) helps you centrally manage, version control, and collaboratively iterate on your prompts.

import PromptOverview from "@/components-mdx/prompt-overview-gifs.mdx";

<div className="h-6" />
<PromptOverview />

The [LLM Playground](/docs/playground) is a tool for testing and iterating on your prompts and model configurations, shortening the feedback loop and accelerating development.

<div className="h-6" />
<CloudflareVideo
  videoId="3cfab665df39518f15fc18813cf82e3f"
  aspectRatio={16 / 10.47}
  title="LLM Playground"
/>

## Evaluations

[Evaluations](/docs/scores) are the most important part of the LLM Application development workflow. Langfuse adapts to your needs and supports LLM-as-a-judge, user feedback, manual labeling, and custom evaluations.

import EvaluationOverview from "@/components-mdx/evaluation-overview-gifs.mdx";

<div className="h-6" />
<EvaluationOverview />

## Datasets

Via [Langfuse Datasets](/docs/datasets) you can create test sets and benchmarks to evaluate the performance of your LLM application in development.

import DatasetsOverview from "@/components-mdx/datasets-overview-gif.mdx";

<div className="h-6" />
<DatasetsOverview />

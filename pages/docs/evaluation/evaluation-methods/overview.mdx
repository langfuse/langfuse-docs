---
title: Evaluation Methods Overview
description: Langfuse a broad range of evaluation methods. You can combine methods like model-based evaluations (LLM-as-a-Judge), manual annotations or custom evaluations vis API/SDK. This allows you to measure quality, tone, factual accuracy, completeness, and other dimensions of your LLM application.
---

# Evaluation Methods Overview

Evaluation is a critical aspect of developing and deploying LLM applications. Usually, teams use a multitude of different evaluation methods to score the performance of their AI application depending on the use case and the stage of the development process.
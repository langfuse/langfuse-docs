---
title: Get Started with Online Evaluation
description: Get started with online evaluation in Langfuse.
sidebarTitle: Online
---

# Online Evaluation

<Callout type="warning" icon="ðŸš§">

This page is a work in progress and will be released in the coming days.

</Callout>

Online evaluation is a way to evaluate the quality of your LLM application in real-time. The core motivation is to:

1. Monitor quality, cost, latency, and security issues in real-time
2. Learn from production data in order to improve prompts, tools, and other application components
3. Debug issues upon negative evaluation scores or user feedback

## How to get started

<Steps>

### Capture Traces of real user interactions

Production traces are the source of truth for online evaluation.
See [Observability](/docs/observability/overview) section on how to get started with tracing.

### Set up online evals

Depending on your use case, you can set up online evals in the following ways:

- User Feedback
- Implicit User Feedback
- Run-time guardrails
- Run-time executionable checks
- Non-grounded LLM-as-a-Judge

</Steps>

---
description: Get started with LLM observability with Langfuse in minutes before diving into all platform features.
---

# Get Started with Langfuse Tracing

This quickstart helps you to ingest your first trace in Langfuse.

<Steps>

## Get API keys

1.  [Create Langfuse account](https://cloud.langfuse.com/auth/sign-up) or [self-host Langfuse](/self-hosting).
2.  Create new API credentials in the project settings.

## Ingest your first trace

import { CopyAgentOnboardingPrompt } from "@/components/agentic-onboarding/CopyAgentOnboardingPrompt";
import DocsMcpServerInstallation from "@/components-mdx/docs-mcp-server-installation.mdx";
import GetStartedPythonSdk from "@/components-mdx/get-started/python-sdk.mdx";
import GetStartedJsSdk from "@/components-mdx/get-started/js-sdk.mdx";
import GetStartedOpenaiSdk from "@/components-mdx/get-started/openai-sdk.mdx";
import GetStartedLangchain from "@/components-mdx/get-started/langchain.mdx";
import GetStartedJsOpenaiSdk from "@/components-mdx/get-started/js-openai-sdk.mdx";
import GetStartedJsLangchain from "@/components-mdx/get-started/js-langchain.mdx";
import EnvPython from "@/components-mdx/env-python.mdx";

import { BookOpen, Code} from "lucide-react";

<Tabs items={["OpenAI SDK (Python)", "OpenAI SDK (JS/TS)", "LangChain (Python)", "LangChain (JS/TS)", "Python SDK", "JS/TS SDK", "âœ¨ Auto Install", "More integrations"]}>

<Tab>
{/* PYTHON - OPENAI*/}

Use the drop-in replacement for the OpenAI Python SDK to get full observability.

<GetStartedOpenaiSdk/>

<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/integrations/model-providers/openai-py"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/colab_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Notebook"
    href="https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/integration_openai_sdk.ipynb"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* JS/TS - OpenAI */}

Use the Langfuse wrapper function around the OpenAI JS/TS SDK for full observability.

<GetStartedJsOpenaiSdk/>

<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/integrations/model-providers/openai-js"
    arrow
  />
  <Card
    icon={<Code />}
    title="Notebook"
    href="/guides/cookbook/js_integration_openai"
    arrow
  />
</Cards>

</Tab>


<Tab>
{/* LANGCHAIN */}

Use the Langfuse CallbackHandler to get full observability of the LangChain Python SDK.

<GetStartedLangchain/>


<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/integrations/frameworks/langchain"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/colab_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Notebook"
    href="https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/integration_langchain.ipynb"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* LANGCHAIN (JS/TS) */}

Use the Langfuse CallbackHandler to get full observability of the LangChain JS/TS SDK.

<GetStartedJsLangchain/>

<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/integrations/frameworks/langchain"
    arrow
  />
  <Card
    icon={<Code />}
    title="Notebook"
    href="/guides/cookbook/js_integration_langchain"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* PYTHON SDK */}

Use the Langfuse Python SDK to wrap any LLM or Agent

```bash
pip install langfuse
```

<EnvPython />

There are three main ways of creating traces with the Python SDK:

<GetStartedPythonSdk/>

<Cards num={1}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/docs/sdk/python/sdk-v3"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* JS/TS SDK */}

Use the Langfuse JS/TS SDK to wrap any LLM or Agent

<GetStartedJsSdk/>

<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/docs/sdk/typescript/guide"
    arrow
  />
  <Card
    icon={<Code />}
    title="Notebook"
    href="/docs/sdk/typescript/example-notebook"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* AUTO INSTALL */}

Use the agent mode of your editor to integrate Langfuse into your existing codebase.

<Callout type="warning" emoji="ðŸ¤–">
This might or might not work very well (depending on your code base). Please share any feedback or issues on [GitHub](/issues).
</Callout>

**1. Install the Langfuse Docs MCP Server (optional)**

The agent will use the Langfuse `searchLangfuseDocs` tool ([docs](/docs/docs-mcp)) to find the correct documentation for the integration you are looking for. This is optional, alternatively the agent can use its native websearch capabilities.

<DocsMcpServerInstallation />

**2. Run Agent**

Copy and execute the following prompt in the agent mode of your editor:

<CopyAgentOnboardingPrompt />

</Tab>

<Tab>
{/* MORE INTEGRATIONS */}

Explore all integrations and frameworks that Langfuse supports.


<Cards num={2}>
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/vercel_ai_sdk_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Vercel AI SDK"
    href="/integrations/frameworks/vercel-ai-sdk"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/llamaindex_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Llamaindex"
    href="/integrations/frameworks/llamaindex"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/crewai_icon.svg" className="w-full h-full object-contain" />
      </div>
    }
    title="CrewAI"
    href="/integrations/frameworks/crewai"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/ollama_icon.svg" className="w-full h-full object-contain" />
      </div>
    }
    title="Ollama"
    href="/integrations/model-providers/ollama"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/litellm_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="LiteLLM"
    href="/integrations/gateways/litellm"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/autogen_icon.svg" className="w-full h-full object-contain" />
      </div>
    }
    title="AutoGen"
    href="/integrations/frameworks/autogen"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/google_adk_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Google ADK"
    href="/integrations/frameworks/google-adk"
    arrow
  />
  <Card
    title="All integrations"
    href="/integrations"
    arrow
  />
</Cards>


</Tab>

</Tabs>

## See your trace in Langfuse

After running your application, visit the Langfuse interface to view the trace you just created. _[(Example LangGraph trace in Langfuse)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7d5f970573b8214d1ca891251e42282c)_

<CloudflareVideo
  videoId="80d78d99dc1ca12276dbc5c43edb1583"
  aspectRatio={16 / 9}
  gifStyle
/>

</Steps>

## Next Steps

import NextSteps from "@/components-mdx/get-started/next-steps.mdx";

<NextSteps />


## FAQ

import { FaqPreview } from "@/components/faq/FaqPreview";

<FaqPreview tags={["setup"]} />

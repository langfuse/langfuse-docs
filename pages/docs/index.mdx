---
title: Langfuse Documentation
description: Langfuse is an open source LLM engineering platform. It includes observability, analytics, and experimentation features.
faq-tags: [security]
---

import { ProductUpdateSignup } from "@/components/productUpdateSignup";

# What is Langfuse?

> Langfuse is an **open-source LLM engineering platform** that helps teams collaboratively debug, analyze, and iterate on their LLM applications. All platform features are natively integrated to accelerate the development workflow.

<details>
<summary>Why Langfuse?</summary>

- Most used open-source LLMOps platform ([blog post](/blog/2024-11-most-used-oss-llmops))
- Model and framework agnostic
- Built for production
- Incrementally adoptable, start with one feature and expand to the full platform over time
- API-first, all features are available via API for custom integrations
- Optionally, Langfuse can be easily self-hosted

[Learn more](/why) about why teams chose Langfuse.

</details>

## LLM Application Observability

Instrument your app and start ingesting traces to Langfuse, thereby tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions. Inspect and debug complex logs and user sessions.

[Learn more](/docs/tracing) about tracing in Langfuse or play with the [interactive demo](/docs/demo).

<details>
<summary>Key benefits</summary>
  
- **Full context:** Capture the complete execution flow including API calls, context, prompts, parallelism and more
- **Conversation/session view:** In multi-turn conversations, group interactions into sessions
- **User tracking:** Add your own identifiers to inspect traces from specific users
- **Cost tracking:** Monitor model usage and costs across your application
- **Quality insights:** Collect user feedback and identify low-quality outputs
- **Low overhead:** Designed for production with minimal performance impact
- **Best-in-class SDKs:** We offer best-in-class SDKs for Python, JS/TS for easy integration
- **Framework support:** Integrated with popular frameworks like OpenAI SDK, LangChain, and LlamaIndex
- **Multi-modal:** Support for tracing text, images and other modalities
- **Open source:** Fully open source with public API for custom integrations

</details>

import TracingOverview from "@/components-mdx/tracing-overview-gifs.mdx";

<TracingOverview />

## Prompt Management

[Langfuse Prompt Management](/docs/prompts) helps you centrally manage, version control, and collaboratively iterate on your prompts.

<details>
<summary>Key benefits</summary>

- **Decoupled from code:** Deploy new prompts without application redeployment
- **Version control:** Track changes and quickly rollback when needed
- **Performance optimized:** Client-side caching prevents latency or availability issues
- **Multi-format support:** Works with both text and chat prompts
- **Flexible access:** Edit via UI, SDKs, or API
- **Non-technical friendly:** Business users can update prompts via Console

</details>

import PromptOverview from "@/components-mdx/prompt-overview-gifs.mdx";

<PromptOverview />

## Evaluations

[Evaluations](/docs/scores) are the most important part of the LLM Application development workflow. Langfuse adapts to your needs and supports:

- **LLM-as-a-judge:** Fully managed evaluators run on production or development traces within Langfuse
- **User feedback:** Collect feedback from your users and add it to traces in Langfuse
- **Manual labeling:** Annotate traces with human feedback in managed workflows
- **Custom:** Build your own evaluation pipelines via Langfuse APIs/SDKs for full flexibility

import EvaluationOverview from "@/components-mdx/evaluation-overview-gifs.mdx";

<EvaluationOverview />

## Playground

The [LLM Playground](/docs/playground) is a tool for testing and iterating on your prompts and model configurations, shortening the feedback loop and accelerating development.

<details>
<summary>Key features</summary>

- **Integrated:** Jump to the playground from prompt management and observability
- **Supports variables:** Use variables in your prompts to dynamically change the input
- **Broad model support:** OpenAI, Anthropic, Azure OpenAI, and Amazon Bedrock
- **Custom model configurations:** You can configure custom model endpoints and credentials

</details>

<CloudflareVideo
  videoId="3cfab665df39518f15fc18813cf82e3f"
  aspectRatio={16 / 10.47}
  title="LLM Playground"
/>

## Experimentation / benchmarking

Via [Langfuse Datasets](/docs/datasets) you can create test sets and benchmarks to evaluate the performance of your LLM application.

---

### Develop

- **Prompt Management:** Manage, version and deploy prompts from within Langfuse ([Prompt Management](/docs/prompts/get-started))
- **Prompt Engineering:** Test and iterate on your prompts with the [LLM Playground](/docs/playground)

### Monitor

- **Analytics:** Track metrics (LLM cost, latency, quality) and gain insights from dashboards & data exports ([Analytics](/docs/analytics), [Daily Metrics API](/docs/analytics/daily-metrics-api))
- **Evals:** Collect and calculate scores for your LLM completions ([Evaluations](/docs/scores))
  - Run [model-based evaluations](/docs/scores/model-based-evals/overview) within Langfuse
  - Collect [user feedback](/docs/scores/user-feedback)
  - [Annotate](/docs/scores/annotation) observations in Langfuse

### Test

- **Experiments:** Track and test app behaviour before deploying a new version
  - [Datasets](/docs/datasets/overview) let you test expected in and output pairs and benchmark performance before deployiong
  - Track versions and releases in your application ([Experimentation](/docs/experimentation), [Prompt Management](/docs/prompts/get-started))

## Get started

<Cards num={3}>
  <Card href="/docs/tracing" title="How tracing works" arrow />
  <Card href="/docs/get-started" title="Quickstart" arrow />
  <Card href="/docs/demo" title="Interactive demo" arrow />
</Cards>

## Why Langfuse?

import { Callout } from "nextra/components";

<Callout type="info">
  We wrote a concise manifesto on: [Why Langfuse?](/why)
</Callout>

- Open-source
- Model and framework agnostic
- Built for production
- Incrementally adoptable - start with a single LLM call or integration, then expand to full tracing of complex chains/agents
- Use the GET API to build downstream use cases

<div className="rounded px-5 py-5 my-10 bg-primary/5 ring-1 ring-primary/20">

<h3 className="_font-semibold _tracking-tight _text-slate-900 dark:_text-slate-100 _text-2xl">
  Challenges of building LLM applications and how Langfuse helps
</h3>

In implementing popular LLM use cases – such as retrieval augmented generation, agents using internal tools & APIs, or background extraction/classification jobs – developers face a unique set of challenges that is different from traditional software engineering:

**Tracing & Control Flow**: Many valuable LLM apps rely on complex, repeated, chained or agentic calls to a foundation model. This makes debugging these applications hard as it is difficult to pinpoint the root cause of an issue in an extended control flow.

_With Langfuse_, it is simple to capture the full context of an LLM application. Our client SDKs and integrations are model and framework agnostic and able to capture the full context of an execution. Users commonly track LLM inference, embedding retrieval, API usage and any other interaction with internal systems that helps pinpoint problems. Users of frameworks such as Langchain benefit from automated instrumentation, otherwise the SDKs offer an ergonomic way to define the steps to be tracked by Langfuse.

**Output quality**: In traditional software engineering, developers are used to testing for the absence of exceptions and compliance with test cases. LLM-based applications are non-deterministic and there rarely is a hard-and-fast standard to assess quality. Understanding the quality of an application, especially at scale, and what ‘good’ evaluation looks like is a main challenge. This problem is accelerated by changes to hosted models that are outside of the user’s control.

_With Langfuse_, users can attach scores to production traces (or even sub-steps of them) to move closer to measuring quality. Depending on the use case, these can be based on model-based evaluations, user feedback, manual labeling or other e.g. implicit data signals. These metrics can then be used to monitor quality over time, by specific users, and versions/releases of the application when wanting to understand the impact of changes deployed to production.

**Mixed intent**: Many LLM apps do not tightly constrain user input. Conversational and agentic applications often contend with wildly varying inputs and user intent.
This poses a challenge: teams build and test their app with their own mental model but real world users often have different goals and lead to many surprising and unexpected results.

_With Langfuse_, users can classify inputs as part of their application and ingest this additional context to later analyze their users behavior in-depth.

<Frame
  transparent
  fullWidth
  className="mt-10 rounded ring-primary/20 ring-1 dark:hidden"
>
  ![Langfuse Features along the development
  lifecycle](/images/docs/features-light.png)
</Frame>
<Frame
  transparent
  fullWidth
  className="mt-10 rounded ring-primary/20 ring-1 hidden dark:block"
>
  ![Langfuse Features along the development
  lifecycle](/images/docs/features-dark.png)
</Frame>
<span>_Langfuse features along the development lifecycle_</span>

</div>

## Updates

Langfuse evolves quickly, check out the [changelog](/changelog) for the latest updates.

Subscribe to the **mailing list** to get notified about new major features:

<ProductUpdateSignup source="langfuse.com/docs" className="mt-2" />

## Get in touch

We actively develop Langfuse in [open source](/docs/open-source):

- Contribute to and vote on the Langfuse [roadmap](/docs/roadmap).
- Ask questions through [GitHub Discussions](/gh-support) or private [support channels](/support).
- Report bugs using [GitHub Issues](/issue).
- Chat with the Langfuse maintainers and community on [Discord](/discord).

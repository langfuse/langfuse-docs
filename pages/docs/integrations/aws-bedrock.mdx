---
title: Observability for AWS Bedrock
description: Open source observability for AWS Bedrock applications and the Bedrock SDK.
---

# AWS Bedrock - Observability & Metrics via Langfuse

**AWS Bedrock** ([AWS](https://aws.amazon.com/bedrock/)) is a fully managed AWS service that lets you use foundation models and custom models to generate text, images, and audio.

When **using Langfuse with AWS Bedrock**, you can easily capture detailed traces and metrics for every request to AWS Bedrock, giving you insights into the performance and behavior of your application.

There are a few ways through which you can capture traces and metrics for AWS Bedrock:

1. via a Framework such as the popular [Langchain](/docs/integrations/langchain), [Llama Index](/docs/integrations/llama-index) or [Haystack](/docs/integrations/haystack). These frameworks have built-in and battle-tested support for Langfuse.
2. via a Proxy such as [LiteLLM](/docs/integrations/litellm)
3. via the [Langfuse Decorator](/docs/sdk/python/decorators) (_We are currently working on adding more documentation and a cookbook for this._)
4. via the [low-level Python SDK](/docs/sdk/python/low-level-sdk)


### Can I monitor cost and token usage of my Bedrock calls in Langfuse?

Yes, you can monitor cost and token usage of your Bedrock calls in Langfuse. The easiest way to do this as of now is to either use Langfuse via a framework/proxy such as Langchain or LiteLLM. Or you can return the cost and token usage you receive in Bedrock's SDK payload to the Langfuse Decorator or the low-level Python SDK.

### Resources

- Metadocs, [Monitoring your Langchain app's cost using Bedrock with Langfuse](https://www.metadocs.co/2024/07/03/monitor-your-langchain-app-cost-using-bedrock-with-langfuse/)


---
title: Langfuse Observability & Tracing Integrations
description: Langfuse natively integrates with OpenAI SDK, Llama Index, Langchain (Python&JS), Vercel AI SDK, Haystack, Dify Flowise, LiteLLM and Langflow
---

# Langfuse Integrations Overview

Integrate your application with Langfuse to explore production traces and metrics.

Objective:

1. Capture [traces](/docs/tracing) of your application
2. Add [scores](/docs/scores) to these traces to measure/evaluate quality of outputs

## Main Integrations

| Integration                                              | Supports                   | Description                                                                                                                                      |
| -------------------------------------------------------- | -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| [SDK](/docs/sdk)                                         | Python, JS/TS              | Manual instrumentation using the SDKs for full flexibility.                                                                                      |
| [OpenAI](/docs/integrations/openai)                      | Python, JS/TS              | Automated instrumentation using drop-in replacement of OpenAI SDK.                                                                               |
| [Langchain](/docs/integrations/langchain)                | Python, JS/TS              | Automated instrumentation by passing callback handler to Langchain application.                                                                  |
| [LlamaIndex](/docs/integrations/llama-index/get-started) | Python                     | Automated instrumentation via LlamaIndex callback system.                                                                                        |
| [Haystack](/docs/integrations/haystack)                  | Python                     | Automated instrumentation via Haystack content tracing system.                                                                                   |
| [LiteLLM](/docs/integrations/litellm)                    | Python, JS/TS (proxy only) | Use any LLM as a drop in replacement for GPT. Use Azure, OpenAI, Cohere, Anthropic, Ollama, VLLM, Sagemaker, HuggingFace, Replicate (100+ LLMs). |
| [Vercel AI SDK](/docs/integrations/vercel-ai-sdk)        | JS/TS                      | TypeScript toolkit designed to help developers build AI-powered applications with React, Next.js, Vue, Svelte, Node.js.                          |
| [API](/docs/api)                                         |                            | Directly call the public API. OpenAPI spec available.                                                                                            |

## Packages integrated with Langfuse

| Name                                                | Type               | Description                                                                                                             |
| --------------------------------------------------- | ------------------ | ----------------------------------------------------------------------------------------------------------------------- |
| [Instructor](/docs/integrations/instructor)         | Library            | Library to get structured LLM outputs (JSON, Pydantic)                                                                  |
| [DSPy](/docs/integrations/dspy)                     | Library            | Framework that systematically optimizes language model prompts and weights                                              |
| [Mirascope](/docs/integrations/mirascope)           | Library            | Python toolkit for building LLM applications.                                                                           |
| [Ollama](/docs/integrations/ollama)                 | Model (local)      | Easily run open source LLMs on your own machine.                                                                        |
| [Amazon Bedrock](/docs/integrations/amazon-bedrock) | Model              | Run foundation and fine-tuned models on AWS.                                                                            |
| [Flowise](/docs/integrations/flowise)               | Chat/Agent&nbsp;UI | JS/TS no-code builder for customized LLM flows.                                                                         |
| [Langflow](/docs/integrations/langflow)             | Chat/Agent&nbsp;UI | Python-based UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows. |
| [Dify](/docs/integrations/dify)                     | Chat/Agent&nbsp;UI | Open source LLM app development platform with no-code builder.                                                          |
| [OpenWebUI](/docs/integrations/openwebui)           | Chat/Agent&nbsp;UI | Self-hosted LLM Chat web ui supporting various LLM runners including self-hosted and local models.                      |
| [Promptfoo](/docs/integrations/promptfoo)           | Tool               | Open source LLM testing platform.                                                                                       |
| [LobeChat](/docs/integrations/lobechat)             | Chat/Agent&nbsp;UI | Open source chatbot platform.                                                                                           |
| [Inferable](/docs/integrations/inferable)           | Agents             | Open source LLM platform for building distributed agents platform.                                                      |

Unsure which integration to choose? Ask us on [Discord](/discord) or in the chat.

## Request a new integration

We use GitHub Discussions to track interest in new integrations. Please upvote/add to the list below if you'd like to see a new integration.

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["integrations"]} filterCategory="Ideas" />

## End to end examples

If you want to see how things work together, you can look at the end-to-end examples below. They are Jupyter notebooks that you can easily run in Google Colab or locally.

<Callout type="info">
  Generally, we recommend reading the get started guides for each integration
  first.
</Callout>

import { CookbookIndex } from "@/components/CookbookIndex";

<CookbookIndex categories={["Integrations", "SDKs", "Examples"]} />

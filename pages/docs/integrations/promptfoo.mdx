---
title: "Promptfoo Integration with Langfuse Prompt Management"
description: "Learn how to integrate Promptfoo with Langfuse for advanced prompt management and prompt collaboration. Follow our detailed step-by-step guide for easy setup and enhanced performance."
---

# Promptfoo Integration with Langfuse Prompt Management

[Promptfoo](https://www.promptfoo.dev/) is an open-source LLM testing platform. It offers tools for red teaming, vulnerability scanning, and LLM evaluations, helping teams ensure the security and reliability of their LLM applications.

Integrate Promptfoo with Langfuse to take advantage of Langfuse's prompt management features during your Promptfoo evaluations. By using this integration, you can easily reference and [manage prompts](/docs/prompts/get-started) directly within Langfuse, making your LLM testing process more efficient and organized.

With Langfuse Prompt Management, you can:

- Update prompts without redeploying your application.
- Track and revert to previous prompt versions.
- Monitor and optimize prompt performance.
- Integrate prompts seamlessly with your tools and applications.
- Manage prompts via UI, SDKs, or API with minimal latency.

For more details, visit the [Langfuse Prompt Management documentation](/docs/prompts/get-started).

Thanks to the team at Promptfoo for developing this integration ([docs](https://www.promptfoo.dev/docs/integrations/langfuse)).

## Quick Start Guide

<Steps>

### Step 1: Set up Langfuse

1. Install the langfuse SDK: `npm install langfuse`
2. Visit [Langfuse](https://cloud.langfuse.com) to create an account.
3. Create a new project and copy your Langfuse API keys.
4. Set the `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, and `LANGFUSE_HOST` environment variables as desired.

### Step 2: Create a Langfuse Prompt

You can create, edit and manage your prompts via the Langfuse UI, SDKs, or API.

<Tabs items={["Langfuse UI", "Python", "JS/TS"]}>
<Tab>

<CloudflareVideo
  videoId="3c9bf36417e79dd2d68c3bba2a8f0a98"
  aspectRatio={1.24}
  gifStyle
  className="max-w-xl"
/>

</Tab>
<Tab>

```python
# Create a text prompt
langfuse.create_prompt(
    name="movie-critic",
    type="text",
    prompt="As a {{criticlevel}} movie critic, do you like {{movie}}?",
    labels=["production"],  # directly promote to production
    config={
        "model": "gpt-3.5-turbo",
        "temperature": 0.7,
        "supported_languages": ["en", "fr"],
    },  # optionally, add configs (e.g. model parameters or model tools) or tags
)

# Create a chat prompt
langfuse.create_prompt(
    name="movie-critic-chat",
    type="chat",
    prompt=[
      { role: "system", content: "You are an {{criticlevel}} movie critic" },
      { role: "user", content: "Do you like {{movie}}?" },
    ],
    labels=["production"],  # directly promote to production
    config={
        "model": "gpt-3.5-turbo",
        "temperature": 0.7,
        "supported_languages": ["en", "fr"],
    },  # optionally, add configs (e.g. model parameters or model tools) or tags
)
```

If you already have a prompt with the same name, the prompt will be added as a new version.

</Tab>

<Tab>

```typescript
// Create a text prompt
await langfuse.createPrompt({
  name: "movie-critic",
  type: "text",
  prompt: "As a {{criticlevel}} critic, do you like {{movie}}?",
  labels: ["production"], // directly promote to production
  config: {
    model: "gpt-3.5-turbo",
    temperature: 0.7,
    supported_languages: ["en", "fr"],
  }, // optionally, add configs (e.g. model parameters or model tools) or tags
});

// Create a chat prompt
await langfuse.createPrompt({
  name: "movie-critic-chat",
  type: "chat",
  prompt: [
    { role: "system", content: "You are an {{criticlevel}} movie critic" },
    { role: "user", content: "Do you like {{movie}}?" },
  ],
  labels: ["production"], // directly promote to production
  config: {
    model: "gpt-3.5-turbo",
    temperature: 0.7,
    supported_languages: ["en", "fr"],
  }, // optionally, add configs (e.g. model parameters or model tools) or tags
});
```

If you already have a prompt with the same name, the prompt will be added as a new version.

</Tab>

</Tabs>

### Step 3: Reference Prompts in Promptfoo

Now you can use the prompts you created in Langfuse with Promptfoo. Use the `langfuse://` prefix for your prompts in your Promptfoo configuration file, followed by the Langfuse prompt ID and version. For example:

```yaml
prompts:
  - "langfuse://foo-bar-prompt:3"
providers:
  - openai:gpt-4o-mini
tests:
  - vars:
      # ...
```

Variables from your Promptfoo test cases will be automatically plugged into the Langfuse prompt as variables.

</Steps>

## GitHub Discussions

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["integration-promptfoo"]} />

---
title: Tracing Data Model in Langfuse
description: Langfuse (open source) helps you trace and analyze LLM applications. Learn how traces and observations are structured in Langfuse.
---

# Core Concepts

This page digs into the underlying concepts of how Langfuse structures and captures your data. Understanding these will make debugging and working with traces easier.

Ready to start? Check out the [Get Started guide](/docs/observability/get-started) to ingest your first trace.

## Traces, Observations and Sessions

Langfuse organizes an application's data into three core concepts: sessions, traces and observations.

```mermaid
flowchart LR

    subgraph SESSION [session]
        direction TB

        subgraph TRACE1 [trace]
            direction LR
            O1[observation]
            O2[observation]
            O3[observation]
        end

        subgraph TRACE2 [trace]
            direction LR
            O4[observation]
            O5[observation]
            O6[observation]
        end

        subgraph TRACE3 [trace]
            direction LR
            O7[observation]
            O8[observation]
            O9[observation]
        end

    end
    classDef sessionBox fill:#ffffff,stroke:#888,stroke-width:2px;
    classDef traceBox fill:#ffffff,stroke:#aaa,stroke-width:1.5px;
    classDef obsBox fill:#E0EFFF,stroke:#ccc;

    %% Assign classes
    class SESSION sessionBox;
    class TRACE1,TRACE2,TRACE3 traceBox;
    class O1,O2,O3,O4,O5,O6,O7,O8,O9 obsBox;
```
### Traces

A `trace` typically represents a single request or operation.
For example, when a user asks a question to a chatbot, that interaction, from the user's question to the bot's response, is captured as one trace. 

It contains the overall input and output of the function, as well as metadata about the request ( i.e. user, session, tags, etc.).

import ObservationTypesList from "@/components-mdx/observation-types-list.mdx";

### Observations

Each trace can contain multiple `observations` to log the individual steps of the execution.  Example observations include LLM text generations, toolcalls, RAG retrieval steps, etc.

#### Nesting

Observations can be nested. The example below shows a trace with a nested observation.

<div className="grid grid-cols-2 mt-6 gap-2 md:gap-4">

<div className="border rounded py-4 px-4 flex flex-col items-center justify-center bg-card">

Hierarchical structure of traces in Langfuse

<div className="flex-1 flex items-center justify-center ">

```mermaid
---
config:
  showSequenceNumbers: true
  theme: base
  themeVariables:
    primaryColor: "#E0EFFF"
    noteBkgColor: "#FCFCFC"
---
classDiagram
    Trace "1" *-- "n" Observation
    Observation o-- Observation: Nesting
```

</div>

</div>

<div className="border rounded py-4 px-4 text-center block dark:hidden bg-card">

Example trace in Langfuse UI

![Trace in Langfuse UI](/images/docs/tracing-observation-tree-light.png)

</div>

<div className="border rounded py-4 px-4 text-center bg-card hidden dark:block">

Example trace in Langfuse UI

![Trace in Langfuse UI](/images/docs/tracing-observation-tree-dark.png)

</div>

</div>

#### Types

Langfuse supports a number of LLM application specific [observation types](/docs/observability/features/observation-types):

<ObservationTypesList />

The advantage of using observation types is that you can filter on them, and certain types have special handling in the Langfuse UI.

### Sessions

Optionally, traces can be grouped into [sessions](/docs/tracing-features/sessions).
Sessions are used to group traces that are part of the same user interaction.
A common example is a thread in a chat interface. 

<div className="grid grid-cols-2 mt-6 gap-2 md:gap-4">

<div className="border rounded py-4 text-center px-4 flex flex-col bg-card">

Optionally, sessions aggregate traces

<div className="flex-1 flex items-center justify-center">

```mermaid
---
config:
  showSequenceNumbers: true
  theme: base
  themeVariables:
    primaryColor: "#E0EFFF"
    noteBkgColor: "#FCFCFC"
---
classDiagram
    Session "1" o-- "n" Trace
```

</div>

</div>

<div className="border rounded py-4 px-4 text-center block bg-card">

Example session in Langfuse UI

<Frame fullWidth>![Session view](/images/docs/session.png)</Frame>

</div>

</div>

Using sessions is recommended for applications with multi-turn conversations or workflows. Please refer to the [Sessions](/docs/tracing-features/sessions) documentation to add sessions to your traces.


## How Langfuse Captures Data

Now that you understand the data model, let's explore how Langfuse actually captures and processes your traces.

### Built on OpenTelemetry

Langfuse is built on [OpenTelemetry](https://opentelemetry.io/), an open standard for collecting telemetry data from applications. 

This means you're not locked into using only Langfuse-specific SDKs. If you're already using a framework that supports OpenTelemetry—like the Vercel AI SDK, LangChain, or LlamaIndex—it'll work with Langfuse out of the box. You can also send your traces to multiple destinations at once, like Langfuse for LLM observability and Datadog for infrastructure monitoring.

Your instrumentation code stays portable. If you decide to self-host Langfuse or switch to a different observability platform later, you won't need to rewrite your tracing code.

### Background Processing

When you add Langfuse tracing to your application, it doesn't send traces immediately the moment they're created. That would introduce network calls in the middle of your request or script, slowing down your application.

Instead, Langfuse batches traces locally and sends them in the background, keeping your application fast and responsive.

```mermaid
---
config:
  showSequenceNumbers: true
  theme: base
  themeVariables:
    primaryColor: "#E0EFFF"
    noteBkgColor: "#FCFCFC"
---
sequenceDiagram
    autonumber
    participant User as End user
    participant App as Application
    participant SDK as Langfuse SDK
    participant Exporter as Background exporter
    participant Langfuse as Langfuse backend

    loop Incoming requests over time
        User->>App: send request
        App->>SDK: createTrace() / log events
        SDK->>Exporter: enqueue(trace/events)
        Note over App,SDK: Tracing is non-blocking<br/>App continues handling request
        App-->>User: response
    end

    loop In the background
        Note over Exporter: Runs on a timer / batch size
        Exporter->>Langfuse: send(batched traces)
        Langfuse-->>Exporter: ack
    end
```

#### Long-running applications

The approach above is perfect for long-running applications (like web servers or APIs) because the background exporter continuously runs and has plenty of time to flush batches on its own.

#### Short-lived applications

For applications that start, execute something, and shut down quickly (such as scripts, CLI tools, or serverless functions), there's a risk that the application terminates while there are still unsent traces in the queue. 

```mermaid
---
config:
  showSequenceNumbers: true
  theme: base
  themeVariables:
    primaryColor: "#E0EFFF"
    noteBkgColor: "#FCFCFC"
---
sequenceDiagram
    autonumber
    participant User as End user
    participant App as Application
    participant SDK as Langfuse SDK
    participant Exporter as Background exporter
    participant Langfuse as Langfuse backend

    User->>App: start script / job
    App->>SDK: createTrace()
    SDK->>Exporter: enqueue(trace)
    Note over Exporter: Trace buffered in memory

    alt No flush() used
        Note over Exporter: Exporter waits for next<br/>background send
        App-->>User: job finished
        App-->>App: process exits
        Note over App,Exporter: Process terminates before<br/>buffer is sent → traces lost
    else flush() used
        App->>SDK: flush() before exit
        SDK->>Exporter: flush()
        Exporter->>Langfuse: send(all buffered traces)
        Langfuse-->>Exporter: ack
        Note over Exporter: Buffer is now empty
        App-->>User: job finished
        App-->>App: process exits
    end
```

To avoid losing data, short-lived applications must explicitly call `flush()` before exiting. This forces the exporter to send all buffered traces immediately, ensuring nothing is lost when the process terminates.


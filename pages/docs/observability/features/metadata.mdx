---
description: Add any customer metadata to your traces to better understand your users, application and experiments.
sidebarTitle: Metadata
---

# Metadata

Traces and observations (see [Langfuse Data Model](/docs/tracing-data-model)) can be enriched with metadata to better understand your users, application, and experiments.
Metadata can be added to traces in the form of arbitrary JSON.

Metadata updates are merged based on the top-level key.
We strongly discourage writing the same key multiple times within your instrumentation.

<Tabs items={["Python SDK", "JS/TS", "OpenAI (Python)", "OpenAI (JS/TS)", "Langchain (Python)", "Langchain (JS/TS)", "Flowise"]}>
<Tab>
When using the `@observe()` decorator:

```python
from langfuse import observe, get_client

langfuse = get_client()

@observe()
def process_data():
    # Access the client and update the current trace metadata

    # Add metadata to the trace level
    langfuse.update_current_trace(
        metadata={"source": "api", "version": "1.2.3"}
    )

    # Add metadata to the current span level
    langfuse.update_current_span(
        metadata={"processing_stage": "initial"}
    )

    # Process data...
    return result
```

When creating spans directly:

```python
from langfuse import get_client

langfuse = get_client()

# Add metadata at trace level
with langfuse.start_as_current_span(
    name="process-request"
) as root_span:
    # Add metadata to the trace
    root_span.update_trace(metadata={"request_id": "req_12345"})

    # Add metadata to the current span
    root_span.update(metadata={"stage": "parsing"})

    # Create a child span with metadata
    with root_span.start_as_current_generation(
        name="generate-response",
        model="gpt-4o",
        metadata={"temperature": 0.7, "max_tokens": 1000}
    ) as gen:
        # Update metadata later if needed
        gen.update(metadata={"completion_type": "creative"})
```

You can add new keys to the metadata object by continuously updating the entity.
We strongly discourage writing the same top-level key multiple times as this will produce an undefined behaviour.

```python
with langfuse.start_as_current_span(name="operation") as span:
    # First write
    span.update(metadata={"status": "started"})

    # Additional key - will be merged with previous metadata
    span.update(metadata={"error": "Failed to process"})

    # Final metadata will be {"status": "started", "error": "Failed to process"}
```

</Tab>
<Tab title="JS/TS SDK">

When using the context manager:

```ts
import {
  startActiveObservation,
  startObservation,
  updateActiveTrace,
} from "@langfuse/tracing";

await startActiveObservation("context-manager", async (span) => {
  // observation metadata
  span.update({
    input: { query: "What is the capital of France?" },
  });

  // trace metadata
  updateActiveTrace({
    metadata: { key: "value" },
  });
});
```

When using the `observe` wrapper:

```ts
import {
  observe,
  updateActiveTrace,
  updateActiveObservation,
} from "@langfuse/tracing";

// An existing function
async function fetchData(source: string) {
  // observation metadata
  updateActiveObservation({
    metadata: { key: "value" },
  });

  // trace metadata
  updateActiveTrace({
    metadata: { key: "value" },
  });

  // ... logic to fetch data
  return { data: `some data from ${source}` };
}

// Wrap the function to trace it
const tracedFetchData = observe(fetchData, {
  name: "observe-wrapper",
});

const result = await tracedFetchData("API");
```

When creating spans manually:

```ts
import { startObservation } from "@langfuse/tracing";

const span = startObservation("manual-observation", {
  input: { query: "What is the capital of France?" },
  metadata: { key: "value" },
});

span.updateTrace({
  metadata: { key: "value" },
});

span.update({ output: "Paris" }).end();
```

See [JS/TS SDK docs](/docs/sdk/typescript/guide) for more details.

</Tab>
<Tab title="OpenAI (Python v2)">

When using the [OpenAI SDK Integration](/integrations/model-providers/openai-py), pass `metadata` as an additional argument:

```python
from langfuse.openai import openai

completion = openai.chat.completions.create(
  name="test-chat",
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a calculator."},
    {"role": "user", "content": "1 + 1 = "}],
  temperature=0,

  # add metadata as additional argument
  metadata={"key":"value"}
)
```

</Tab>
<Tab title="OpenAI (JS/TS)">

When using the [OpenAI SDK Integration (JS)](/integrations/model-providers/openai-js), pass `metadata` as an additional argument:

```ts
import OpenAI from "openai";
import { observeOpenAI } from "@langfuse/openai";

const res = await observeOpenAI(new OpenAI(), {
  metadata: { someMetadataKey: "someValue" },
}).chat.completions.create({
  messages: [{ role: "system", content: "Tell me a story about a dog." }],
  model: "gpt-3.5-turbo",
  max_tokens: 300,
});
```

</Tab>
<Tab>

Option 1: Via metadata fields in chain invocation (simplest approach):

```python
from langfuse.langchain import CallbackHandler
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

langfuse_handler = CallbackHandler()

llm = ChatOpenAI(model_name="gpt-4o")
prompt = ChatPromptTemplate.from_template("Tell me a joke about {topic}")
chain = prompt | llm

# Set trace attributes dynamically via metadata
response = chain.invoke(
    {"topic": "cats"},
    config={
        "callbacks": [langfuse_handler],
        "metadata": {
            "foo": "bar",
            "baz": "qux"
        }
    }
)
```

Option 2: Via enclosing span (for more control):

```python
from langfuse import get_client
from langfuse.langchain import CallbackHandler
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

langfuse = get_client()
langfuse_handler = CallbackHandler()

llm = ChatOpenAI(model_name="gpt-4o")
prompt = ChatPromptTemplate.from_template("Tell me a joke about {topic}")
chain = prompt | llm

# Set trace attributes dynamically via enclosing span
with langfuse.start_as_current_span(name="dynamic-langchain-trace") as span:
    span.update_trace(
        metadata={"foo": "bar", "baz": "qux"}
    )

    response = chain.invoke({"topic": "cats"}, config={"callbacks": [langfuse_handler]})

    span.update_trace(output={"response": response.content})
```

</Tab>
<Tab title="Langchain (JS/TS)">

When using the [CallbackHandler](/integrations/frameworks/langchain), you can pass `metadata` to the constructor:

```ts
const handler = new CallbackHandler({
  metadata: { key: "value" },
});
```

When using the integration with the JS SDK (see [interop docs](/integrations/frameworks/langchain#interoperability)), set `metadata` via `langfuse.trace()`:

```ts
import { CallbackHandler, Langfuse } from "langfuse-langchain";
const langfuse = new Langfuse();

const trace = langfuse.trace({
  metadata: { key: "value" },
});
const langfuseHandler = new CallbackHandler({ root: trace });

// Add Langfuse handler as callback to your langchain chain/agent
await chain.invoke({ input: "<user_input>" }, { callbacks: [langfuseHandler] });
```

</Tab>

<Tab title="Flowise">
You can set the `metadata` via the override configs, see the [Flowise Integration docs](/docs/flowise) for more details.

</Tab>

</Tabs>

## GitHub Discussions

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["feat-metadata"]} />

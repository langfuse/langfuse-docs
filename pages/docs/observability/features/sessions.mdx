---
title: Sessions (Chats, Threads, etc.)
description: Track LLM chat conversations or threads across multiple traces in a single session. Replay the entire interaction to debug or analyze the conversation.
sidebarTitle: Sessions
---

import { PropagationRestrictionsCallout } from "@/components/PropagationRestrictionsCallout";

# Sessions

Many interactions with LLM applications span multiple traces. `Sessions` in Langfuse are a way to group these traces together and see a simple **session replay** of the entire interaction. Get started by adding a `sessionId` when creating a trace.

```mermaid
graph LR
    A(Session) -->|1:n, sessionId| B(Trace)
```

Add a `sessionId` when creating/updating a trace. This can be any string that you use to identify the session. All traces with the same `sessionId` will be grouped together.

<LangTabs items={["Python SDK", "JS/TS SDK", "OpenAI (Python)", "Langchain (Python)", "Langchain (JS/TS)", "Flowise"]}>

<Tab title="Python SDK (v3)">
When using the `@observe()` decorator:

```python
from langfuse import observe, get_client

langfuse = get_client()

@observe()
def process_request():
    # Propagate session_id to all child spans
    with langfuse.propagate_attributes(session_id="your-session-id"):
        # All nested operations automatically inherit session_id
        result = process_chat_message()
        return result
```

When creating spans directly:

```python
from langfuse import get_client

langfuse = get_client()

with langfuse.start_as_current_span(
    name="process-chat-message"
) as root_span:
    # Propagate session_id to all child spans
    with langfuse.propagate_attributes(session_id="chat-session-123"):
        # All spans created here automatically have session_id
        with root_span.start_as_current_generation(
            name="generate-response",
            model="gpt-4o"
        ) as gen:
            # This generation automatically has session_id
            pass
```

</Tab>
<Tab title="JS/TS SDK">

When using the context manager:

```ts
import {
  startActiveObservation,
  propagateAttributes,
} from "@langfuse/tracing";

await startActiveObservation("context-manager", async (span) => {
  span.update({
    input: { query: "What is the capital of France?" },
  });

  // Propagate sessionId to all child spans
  await propagateAttributes({
    sessionId: "session-123",
  }, async () => {
    // All spans created here automatically have sessionId
    // ... your logic ...
  });
});
```

When using the `observe` wrapper:

```ts
import { observe, propagateAttributes } from "@langfuse/tracing";

const processChatMessage = observe(async (message: string) => {
  // Propagate sessionId to all child spans
  return await propagateAttributes(
    { sessionId: "session-123" },
    async () => {
      // All nested operations automatically inherit sessionId
      const result = await processMessage(message);
      return result;
    }
  );
}, { name: "process-chat-message" });

const result = await processChatMessage("Hello!");
```

See [JS/TS SDK docs](/docs/sdk/typescript/guide) for more details.

</Tab>
<Tab>

```python
from langfuse import get_client
from langfuse.openai import openai

langfuse = get_client()

with langfuse.start_as_current_span(name="openai-call"):
    # Propagate session_id to all spans including OpenAI generation
    with langfuse.propagate_attributes(session_id="your-session-id"):
        completion = openai.chat.completions.create(
            name="test-chat",
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a calculator."},
                {"role": "user", "content": "1 + 1 = "}
            ],
            temperature=0,
        )
```

</Tab>
<Tab>

```python
from langfuse import get_client
from langfuse.langchain import CallbackHandler

langfuse = get_client()
handler = CallbackHandler()

with langfuse.start_as_current_span(name="langchain-call"):
    # Propagate session_id to all spans
    with langfuse.propagate_attributes(session_id="your-session-id"):
        # Pass handler to the chain invocation
        chain.invoke(
            {"animal": "dog"},
            config={"callbacks": [handler]},
        )
```

</Tab>
<Tab title="Langchain (JS/TS)">

Use `propagateAttributes()` with the CallbackHandler:

```ts
import { startActiveObservation, propagateAttributes } from "@langfuse/tracing";
import { CallbackHandler } from "langfuse-langchain";

const langfuseHandler = new CallbackHandler();

await startActiveObservation("langchain-call", async () => {
  // Propagate sessionId to all spans
  await propagateAttributes({
    sessionId: "your-session-id",
  }, async () => {
    // Pass handler to the chain invocation
    await chain.invoke(
      { input: "<user_input>" },
      { callbacks: [langfuseHandler] }
    );
  });
});
```

</Tab>

<Tab title="Flowise">
The [Flowise Integration](/docs/flowise) automatically maps the Flowise chatId to the Langfuse sessionId. Flowise 1.4.10 or higher is required.

</Tab>

</LangTabs>

<PropagationRestrictionsCallout attributes={["sessionId"]} />

## Example

Try this feature using the public [example project](/docs/demo).

_Example session spanning multiple traces_

<Frame fullWidth>![Session view](/images/docs/session.png)</Frame>

## Other features

- Publish a session to share with others as a public link ([example](https://cloud.langfuse.com/project/clkpwwm0m000gmm094odg11gi/sessions/lf.docs.conversation.TL4KDlo))
- Bookmark a session to easily find it later
- Annotate sessions by adding `scores` via the Langfuse UI to record human-in-the-loop evaluations
- How to [evaluate sessions](/faq/all/evaluating-sessions-conversations) in Langfuse?

## GitHub Discussions

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["feat-sessions"]} />

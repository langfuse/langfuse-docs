---
description: Get started with LLM observability with Langfuse in minutes before diving into all platform features.
---

# Get Started with Tracing

This quickstart helps you to ingest your first trace in Langfuse.

<Steps>

## Get API keys

1.  [Create Langfuse account](https://cloud.langfuse.com/auth/sign-up) or [self-host Langfuse](/self-hosting).
2.  Create new API credentials in the project settings.

## Ingest your first trace

import { CopyAgentOnboardingPrompt } from "@/components/agentic-onboarding/CopyAgentOnboardingPrompt";
import DocsMcpServerInstallation from "@/components-mdx/docs-mcp-server-installation.mdx";
import GetStartedPythonSdk from "@/components-mdx/get-started/python-sdk.mdx";
import GetStartedJsSdk from "@/components-mdx/get-started/js-sdk.mdx";
import GetStartedOpenaiSdk from "@/components-mdx/get-started/openai-sdk.mdx";
import GetStartedLangchain from "@/components-mdx/get-started/langchain.mdx";
import GetStartedJsOpenaiSdk from "@/components-mdx/get-started/js-openai-sdk.mdx";
import GetStartedJsLangchain from "@/components-mdx/get-started/js-langchain.mdx";
import EnvPython from "@/components-mdx/env-python.mdx";

import { BookOpen, Code} from "lucide-react";

<Tabs items={["OpenAI SDK (Python)", "OpenAI SDK (JS/TS)", "LangChain (Python)", "LangChain (JS/TS)", "Python SDK", "JS/TS SDK", "âœ¨ Auto Install", "More integrations"]}>

<Tab>
{/* PYTHON - OPENAI*/}

Use the drop-in replacement for the OpenAI Python SDK to get full observability.

<GetStartedOpenaiSdk/>

<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/integrations/model-providers/openai-py"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/colab_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Notebook"
    href="https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/integration_openai_sdk.ipynb"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* JS/TS - OpenAI */}

Use the Langfuse wrapper function around the OpenAI JS/TS SDK for full observability.

<GetStartedJsOpenaiSdk/>

<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/integrations/model-providers/openai-js"
    arrow
  />
  <Card
    icon={<Code />}
    title="Notebook"
    href="/guides/cookbook/js_integration_openai"
    arrow
  />
</Cards>

</Tab>


<Tab>
{/* LANGCHAIN */}

Use the Langfuse CallbackHandler to get full observability of the LangChain Python SDK.

<GetStartedLangchain/>


<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/integrations/frameworks/langchain"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/colab_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Notebook"
    href="https://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/cookbook/integration_langchain.ipynb"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* LANGCHAIN (JS/TS) */}

Use the Langfuse CallbackHandler to get full observability of the LangChain JS/TS SDK.

<GetStartedJsLangchain/>

<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/integrations/frameworks/langchain"
    arrow
  />
  <Card
    icon={<Code />}
    title="Notebook"
    href="/guides/cookbook/js_integration_langchain"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* PYTHON SDK */}

Use the Langfuse Python SDK to wrap any LLM or Agent

```bash
pip install langfuse
```

<EnvPython />

There are three main ways of creating traces with the Python SDK:

<GetStartedPythonSdk/>

<Cards num={1}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/docs/sdk/python/sdk-v3"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* JS/TS SDK */}

Use the Langfuse JS/TS SDK to wrap any LLM or Agent

<GetStartedJsSdk/>

<Cards num={2}>
  <Card
    icon={<BookOpen />}
    title="Documentation"
    href="/docs/sdk/typescript/guide"
    arrow
  />
  <Card
    icon={<Code />}
    title="Notebook"
    href="/docs/sdk/typescript/example-notebook"
    arrow
  />
</Cards>

</Tab>

<Tab>
{/* AUTO INSTALL */}

Use the agent mode of your editor to integrate Langfuse into your existing codebase.

<Callout type="warning" emoji="ðŸ¤–">
This might or might not work very well (depending on your code base). Please share any feedback or issues on [GitHub](/issues).
</Callout>

**1. Install the Langfuse Docs MCP Server (optional)**

The agent will use the Langfuse `searchLangfuseDocs` tool ([docs](/docs/docs-mcp)) to find the correct documentation for the integration you are looking for. This is optional, alternatively the agent can use its native websearch capabilities.

<DocsMcpServerInstallation />

**2. Run Agent**

Copy and execute the following prompt in the agent mode of your editor:

<CopyAgentOnboardingPrompt />

</Tab>

<Tab>
{/* MORE INTEGRATIONS */}

Explore all integrations and frameworks that Langfuse supports.


<Cards num={2}>
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/vercel_ai_sdk_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Vercel AI SDK"
    href="/integrations/frameworks/vercel-ai-sdk"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/llamaindex_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Llamaindex"
    href="/integrations/frameworks/llamaindex"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/crewai_icon.svg" className="w-full h-full object-contain" />
      </div>
    }
    title="CrewAI"
    href="/integrations/frameworks/crewai"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/ollama_icon.svg" className="w-full h-full object-contain" />
      </div>
    }
    title="Ollama"
    href="/integrations/model-providers/ollama"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/litellm_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="LiteLLM"
    href="/integrations/gateways/litellm"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/autogen_icon.svg" className="w-full h-full object-contain" />
      </div>
    }
    title="AutoGen"
    href="/integrations/frameworks/autogen"
    arrow
  />
  <Card
    icon={
      <div className="w-6 h-6 dark:bg-white rounded-sm p-0.5 flex items-center justify-center">
        <img src="/images/integrations/google_adk_icon.png" className="w-full h-full object-contain" />
      </div>
    }
    title="Google ADK"
    href="/integrations/frameworks/google-adk"
    arrow
  />
  <Card
    title="All integrations"
    href="/integrations"
    arrow
  />
</Cards>


</Tab>

</Tabs>

## See your trace in Langfuse

After running your application, visit the Langfuse interface to view the trace you just created. _[(Example LangGraph trace in Langfuse)](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/7d5f970573b8214d1ca891251e42282c)_

<CloudflareVideo
  videoId="80d78d99dc1ca12276dbc5c43edb1583"
  aspectRatio={16 / 9}
  gifStyle
/>

</Steps>

## Next Steps {/* I actually think users would want tracing specific next steps "Add Sessions" etc.. */}

import NextSteps from "@/components-mdx/get-started/next-steps.mdx";

<NextSteps />

## Enable/disable tracing

All Langfuse SDKs and integrations are designed to be non-intrusive. You can add Langfuse tracing to your application while being able to enable it only in specific environments.

By default, the Langfuse Tracing is enabled if an API key is set. You can manually disable tracing via the `LANGFUSE_TRACING_ENABLED` environment variable. See the documentation for the specific SDK or integration for more details.


## FAQ

import { FaqPreview } from "@/components/faq/FaqPreview";

<FaqPreview tags={["setup"]} />

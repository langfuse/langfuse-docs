---
title: Advanced features of the Langfuse SDKs
description: Configure masking, logging, sampling, multi-project routing, evaluations, and environment-specific behaviors for Python and JS/TS.
category: SDKs
---

# Advanced features

Use these patterns to harden your Langfuse instrumentation, protect sensitive data, and adapt the SDKs to complex environments. Each section shows the equivalent Python and JS/TS setup side-by-side.

## Mask sensitive data

Route spans to different Langfuse projects (multi-tenant, staging vs. prod, etc.) by registering separate exporters. Note the limitations below.

Both SDKs expose helpers to attach scores to observations or entire traces, plus dataset utilities for repeatable experiments.

<Tabs items={["Python", "TypeScript"]}>
<Tab title="Python">
Provide a `mask` function when instantiating the client to scrub inputs, outputs, and metadata before they leave your infrastructure.

```python
from langfuse import Langfuse
import re

def pii_masker(data: any, **kwargs) -> any:
    if isinstance(data, str):
        return re.sub(r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+", "[EMAIL_REDACTED]", data)
    elif isinstance(data, dict):
        return {k: pii_masker(data=v) for k, v in data.items()}
    elif isinstance(data, list):
        return [pii_masker(data=item) for item in data]
    return data

langfuse = Langfuse(mask=pii_masker)
```
</Tab>
<Tab title="TypeScript">
Pass a `mask` callback to the `LangfuseSpanProcessor`. The callback receives stringified JSON of the attribute and should return the masked payload.

```ts filename="instrumentation.ts" /mask: /
import { NodeSDK } from "@opentelemetry/sdk-node";
import { LangfuseSpanProcessor } from "@langfuse/otel";

const spanProcessor = new LangfuseSpanProcessor({
  mask: ({ data }) =>
    data.replace(/\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b/g, "***MASKED_CREDIT_CARD***"),
});

const sdk = new NodeSDK({ spanProcessors: [spanProcessor] });

sdk.start();
```
</Tab>
</Tabs>

## Logging & debugging

<Tabs items={["Python", "TypeScript"]}>
<Tab title="Python">
The Langfuse SDK uses Python's standard `logging` module. The main logger is named `"langfuse"`. Enable detailed debug logging by either passing `debug=True` when instantiating `Langfuse`, setting the `LANGFUSE_DEBUG="True"` environment variable, or configuring the logger manually:

```python
import logging

langfuse_logger = logging.getLogger("langfuse")
langfuse_logger.setLevel(logging.DEBUG)
```

The default log level for `"langfuse"` is `logging.WARNING`.
</Tab>
<Tab title="TypeScript">
Configure the global SDK logger (or set `LANGFUSE_LOG_LEVEL`) to control verbosity. Available log levels are `DEBUG`, `INFO`, `WARN`, and `ERROR`.

```ts /configureGlobalLogger/
import { configureGlobalLogger, LogLevel } from "@langfuse/core";

configureGlobalLogger({ level: LogLevel.DEBUG });
```

```bash
export LANGFUSE_LOG_LEVEL="DEBUG"
```
</Tab>
</Tabs>

## Sampling

<Tabs items={["Python", "TypeScript"]}>
<Tab title="Python">
Sample traces directly on the client via the `sample_rate` constructor argument or the `LANGFUSE_SAMPLE_RATE` environment variable. The value must be between `0.0` (drop everything) and `1.0` (send all traces). If a trace is not sampled, none of its observations or scores are exported.

```python
from langfuse import Langfuse

langfuse = Langfuse(sample_rate=0.2)
```
</Tab>
<Tab title="TypeScript">
Langfuse respects OpenTelemetry's sampling decisions. Configure a sampler on your OTEL `NodeSDK` to control which traces reach Langfuse and reduce noise/costs in high-volume workloads.

```ts filename="instrumentation.ts" /TraceIdRatioBasedSampler/
import { NodeSDK } from "@opentelemetry/sdk-node";
import { LangfuseSpanProcessor } from "@langfuse/otel";
import { TraceIdRatioBasedSampler } from "@opentelemetry/sdk-trace-base";

const sdk = new NodeSDK({
  sampler: new TraceIdRatioBasedSampler(0.2),
  spanProcessors: [new LangfuseSpanProcessor()],
});

sdk.start();
```
</Tab>
</Tabs>

## Filter exported spans [#filtering-spans]

<Tabs items={["Python", "TypeScript"]}>
<Tab title="Python">
Exclude spans from specific instrumentation scopes.

```python
from langfuse import Langfuse

langfuse = Langfuse(blocked_instrumentation_scopes=["sqlalchemy", "psycopg"])
```

**How it works:** every OpenTelemetry span contains an instrumentation scope (visible in Langfuse under `metadata.scope.name`). Langfuse evaluates the scope against `blocked_instrumentation_scopes` when deciding whether to export. Be careful when filtering parents‚Äîchild spans may become orphaned.

<Callout type="warning">
Filtering parent spans may result in orphaned children in Langfuse.
</Callout>
</Tab>
<Tab title="TypeScript">
Provide a `shouldExportSpan` predicate.

```ts filename="instrumentation.ts" /shouldExportSpan/
import { NodeSDK } from "@opentelemetry/sdk-node";
import { LangfuseSpanProcessor, ShouldExportSpan } from "@langfuse/otel";

const shouldExportSpan: ShouldExportSpan = ({ otelSpan }) =>
  otelSpan.instrumentationScope.name !== "express";

const sdk = new NodeSDK({
  spanProcessors: [new LangfuseSpanProcessor({ shouldExportSpan })],
});

sdk.start();
```

Use allowlists when you only want to forward specific instrumentation scopes (e.g., Langfuse SDK + AI SDK).

```ts
import { ShouldExportSpan } from "@langfuse/otel";

const shouldExportSpan: ShouldExportSpan = ({ otelSpan }) =>
  ["langfuse-sdk", "ai"].includes(otelSpan.instrumentationScope.name);
```
</Tab>
</Tabs>

## Tracer provider isolation

<Tabs items={["Python", "TypeScript"]}>
<Tab title="Python">
Create a dedicated OTEL `TracerProvider` for Langfuse spans when you need isolation from other observability backends (Datadog, Jaeger, Zipkin, etc.).

**Benefits**

- Prevent Langfuse spans from reaching other exporters.
- Prevent third-party spans from appearing inside Langfuse.
- Configure sampling/export policies independently.

```python
from opentelemetry.sdk.trace import TracerProvider
from langfuse import Langfuse

langfuse_tracer_provider = TracerProvider()
langfuse = Langfuse(tracer_provider=langfuse_tracer_provider)
langfuse.start_span(name="isolated").end()
```

<Callout type="warning">
TracerProviders still share the same context, so mixing providers may create orphaned spans.
</Callout>
</Tab>
<Tab title="TypeScript">
Isolate Langfuse spans with a custom provider and avoid sending them to other exporters.

```ts /setLangfuseTracerProvider/
import { NodeTracerProvider } from "@opentelemetry/sdk-trace-node";
import { setLangfuseTracerProvider } from "@langfuse/tracing";
import { LangfuseSpanProcessor } from "@langfuse/otel";

const langfuseTracerProvider = new NodeTracerProvider({
  spanProcessors: [new LangfuseSpanProcessor()],
});

setLangfuseTracerProvider(langfuseTracerProvider);
```

<Callout type="warning">
As with Python, isolating tracer providers can break parent/child relationships when contexts overlap.
</Callout>
</Tab>
</Tabs>

## Multi-project setups [#multi-project-setup-experimental]

<Tabs items={["Python", "TypeScript"]}>
<Tab title="Python">
Instantiate dedicated clients per project and pass the `langfuse_public_key` context where needed.

```python
from langfuse import Langfuse, observe

project_a = Langfuse(public_key="pk-lf-project-a-...", secret_key="sk-lf-project-a-...")
project_b = Langfuse(public_key="pk-lf-project-b-...", secret_key="sk-lf-project-b-...")

@observe
def process_data_for_project_a(data, langfuse_public_key="pk-lf-project-a-..."):
    return {"processed": data}

@observe
def process_data_for_project_b(data, langfuse_public_key="pk-lf-project-b-..."):
    return {"processed": data}
```

You can also route OpenAI or LangChain integrations by passing `langfuse_public_key` on each call.

<Callout type="warning">
Multi-project setups are experimental. Third-party OTEL spans (HTTP clients, databases, etc.) lack the Langfuse public key attribute and will therefore be exported to **all** projects.
</Callout>

**How it works**

1. Langfuse spans carry a public-key attribute.
2. You register one exporter per project.
3. Each exporter filters spans by that attribute before sending them.

**Important considerations**

- Always provide the correct `langfuse_public_key` to the top-most observed function or integration call.
- Missing the key routes traces to the default project or drops them.
- Third-party spans without the attribute go to every project.
</Tab>
<Tab title="TypeScript">
Register multiple span processors‚Äîone per Langfuse project‚Äîand optionally set filters per processor.

```ts filename="instrumentation.ts"
import { NodeSDK } from "@opentelemetry/sdk-node";
import { LangfuseSpanProcessor } from "@langfuse/otel";

const sdk = new NodeSDK({
  spanProcessors: [
    new LangfuseSpanProcessor({
      publicKey: "pk-lf-public-key-project-1",
      secretKey: "sk-lf-secret-key-project-1",
    }),
    new LangfuseSpanProcessor({
      publicKey: "pk-lf-public-key-project-2",
      secretKey: "sk-lf-secret-key-project-2",
    }),
  ],
});

sdk.start();
```
</Tab>
</Tabs>

## Environment-specific considerations

<Tabs items={["Python", "TypeScript"]}>
<Tab title="Python">
### Thread pools and multiprocessing

Use the OpenTelemetry threading instrumentor so context flows across worker threads.

```python
from opentelemetry.instrumentation.threading import ThreadingInstrumentor

ThreadingInstrumentor().instrument()
```

For multiprocessing, follow the [OpenTelemetry guidance](https://github.com/open-telemetry/opentelemetry-python/issues/2765#issuecomment-1158402076). If you use Pydantic Logfire, enable `distributed_tracing=True`.

### Distributed tracing

Prefer native OTEL propagation when linking services. The `trace_context` argument should be a last resort because it forces root-span semantics server-side.

### Time to first token (TTFT)

```python
from langfuse import get_client
import datetime, time

langfuse = get_client()

with langfuse.start_as_current_observation(as_type="generation", name="TTFT-Generation") as generation:
    time.sleep(3)
    generation.update(
        completion_start_time=datetime.datetime.now(),
        output="some response",
    )

langfuse.flush()
```

### Self-signed TLS certificates

```bash filename=".env"
OTEL_EXPORTER_OTLP_TRACES_CERTIFICATE="/path/to/my-selfsigned-cert.crt"
```

```python
import os, httpx
from langfuse import Langfuse

httpx_client = httpx.Client(verify=os.environ["OTEL_EXPORTER_OTLP_TRACES_CERTIFICATE"])
langfuse = Langfuse(httpx_client=httpx_client)
```

<Callout type="warning">
Understand the security implications before trusting self-signed certificates.
</Callout>
</Tab>
<Tab title="TypeScript">
### Serverless environments

```ts filename="instrumentation.ts" /langfuseSpanProcessor/
import { NodeSDK } from "@opentelemetry/sdk-node";
import { LangfuseSpanProcessor } from "@langfuse/otel";

export const langfuseSpanProcessor = new LangfuseSpanProcessor({
  exportMode: "immediate",
});

const sdk = new NodeSDK({ spanProcessors: [langfuseSpanProcessor] });

sdk.start();
```

```ts filename="handler.ts" /forceFlush/
import { langfuseSpanProcessor } from "./instrumentation";

export async function handler(event, context) {
  // ... logic ...
  await langfuseSpanProcessor.forceFlush();
}
```

Use `after` in Vercel Cloud Functions to schedule the flush after the response has been sent.

### Custom scores from the browser [#custom-scores-from-browser]

```ts
import { LangfuseWeb } from "langfuse";

export function UserFeedbackComponent(props: { traceId: string }) {
  const langfuseWeb = new LangfuseWeb({
    publicKey: env.NEXT_PUBLIC_LANGFUSE_PUBLIC_KEY,
    baseUrl: "https://cloud.langfuse.com",
  });

  const handleUserFeedback = async (value: number) =>
    await langfuseWeb.score({ traceId: props.traceId, name: "user_feedback", value });

  return (
    <div>
      <button onClick={() => handleUserFeedback(1)}>üëç</button>
      <button onClick={() => handleUserFeedback(0)}>üëé</button>
    </div>
  );
}
```

<Callout type="warning">
Never expose your Langfuse secret key in browser code. Use only the public key with `LangfuseWeb`.
</Callout>

<Callout type="info">
When sending client-side scores, make sure the frontend has access to the relevant `traceId` (and optional `observationId`). Expose those IDs in your backend response or use deterministic IDs that exist in both environments.
</Callout>

Learn more in the [custom scores documentation](/docs/evaluation/evaluation-methods/custom-scores).

### Langfuse + Sentry

```ts filename="instrumentation.ts"
import * as Sentry from "@sentry/node";
import { LangfuseSpanProcessor } from "@langfuse/otel";
import { NodeTracerProvider } from "@opentelemetry/sdk-trace-node";
import {
  SentryPropagator,
  SentrySampler,
  SentrySpanProcessor,
} from "@sentry/opentelemetry";

const sentryClient = Sentry.init({
  dsn: "<your dsn>",
  skipOpenTelemetrySetup: true,
  tracesSampleRate: 1,
});

const provider = new NodeTracerProvider({
  sampler: sentryClient ? new SentrySampler(sentryClient) : undefined,
  spanProcessors: [new LangfuseSpanProcessor(), new SentrySpanProcessor()],
});

provider.register({
  propagator: new SentryPropagator(),
  contextManager: new Sentry.SentryContextManager(),
});
```

<Callout type="info">
If you only use Sentry for error monitoring, omit `tracesSampleRate` and the `SentrySpanProcessor` so its sampling rules don't affect Langfuse traces.
</Callout>
</Tab>
</Tabs>

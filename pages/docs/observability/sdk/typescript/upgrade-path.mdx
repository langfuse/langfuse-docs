---
title: TypeScript SDK - Upgrade Path
description: Upgrade path from v3 to v4 for the TypeScript SDK.
---

# TypeScript SDK - Upgrade Path v3 to v4

## Tracing

The v4 SDK tracing is a major rewrite based on OpenTelemetry and introduces several breaking changes.

1.  **OTEL-based Architecture**: The SDK is now built on top of OpenTelemetry. An OpenTelemetry Setup is required now and done by registering the `LangfuseSpanProcessor` with an OpenTelemetry `NodeSDK`.
2.  **New Tracing Functions**: The `langfuse.trace()`, `langfuse.span()`, and `langfuse.generation()` methods have been replaced by `startSpan`, `startGeneration`, `startActiveSpan`, etc., from the `@langfuse/tracing` package.
3.  **Separation of Concerns**:
      * The **`@langfuse/tracing`** and **`@langfuse/otel`** packages are for tracing.
      * The **`@langfuse/client`** package and the `LangfuseClient` class are now only for non-tracing features like scoring, prompt management, and datasets.

See the [SDK v4 docs](/docs/observability/sdk/typescript/overview) for details on each.

## Prompt Management

- **Import**: The import of the Langfuse client is now:

```typescript
import { LangfuseClient } from "@langfuse/client";
```

- **Usage**: The usage of the Langfuse client is now:

```typescript
const langfuse = new LangfuseClient();

const prompt = await langfuse.prompt.get("my-prompt");

const compiledPrompt = prompt.compile({ topic: "developers" });

const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [{ role: "user", content: compiledPrompt }],
});
```

- `version` is now an optional property of the second argument of `langfuse.prompt.get()`.

```typescript
const prompt = await langfuse.prompt.get("my-prompt", { version: "1.0" });
```


## OpenAI integration

- **Import**: The import of the OpenAI integration is now:

```typescript
import { observeOpenAI } from "@langfuse/openai";
```

- You can set the `environment` and `release` now via the `LANGFUSE_TRACING_ENVIRONMENT` and `LANGFUSE_TRACING_RELEASE` environment variables.

## Vercel AI SDK

Please the v4 `LangfuseSpanProcessor` in your OpenTelemetry setup instead of the v3 `LangfuseExporter`.

If you are using Next.js, please use a manual OpenTelemetry setup via the `NodeTracerProvider` than via `registerOTel` from `@vercel/otel`. This is because [the `@vercel/otel` package does not yet support the OpenTelemetry JS SDK v2](https://github.com/vercel/otel/issues/154) on which the `@langfuse/tracing` and `@langfuse/otel` packages are based.

If you are still missing traces, please see the documentation on [serverless environments](/docs/observability/sdk/typescript/advanced-usage#serverless-environments)

If you would like to filter out the Next JS level spans from being exported to Langfuse, [see here](/docs/observability/typescript/advanced-usage#filtering-spans).


## Langchain integration

- **Import**: The import of the Langchain integration is now:

```typescript
import { CallbackHandler } from "@langfuse/langchain";
```

- You can set the `environment` and `release` now via the `LANGFUSE_TRACING_ENVIRONMENT` and `LANGFUSE_TRACING_RELEASE` environment variables.

## `langfuseClient.getTraceUrl`
- method is now asynchronous and returns a promise

```typescript
const traceUrl = await langfuseClient.getTraceUrl(traceId);
```

## Scoring

- **Import**: The import of the Langfuse client is now:

```typescript
import { LangfuseClient } from "@langfuse/client";
```

- **Usage**: The usage of the Langfuse client is now:

```typescript
const langfuse = new LangfuseClient();

await langfuse.score.create({
  traceId: "trace_id_here",
  name: "accuracy",
  value: 0.9,
});
```

See [custom scores documentation](/docs/evaluation/evaluation-methods/custom-scores) for new scoring methods.

## Datasets

See [datasets section above](#datasets) for new dataset methods.


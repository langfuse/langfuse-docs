---
title: Open Source LLM Analytics
description: Improve your LLM application with open source product analytics measuring latency, cost, and quality across various dimensions.
---

# LLM Analytics

Langfuse analytics derives actionable insights from [production traces](/docs/tracing).

<CloudflareVideo
  videoId="8d3f304202f7af9c7afbaa57306082ed"
  gifStyle
  aspectRatio={1908 / 1080}
/>

â†’ Not using Langfuse yet? Explore the dashboard in our [interactive demo](/docs/demo).

## Metrics

- **Quality** is measured through user feedback, model-based scoring, human-in-the-loop scored samples or custom scores via SDKs/API (see [scores](/docs/scores/overview)). Quality is assessed over time as well as across prompt versions, LLMs and users.
- **Cost and Latency** are accurately measured and broken down by user, session, geography, feature, model and prompt version.
- **Volume** based on the ingested traces and tokens used.

## Dimensions

Analytics is incrementally adoptable based on the data you send to Langfuse. The following dimensions are available:

- Trace name: differentiate between different use cases, features, etc. by adding a `name` field to your traces.
- User: track usage and cost by user. Just add a `userId` to your traces ([docs](/docs/tracing-features/users)).
- Tags: filter different use cases, features, etc. by adding [tags](/docs/tracing-features/tags) to your traces.
- Release and version numbers: track how changes to the LLM application affected your metrics.

## Feedback

We are continuously adding new charts to the dashboard. If you have any feedback or requests, please create a [GitHub Issue](/issue) or share your idea with the community on [Discord](/discord).

## GitHub Discussions

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["feat-dashboard"]} />

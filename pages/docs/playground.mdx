---
description: Test, iterate, and compare different prompts and models within the LLM Playground.
---

# LLM Playground

<AvailabilityBanner
  availability={{
    hobby: "full",
    pro: "full",
    team: "full",
    selfHosted: "pro",
  }}
/>

Test and iterate on your prompts directly in the Langfuse Prompt Playground. Tweak the prompt and the model parameters to see how different models responds to these changes inputs. This allows you to quickly iterate on your prompts and optimize them for the best results in your LLM app without having to switch between tools or use any code.

<CloudflareVideo
  videoId="3cfab665df39518f15fc18813cf82e3f"
  aspectRatio={16 / 10.47}
  className="max-w-3xl"
  title="LLM Playground"
/>

**Core features**

- `{{variables}}` in prompts
- OpenAI and Anthropic models
- Compare model parameters
- Linked to [prompt management](/docs/prompts/get-started)

We'll be adding more features and models in the future. If you have any feedback or feature requests, please let us know!

## Jump from prompt management to the playground

You can either start from scratch or jump into the playground from an existing prompt in [Langfuse Prompt Management](/docs/prompts/get-started).

<CloudflareVideo
  videoId="44bbf8b87ae2dfa815d0bf0769eea542"
  gifStyle
  aspectRatio={16 / 9.68}
  className="max-w-3xl"
/>

## Supported Models

Currently the playground supports the following models by default. You may configure additional custom model names when adding your LLM API Key in the Langfuse project settings, e.g. when using a custom model or proxy.

export function ModelList() {
  const openAIModels = [
    "gpt-4o",
    "gpt-4o-2024-08-06",
    "gpt-4o-2024-05-13",
    "gpt-4o-mini",
    "gpt-4o-mini-2024-07-18",
    "o3-mini",
    "o3-mini-2025-01-31",
    "o1-preview",
    "o1-preview-2024-09-12",
    "o1-mini",
    "o1-mini-2024-09-12",
    "gpt-4-turbo-preview",
    "gpt-4-1106-preview",
    "gpt-4-0613",
    "gpt-4-0125-preview",
    "gpt-4",
    "gpt-3.5-turbo-16k-0613",
    "gpt-3.5-turbo-16k",
    "gpt-3.5-turbo-1106",
    "gpt-3.5-turbo-0613",
    "gpt-3.5-turbo-0301",
    "gpt-3.5-turbo-0125",
    "gpt-3.5-turbo",
  ];
  const anthropicModels = [
    "claude-3-5-sonnet-20241022",
    "claude-3-5-sonnet-20240620",
    "claude-3-opus-20240229",
    "claude-3-sonnet-20240229",
    "claude-3-5-haiku-20241022",
    "claude-3-haiku-20240307",
    "claude-2.1",
    "claude-2.0",
    "claude-instant-1.2",
  ];
  const vertexAIModels = [
    "gemini-2.0-flash-exp",
    "gemini-1.5-pro",
    "gemini-1.5-flash",
    "gemini-1.0-pro",
  ];
  return (
    <div>
      <ul>
        <li>
          <strong>OpenAI / Azure OpenAI:</strong> {openAIModels.join(", ")}
        </li>
        <li>
          <strong>Anthropic:</strong> {anthropicModels.join(", ")}
        </li>
        <li>
          <strong>Google Vertex AI:</strong> {vertexAIModels.join(", ")}. You
          may also add additional model names supported by Google Vertex AI
          platform and enabled in your GCP account through the `Custom model
          names` section in the LLM API Key creation form.
        </li>
        <li>
          <strong>Amazon Bedrock:</strong> All Amazon Bedrock models are supported.
        </li>
        <li>
          <strong>Any model that supports the OpenAI API:</strong> The Playground and LLM-as-a-Judge evaluations can be used by any framework that supports the OpenAI API schema such as Groq, OpenRouter, LiteLLM, Hugging Face, and more. Just replace the API Base URL with the appropriate endpoint for the model you want to use and add the providers API keys for authentication.
        </li>
      </ul>
    </div>
  );
}

<ModelList />


## GitHub Discussions

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["feat-playground"]} />

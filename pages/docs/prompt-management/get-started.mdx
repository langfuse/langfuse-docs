---
title: Get Started with Open Source Prompt Management
sidebarTitle: Get Started
description: Get started with Langfuse Prompt Management.
---

# Get Started with Prompt Management

This quickstart helps you to create your first prompt and use it in your application.

<Steps>

### Get API keys

1.  [Create Langfuse account](https://cloud.langfuse.com/auth/sign-up) or [self-host Langfuse](/self-hosting).
2.  Create new API credentials in the project settings.

### Create a prompt [#create-update-prompt]

import PromptCreate from "@/components-mdx/prompt-create.mdx";

<PromptCreate />

### Use prompt [#use-prompt]

At runtime, you can fetch the latest production version from Langfuse. Learn more about control (versions/labels) [here](/docs/prompt-management/features/prompt-version-control).

<Tabs items={["Python SDK", "JS/TS SDK", "Langchain (Python)", "Langchain (JS)"]}>
<Tab>

```python
from langfuse import get_client

# Initialize Langfuse client
langfuse = get_client()
```

**Text prompt**

```python
# Get current `production` version of a text prompt
prompt = langfuse.get_prompt("movie-critic")

# Insert variables into prompt template
compiled_prompt = prompt.compile(criticlevel="expert", movie="Dune 2")
# -> "As an expert movie critic, do you like Dune 2?"
```

**Chat prompt**

```python
# Get current `production` version of a chat prompt
chat_prompt = langfuse.get_prompt("movie-critic-chat", type="chat") # type arg infers the prompt type (default is 'text')

# Insert variables into chat prompt template
compiled_chat_prompt = chat_prompt.compile(criticlevel="expert", movie="Dune 2")
# -> [{"role": "system", "content": "You are an expert movie critic"}, {"role": "user", "content": "Do you like Dune 2?"}]
```

**Optional parameters**

```python
# Get specific version
prompt = langfuse.get_prompt("movie-critic", version=1)

# Get specific label
prompt = langfuse.get_prompt("movie-critic", label="staging")

# Get latest prompt version. The 'latest' label is automatically maintained by Langfuse.
prompt = langfuse.get_prompt("movie-critic", label="latest")
```

**Attributes**

```python
# Raw prompt including {{variables}}. For chat prompts, this is a list of chat messages.
prompt.prompt

# Config object
prompt.config
```

</Tab>

<Tab>

```ts
import { LangfuseClient } from "@langfuse/client";

// Iniitialize the Langfuse client
const langfuse = new LangfuseClient();
```

**Text prompt**

```ts
// Get current `production` version
const prompt = await langfuse.prompt.get("movie-critic");

// Insert variables into prompt template
const compiledPrompt = prompt.compile({
  criticlevel: "expert",
  movie: "Dune 2",
});
// -> "As an expert movie critic, do you like Dune 2?"
```

**Chat prompt**

```ts
// Get current `production` version of a chat prompt
const chatPrompt = await langfuse.prompt.get("movie-critic-chat", {
  type: "chat",
}); // type option infers the prompt type (default is 'text')

// Insert variables into chat prompt template
const compiledChatPrompt = chatPrompt.compile({
  criticlevel: "expert",
  movie: "Dune 2",
});
// -> [{"role": "system", "content": "You are an expert movie critic"}, {"role": "user", "content": "Do you like Dune 2?"}]
```

**Optional parameters**

```ts
// Get specific version of a prompt (here version 1)
const prompt = await langfuse.prompt.get("movie-critic", {
  version: 1
});

// Get specific label
const prompt = await langfuse.prompt.get("movie-critic", {
  label: "staging",
});

// Get latest prompt version. The 'latest' label is automatically maintained by Langfuse.
const prompt = await langfuse.prompt.get("movie-critic", {
  label: "latest",
});
```

**Attributes**

```ts
// Raw prompt including {{variables}}. For chat prompts, this is a list of chat messages.
prompt.prompt;

// Config object
prompt.config;
```

</Tab>

<Tab>

As Langfuse and Langchain process input variables of prompt templates differently (`{}` instead of `{{}}`), we provide the `prompt.get_langchain_prompt()` method to transform the Langfuse prompt into a string that can be used with Langchain's PromptTemplate. You can pass optional keyword arguments to `prompt.get_langchain_prompt(**kwargs)` in order to precompile some variables and handle the others with Langchain's PromptTemplate.

```python
from langfuse import Langfuse
from langchain_core.prompts import ChatPromptTemplate

# Initialize Langfuse client
langfuse = Langfuse()
```

**Text prompt**

```python
# Get current `production` version
langfuse_prompt = langfuse.get_prompt("movie-critic")

# Example using ChatPromptTemplate
langchain_prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())

# Example using ChatPromptTemplate with pre-compiled variables.
langchain_prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt(strictness='tough'))
```

**Chat prompt**

```python
# Get current `production` version of a chat prompt
langfuse_prompt = langfuse.get_prompt("movie-critic-chat", type="chat")

# Create a Langchain ChatPromptTemplate from the Langfuse prompt chat messages
langchain_prompt = ChatPromptTemplate.from_messages(langfuse_prompt.get_langchain_prompt())
```

**Optional parameters**

```python
# Get specific version
prompt = langfuse.get_prompt("movie-critic", version=1)

# Get specific label
prompt = langfuse.get_prompt("movie-critic", label="staging")

# Get latest prompt version. The 'latest' label is automatically maintained by Langfuse.
prompt = langfuse.get_prompt("movie-critic", label="latest")
```

**Attributes**

```python
# Raw prompt including {{variables}}. For chat prompts, this is a list of chat messages.
prompt.prompt

# Config object
prompt.config
```

</Tab>

<Tab>

As Langfuse and Langchain process input variables of prompt templates differently (`{}` instead of `{{}}`), we provide the `prompt.getLangchainPrompt()` method to transform the Langfuse prompt into a string that can be used with Langchain's PromptTemplate.

```ts
import { LangfuseClient } from "@langfuse/client";
import { ChatPromptTemplate } from "@langchain/core/prompts";

const langfuse = new LangfuseClient();
```

**Text prompt**

```ts
// Get current `production` version
const langfusePrompt = await langfuse.prompt.get("movie-critic");

// Example using ChatPromptTemplate
const promptTemplate = PromptTemplate.fromTemplate(
  langfusePrompt.getLangchainPrompt()
);
```

**Chat prompt**

```ts
// Get current `production` version of a chat prompt
const langfusePrompt = await langfuse.prompt.get(
  "movie-critic-chat",
  { type: "chat" }
);

// Example using ChatPromptTemplate
const promptTemplate = ChatPromptTemplate.fromMessages(
  langfusePrompt.getLangchainPrompt().map((msg) => [msg.role, msg.content])
);
```

**Optional parameters**

```ts
// Get specific version of a prompt (here version 1)
const prompt = await langfuse.prompt.get("movie-critic", {
  version: 1
});

// Get specific label
const prompt = await langfuse.prompt.get("movie-critic", {
  label: "staging",
});

// Get latest prompt version. The 'latest' label is automatically maintained by Langfuse.
const prompt = await langfuse.prompt.get("movie-critic", {
  label: "latest",
});
```

**Attributes**

```ts
// Raw prompt including {{variables}}. For chat prompts, this is a list of chat messages.
prompt.prompt;

// Config object
prompt.config;
```

</Tab>

</Tabs>

### Link with Langfuse Tracing (optional)

You can link the prompt to the LLM `generation` span that used the prompt. This linkage enables tracking of metrics by prompt version and name directly in the Langfuse UI and see which prompt performed best.

import PromptLinking from "@/components-mdx/prompt-linking.mdx";

<PromptLinking />

<Callout type="info">
  If a [fallback
  prompt](/docs/prompt-management/features/guaranteed-availability#fallback) is
  used, no link will be created.
</Callout>

</Steps>

## End-to-end examples

The following example notebooks include end-to-end examples of prompt management:

import { Terminal, FileCode } from "lucide-react";

<Cards num={2}>
  <Card
    title="Example OpenAI Functions"
    href="/guides/cookbook/prompt_management_openai_functions"
    icon={<FileCode />}
  />
  <Card
    title="Example Langchain (Python)"
    href="/guides/cookbook/prompt_management_langchain"
    icon={<FileCode />}
  />
  <Card
    title="Example Langchain (JS/TS)"
    href="/guides/cookbook/js_prompt_management_langchain"
    icon={<FileCode />}
  />
</Cards>

We also used Prompt Management for our Docs Q&A Chatbot and traced it with Langfuse. You can get view-only access to the project by signing up to the [public demo](/docs/demo).

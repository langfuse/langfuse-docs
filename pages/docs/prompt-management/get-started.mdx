---
title: Get Started with Open Source Prompt Management
sidebarTitle: Get Started
description: Get started with Langfuse Prompt Management.
---

# Get Started with Langfuse Prompt Management

This quickstart helps you to create your first prompt and use it in your application.

<Steps>

## Get API keys

1.  [Create Langfuse account](https://cloud.langfuse.com/auth/sign-up) or [self-host Langfuse](/self-hosting).
2.  Create new API credentials in the project settings.

## Create a prompt [#create-update-prompt]

import PromptCreate from "@/components-mdx/prompt-create.mdx";

<PromptCreate />

### Use prompt [#use-prompt]

At runtime, you can fetch the latest production version from Langfuse. Learn more about versions and labels [here](/docs/prompt-management/data-model).

<Tabs items={["Python", "JS/TS", "Langchain (Python)", "Langchain (JS)"]}>
<Tab>

```python
from langfuse import get_client

# Initialize Langfuse client
langfuse = get_client()
```

**Text prompt**

```python
# Get current `production` version of a text prompt
prompt = langfuse.get_prompt("movie-critic")

# Insert variables into prompt template
compiled_prompt = prompt.compile(criticlevel="expert", movie="Dune 2")
# -> "As an expert movie critic, do you like Dune 2?"
```

**Chat prompt**

```python
# Get current `production` version of a chat prompt
chat_prompt = langfuse.get_prompt("movie-critic-chat", type="chat") # type arg infers the prompt type (default is 'text')

# Insert variables into chat prompt template
compiled_chat_prompt = chat_prompt.compile(criticlevel="expert", movie="Dune 2")
# -> [{"role": "system", "content": "You are an expert movie critic"}, {"role": "user", "content": "Do you like Dune 2?"}]
```

**Optional parameters**

```python
# Get specific version
prompt = langfuse.get_prompt("movie-critic", version=1)

# Get specific label
prompt = langfuse.get_prompt("movie-critic", label="staging")

# Get latest prompt version. The 'latest' label is automatically maintained by Langfuse.
prompt = langfuse.get_prompt("movie-critic", label="latest")
```

**Attributes**

```python
# Raw prompt including {{variables}}. For chat prompts, this is a list of chat messages.
prompt.prompt

# Config object
prompt.config
```

</Tab>

<Tab>

```ts
import { Langfuse } from "langfuse";

// Iniitialize the Langfuse client
const langfuse = new Langfuse();
```

**Text prompt**

```ts
// Get current `production` version
const prompt = await langfuse.getPrompt("movie-critic");

// Insert variables into prompt template
const compiledPrompt = prompt.compile({
  criticlevel: "expert",
  movie: "Dune 2",
});
// -> "As an expert movie critic, do you like Dune 2?"
```

**Chat prompt**

```ts
// Get current `production` version of a chat prompt
const chatPrompt = await langfuse.getPrompt("movie-critic-chat", undefined, {
  type: "chat",
}); // type option infers the prompt type (default is 'text')

// Insert variables into chat prompt template
const compiledChatPrompt = chatPrompt.compile({
  criticlevel: "expert",
  movie: "Dune 2",
});
// -> [{"role": "system", "content": "You are an expert movie critic"}, {"role": "user", "content": "Do you like Dune 2?"}]
```

**Optional parameters**

```ts
// Get specific version of a prompt (here version 1)
const prompt = await langfuse.getPrompt("movie-critic", 1);

// Get specific label
const prompt = await langfuse.getPrompt("movie-critic", undefined, {
  label: "staging",
});

// Get latest prompt version. The 'latest' label is automatically maintained by Langfuse.
const prompt = await langfuse.getPrompt("movie-critic", undefined, {
  label: "latest",
});
```

**Attributes**

```ts
// Raw prompt including {{variables}}. For chat prompts, this is a list of chat messages.
prompt.prompt;

// Config object
prompt.config;
```

</Tab>

<Tab>

As Langfuse and Langchain process input variables of prompt templates differently (`{}` instead of `{{}}`), we provide the `prompt.get_langchain_prompt()` method to transform the Langfuse prompt into a string that can be used with Langchain's PromptTemplate. You can pass optional keyword arguments to `prompt.get_langchain_prompt(**kwargs)` in order to precompile some variables and handle the others with Langchain's PromptTemplate.

```python
from langfuse import Langfuse
from langchain_core.prompts import ChatPromptTemplate

# Initialize Langfuse client
langfuse = Langfuse()
```

**Text prompt**

```python
# Get current `production` version
langfuse_prompt = langfuse.get_prompt("movie-critic")

# Example using ChatPromptTemplate
langchain_prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())

# Example using ChatPromptTemplate with pre-compiled variables.
langchain_prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt(strictness='tough'))
```

**Chat prompt**

```python
# Get current `production` version of a chat prompt
langfuse_prompt = langfuse.get_prompt("movie-critic-chat", type="chat")

# Create a Langchain ChatPromptTemplate from the Langfuse prompt chat messages
langchain_prompt = ChatPromptTemplate.from_messages(langfuse_prompt.get_langchain_prompt())
```

**Optional parameters**

```python
# Get specific version
prompt = langfuse.get_prompt("movie-critic", version=1)

# Get specific label
prompt = langfuse.get_prompt("movie-critic", label="staging")

# Get latest prompt version. The 'latest' label is automatically maintained by Langfuse.
prompt = langfuse.get_prompt("movie-critic", label="latest")
```

**Attributes**

```python
# Raw prompt including {{variables}}. For chat prompts, this is a list of chat messages.
prompt.prompt

# Config object
prompt.config
```

</Tab>

<Tab>

As Langfuse and Langchain process input variables of prompt templates differently (`{}` instead of `{{}}`), we provide the `prompt.getLangchainPrompt()` method to transform the Langfuse prompt into a string that can be used with Langchain's PromptTemplate.

```ts
import { Langfuse } from "langfuse";
import { ChatPromptTemplate } from "@langchain/core/prompts";

const langfuse = new Langfuse();
```

**Text prompt**

```ts
// Get current `production` version
const langfusePrompt = await langfuse.getPrompt("movie-critic");

// Example using ChatPromptTemplate
const promptTemplate = PromptTemplate.fromTemplate(
  langfusePrompt.getLangchainPrompt()
);
```

**Chat prompt**

```ts
// Get current `production` version of a chat prompt
const langfusePrompt = await langfuse.getPrompt(
  "movie-critic-chat",
  undefined,
  { type: "chat" }
);

// Example using ChatPromptTemplate
const promptTemplate = ChatPromptTemplate.fromMessages(
  langfusePrompt.getLangchainPrompt().map((msg) => [msg.role, msg.content])
);
```

**Optional parameters**

```ts
// Get specific version of a prompt (here version 1)
const prompt = await langfuse.getPrompt("movie-critic", 1);

// Get specific label
const prompt = await langfuse.getPrompt("movie-critic", undefined, {
  label: "staging",
});

// Get latest prompt version. The 'latest' label is automatically maintained by Langfuse.
const prompt = await langfuse.getPrompt("movie-critic", undefined, {
  label: "latest",
});
```

**Attributes**

```ts
// Raw prompt including {{variables}}. For chat prompts, this is a list of chat messages.
prompt.prompt;

// Config object
prompt.config;
```

</Tab>

</Tabs>

### Link with Langfuse Tracing (optional)

You can link the prompt to the LLM `generation` span that used the prompt. This linkage enables tracking of metrics by prompt version and name directly in the Langfuse UI and see which prompt performed best. 

<Callout type="info">
If a [fallback prompt](/docs/prompt-management/features/guaranteed-availability#fallback) is used, no link will be created.
</Callout>

import PromptLinking from "@/components-mdx/prompt-linking.mdx";

<PromptLinking />

### Rollbacks (optional)

When a prompt has a `production` label, then that version will be served by default in the SDKs. You can quickly rollback to a previous version by setting the `production` label to that previous version in the Langfuse UI.

</Steps>

## End-to-end examples

The following example notebooks include end-to-end examples of prompt management:

import { Terminal, FileCode } from "lucide-react";

<Cards num={3}>
  <Card
    title="Example OpenAI Functions"
    href="/guides/cookbook/prompt_management_openai_functions"
    icon={<FileCode />}
  />
  <Card
    title="Example Langchain (Python)"
    href="/guides/cookbook/prompt_management_langchain"
    icon={<FileCode />}
  />
  <Card
    title="Example Langchain (JS/TS)"
    href="/guides/cookbook/js_prompt_management_langchain"
    icon={<FileCode />}
  />
</Cards>

We also used Prompt Management for our Docs Q&A Chatbot and traced it with Langfuse. You can get view-only access to the project by signing up to the [public demo](/docs/demo).

## Advanced features

// tbd: add advanced features from /features folder

# Python SDK

import { Callout } from "nextra/components";

<Callout type="info" emoji="â„¹ï¸">
  Get started with the SDK using this [example
  notebook](https://github.com/langfuse/langfuse-demo-python/blob/main/notebook.ipynb)
  ([open in Google
  Colab](http://colab.research.google.com/github/langfuse/langfuse-demo-python/blob/main/notebook.ipynb))
</Callout>

<Callout type="warning" emoji="ðŸš§">
  We have recently shipped a new version of the Python SDK with many
  improvements and simplifications. The documentation below is for the old
  version. We are working on updating the documentation. In the meantime, please
  refer to the [example
  notebook](https://github.com/langfuse/langfuse-demo-python/blob/main/notebook.ipynb)
  ([open in Google
  Colab](http://colab.research.google.com/github/langfuse/langfuse-demo-python/blob/main/notebook.ipynb))
</Callout>

The Python SDK can be imported into your project using pip.

## Installation

```bash
pip install --extra-index-url https://pypi.buildwithfern.com finto-fern-langfuse
```

## Usage

### Initialize client

Initialize the client with your environment and api keys. In the example we are using the cloud environment. The Python client can modify all entities in the Langfuse API and requires the secret key.

```python filename="server.py"
from finto.client import FintoLangfuse

client = FintoLangfuse(
  environment = "https://cloud.langfuse.com", # or any custom host, e.g. http://localhost:3030
  username = "pk-lf-...", # publishable key
  password = "sk-sk-...", # secret key
)
```

### Trace

Traces are the top-level entity in the Langfuse API. They represent an execution flow in a LLM application. Traces can be created and updated.

`trace.create()` takes the following parameters:

- `name`: identifier of the trace
- `attributes`: additional attributes of the trace. The content can be chosen freely.

```python filename="server.py"
trace = client.trace.create(
  request = CreateTraceRequest(
    name = "chat-completion",
    metadata = {
      "env": "production"
    }
  )
)
```

### Span

Spans represent durations of units of work in a trace. We generated convenient SDK functions for generic spans as well as LLM spans.

`span.create()` and `span.createLlmCall()` take the following parameters:

- `traceId` (optional): the id of the trace to which the span should be attached
- `name`: identifier of the span
- `attributes`: additional attributes of the span. The content can be chosen freely for generic spans. For LLM spans, the attributes are predefined.
- `parentObservationId` (optional): the id of the span or event to which the span should be attached

`span.update()` and `span.updateLlmCall()` take the following parameters:

- `spanId`: the id of the span to update
- `endTime`: the time at which the span ended
- `attributes` (optional): merges with existing attributes of the span. The content can be chosen freely for generic spans. For LLM spans, the attributes are predefined.

```python filename="server.py"
retrievalStart = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')

# const retrievedDoc = await retrieveDoc();

span = client.span.create(
  request = CreateSpanRequest(
    traceId = trace.id,
    name = "embedding-retrieval",
    startTime = retrievalStart,
    endTime = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
    metadata = {
      "userId": "user__935d7d1d-8625-4ef4-8651-544613e7bd22",
    },
  )
)

generationStart = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')

# const chat_completion = await callLLM([{"role": "user", "content": message_to_send}]);

generation = client.generations.log(
  request = CreateLog(
    traceId = trace.id,
    name = "chat-completion",
    startTime = generationStart,
    endTime = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
    model = "gpt-3.5-turbo",
    modelParameters = {
      "temperature": 0.9,
      "maxTokens": 1000,
      "topP": None,
    },
    prompt= [{"role": "user", "content": message_to_send}],
    completion=chat_response.json()["choices"][0]["message"],
    usage = LlmUsage(
      prompt_tokens = 512,
      completion_tokens = 49
    ),
    metadata = {
     "userid":'user__935d7d1d-8625-4ef4-8651-544613e7bd22',
    }
  )
)
```

### Events

Events are used to track discrete events in a trace. They are similar to spans just that they don't have a duration.

- `traceId`: the id of the trace to which the event should be attached
- `name`: identifier of the event
- `attributes`: additional attributes of the event. The content can be chosen freely.
- `parentObservationId` (optional): the id of the span or event to which the event should be attached
- `startTime`: the time at which the event occurred

```python filename="server.py"
event = client.event.create(
  request = CreateEventRequest(
    traceId = trace.id,
    name = "chat-completion-retried",
    startTime = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
    metadata = {
      "attempt": 2,
      "userid":'user__935d7d1d-8625-4ef4-8651-544613e7bd22',
    },
    parentObservationId = span.id,
  )
)
```

### Scores

Scores are used to evaluate the quality of LLM applications. They can be attached to spans, events, or traces.

- `traceId`: the id of the trace to which the score should be attached
- `name`: identifier of the score
- `value`: the value of the score; float; optional: scale it to e.g. 0..1
- `observationId` (optional): the id of the span or event to which the score should be attached

Either the traceId or the observationId must be provided.

```python filename="server.py"
score = client.score.create(
  request = CreateScoreRequest(
    traceId = trace.id,
    name = "user-feedback",
    value = 1,
    observationId = generation.id
  )
)
```

## Troubleshooting

If you encounter any issue, we are happy to help on [Discord](https://discord.gg/7NXusRtqYU) or shoot us an email: help@langfuse.com

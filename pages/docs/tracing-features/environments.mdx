---
description: Configure environments to organize your traces, observations, and scores.
---

# Environments

Environments allow you to organize your traces, observations, and scores from different contexts such as production, staging, or development. This helps you:

- Keep your development and production data separate while using the same project
- Filter and analyze data by environment
- Reuse datasets and prompts across environments

You can configure the environment by setting the `LANGFUSE_TRACING_ENVIRONMENT` environment variable or by using the `environment` parameter in the client initialization.
If both are specified, the initialization parameter takes precedence.
If nothing is specified, the default environment is `default`.

## Data Model

The `environment` attribute is available on all events in Langfuse:

- Traces
- Observations (spans, events, generations)
- Scores
- Sessions

See [Data Model](/docs/tracing-data-model) for more details.

The environment must be a string that follows this regex pattern: `^(?!langfuse)[a-z0-9-_]+$` with at most 40 characters.

This means:

- Cannot start with "langfuse"
- Can only contain lowercase letters, numbers, hyphens, and underscores

## Usage

<Tabs items={["Python", "JS/TS", "OpenTelemetry", "OpenAI (Python)", "OpenAI (JS/TS)", "Langchain (Python)", "Langchain (JS/TS)", "Vercel AI SDK (JS/TS)", "LlamaIndex (instrumentor)"]}>
<Tab>

When using the [`@observe()` decorator](/docs/sdk/python/decorators):

```python
from langfuse.decorators import langfuse_context, observe

# Either set the environment variable or configure the decorator. The latter takes precedence.
os.environ["LANGFUSE_TRACING_ENVIRONMENT"] = "production"

# Configure the decorator
langfuse_context.configure(environment="production")

@observe()
def fn():
    pass

fn()
```

When using the [low-level SDK](/docs/sdk/python/low-level-sdk):

```python
from langfuse import Langfuse

# Either set the environment variable or the constructor parameter. The latter takes precedence.
os.environ["LANGFUSE_TRACING_ENVIRONMENT"] = "production"

# Configure the client
langfuse = Langfuse(environment="production")

trace = langfuse.trace(
  name="Rap Battle",
)
```

</Tab>
<Tab>

```ts
import { Langfuse } from "langfuse";

const langfuse = new Langfuse({
  environment: "production",
});
```

See [JS/TS SDK docs](/docs/sdk/typescript/guide#environments) for more details.

</Tab>
<Tab>

When using [OpenTelemetry](/docs/opentelemetry/get-started), you can set the environment using any of these attributes:

- `langfuse.environment`
- `deployment.environment.name`
- `deployment.environment`

```python
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode

tracer = trace.get_tracer(__name__)

with tracer.start_as_current_span("my-operation") as span:
    # Set environment using Langfuse-specific attribute
    span.set_attribute("langfuse.environment", "staging")

    # Or using OpenTelemetry convention
    span.set_attribute("deployment.environment.name", "staging")
```

</Tab>
<Tab>

When using the [OpenAI SDK Integration](/docs/integrations/openai)

```python
from langfuse.openai import openai

# Either set the environment variable or configure the openai import. The latter takes precedence.
os.environ["LANGFUSE_TRACING_ENVIRONMENT"] = "production"

# Configure the openai import
openai.langfuse_environment = "production"

completion = openai.chat.completions.create(
  name="test-chat",
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a calculator."},
    {"role": "user", "content": "1 + 1 = "}],
)
```

</Tab>
<Tab>

```ts
import OpenAI from "openai";
import { observeOpenAI } from "langfuse";

const openai = observeOpenAI(new OpenAI(), {
  clientInitParams: {
    environment: "production",
  },
});
```

See [OpenAI Integration (JS/TS)](/docs/integrations/openai/js/get-started) for more details.

</Tab>

<Tab>

When using the [CallbackHandler](/docs/integrations/langchain/tracing)

```python
from langfuse.callback import CallbackHandler

# Either set the environment variable or the constructor parameter. The latter takes precedence.
os.environ["LANGFUSE_TRACING_ENVIRONMENT"] = "production"
handler = CallbackHandler(
  environment="production"
)
```

</Tab>

<Tab>

```ts
import { CallbackHandler } from "langfuse-langchain";

const handler = new CallbackHandler({
  environment: "production",
});
```

See [Langchain Integration (JS/TS)](/docs/integrations/langchain/tracing) for more details.

</Tab>

<Tab>

When using the [Vercel AI SDK Integration](/docs/integrations/vercel-ai-sdk)

```ts filename="instrumentation.ts" {/environment: "production"/}
import { registerOTel } from "@vercel/otel";
import { LangfuseExporter } from "langfuse-vercel";

export function register() {
  registerOTel({
    serviceName: "langfuse-vercel-ai-nextjs-example",
    traceExporter: new LangfuseExporter({ environment: "production" }),
  });
}
```

</Tab>

<Tab>

When using the [LlamaIndex Integration](/docs/integrations/llama-index/get-started)

```python
import os
from langfuse.llama_index import LlamaIndexInstrumentor

# Either set the environment variable or the constructor parameter. The latter takes precedence.
os.environ["LANGFUSE_TRACING_ENVIRONMENT"] = "production"
instrumentor = LlamaIndexInstrumentor(environment="production")
```

</Tab>

</Tabs>

## Filtering

In the Langfuse UI, you can filter events by environment using the environment filter in the navigation bar. This filter applies across all views in Langfuse (Coming soon).

See our [API Reference](/docs/api) for details on how to filter by environment on our API.

## Best Practices

1. **Consistent Environment Names**: Use consistent environment names across your application to make filtering and analysis easier.
2. **Environment-Specific Analysis**: Use environments to analyze and compare metrics across different deployment stages.
3. **Testing**: Use separate environments for testing to avoid polluting production data.

## GitHub Discussions

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["feat-tracing-environments"]} />

---
description: Capture all LLM calls made via LiteLLM in Langfuse
---

# ðŸš… LiteLLM Integration

**LiteLLM** ([GitHub](https://github.com/BerriAI/litellm)): Use any LLM as a drop in replacement for GPT. Use Azure, OpenAI, Cohere, Anthropic, Ollama, VLLM, Sagemaker, HuggingFace, Replicate (100+ LLMs).

## Integration

By adding the callback you can instantly log your responses across all providers with Langfuse.

```python filename="main.py"
# API keys from project settings in Langfuse
os.environ["LANGFUSE_PUBLIC_KEY"] = "your key"
os.environ["LANGFUSE_SECRET_KEY"] = "your key"

# Your host, defaults to https://cloud.langfuse.com
# For US data region, set to "https://us.cloud.langfuse.com"
# os.environ["LANGFUSE_HOST"] = "http://localhost:3000"

# Set callback
litellm.success_callback = ["langfuse"]
```

## Full Example

```python filename="main.py"
from litellm import completion

## set env variables
os.environ["LANGFUSE_PUBLIC_KEY"] = "your key"
os.environ["LANGFUSE_SECRET_KEY"] = "your key"

# Your host, defaults to https://cloud.langfuse.com
# For US data region, set to "https://us.cloud.langfuse.com"
# os.environ["LANGFUSE_HOST"] = "http://localhost:3000"

os.environ["OPENAI_API_KEY"] = ""
os.environ["COHERE_API_KEY"] = ""

# set callbacks
litellm.success_callback = ["langfuse"]

# openai call
response = completion(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "user", "content": "Hi ðŸ‘‹ - i'm openai"}
  ]
)

# cohere call
response = completion(
  model="command-nightly",
  messages=[
    {"role": "user", "content": "Hi ðŸ‘‹ - i'm cohere"}
  ]
)
```

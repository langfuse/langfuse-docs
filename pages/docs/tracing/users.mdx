---
description: User-level LLM observability to track token usage, usage volume and individual user feedback.
---

# Users

The Users view provides an overview of all users. It also offers an in-depth look into individual users.

It's easy to map data in Langfuse to individual users. Just pass a unique identifier as the `userId` when you create a `trace`. This can be a username, email, or any other unique identifier. The `userId` is optional, but using it helps you get more from Langfuse. See the integration docs to learn more.

<Tabs items={["Python", "JS/TS", "OpenAI", "Langchain (Python)", "Langchain (JS/TS)","LlamaIndex","Flowise"]}>
<Tab>

Decorators

```python
from langfuse.decorators import langfuse_context, observe

@observe()
def fn():
    langfuse_context.update_current_trace(
        user_id="your-user-id"
    )

fn()
```

Low-level SDK

```python
from langfuse import Langfuse
langfuse = Langfuse()

trace = langfuse.trace(
    user_id="your-user-id"
)
```

</Tab>
<Tab>

```typescript
import { Langfuse } from "langfuse";
const langfuse = new Langfuse();

const trace = langfuse.trace({
  userId: "your-user-id",
});
```

</Tab>
<Tab>

```python
from langfuse.openai import openai

completion = openai.chat.completions.create(
  name="test-chat",
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a calculator."},
    {"role": "user", "content": "1 + 1 = "}],
  temperature=0,

  # add user_id as additional argument
  user_id="your-user-id"
)
```

</Tab>
<Tab>

```python
handler = CallbackHandler(
  user_id="your-user-id"
)
```

</Tab>
<Tab>

```typescript
const handler = new CallbackHandler({
  userId: "your-user-id",
});
```

</Tab>

<Tab>

```python
from llama_index.core import Settings
from llama_index.core.callbacks import CallbackManager
from langfuse import langfuse

# Instantiate a new LlamaIndexCallbackHandler and register it in the LlamaIndex Settings
langfuse_callback_handler = LlamaIndexCallbackHandler()
Settings.callback_manager = CallbackManager([langfuse_callback_handler])

langfuse_callback_handler.set_trace_params(
  user_id="user-id",
)
```

All LlamaIndex traces created after `set_trace_params` will include the `user_id`. Learn more about `set_trace_params` [here](/docs/integrations/llama-index/get-started#set-trace-params).

</Tab>

<Tab>
You can set the `userId` via the override configs, see the [Flowise Integration docs](/docs/flowise) for more details.

</Tab>

</Tabs>

## View all users

The user list provides an overview of all users that have been tracked by Langfuse. It makes it simple to segment by overall token usage, number of traces, and user feedback.

<Frame>![User List](/images/docs/users-list.png)</Frame>

## Individual user view

The individual user view provides an in-depth look into a single user. Explore aggregated metrics or view all traces and feedback for a user.

<Frame>![Individual user view](/images/docs/users-single-user.gif)</Frame>

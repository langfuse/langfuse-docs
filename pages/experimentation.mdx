import { Steps, Card, Cards } from "nextra-theme-docs";
import { Callout } from "nextra/components";
import { SiGithub, SiTypescript, SiPython, SiDiscord } from "react-icons/si";
import { AiOutlineCloud } from "react-icons/ai";
import { BsCode } from "react-icons/bs";
import { Button } from "@/components/ui/button";
import Link from "next/link";
import Image from "next/image";
import ycImg from "@/src/yc.svg";
import { Calendar, Video } from "lucide-react";
import dashboardImg from "@/src/screen_experimentation_dashboard.svg";
import experimentationChart from "@/src/experimentation_chart.png";
import experimentationMetricEvalFact from "@/src/experimentation_metric_eval_fact.png";
import experimentationMetricEvalKindness from "@/src/experimentation_metric_eval_kindness.png";
import { ProductUpdateSignup } from "@/components/productUpdateSignup";

<div className="flex flex-col gap-9 mt-20 mb-10 md:mt-24 md:mb-20 lg:my-40 items-center">
  <h1 className="text-center text-4xl">`ðŸª¢ Langfuse`</h1>
  <div className="text-xl text-center">
    <div className="mb-2">
      **Developer-friendly experimentation** to iterate quickly on your LLM
      application's
    </div>
    <div>
      `prompts`, `chains`, `agents`, `models`, `embeddings`, `chunking`, ...
    </div>
  </div>
  <div className="flex flex-col items-center gap-4">
    <ProductUpdateSignup source="Experimentation [Landingpage test]" />
    <div className="flex flex-col gap-2 flex-wrap">
      <Button variant="ghost" asChild>
        <a href="https://cal.com/marc-kl/experimentation" target="_blank">
          <Calendar className="h-4 w-4 mr-2" />
          <span>Interested? Chat with us to join alpha</span>
        </a>
      </Button>
      <Button variant="ghost" asChild>
        <a
          href="https://www.loom.com/share/903d50e5d6d341d2aa7f1678562dfaba"
          target="_blank"
        >
          <Video className="h-4 w-4 mr-2" />
          <span>Why do we build Langfuse? (3 min)</span>
        </a>
      </Button>
    </div>
  </div>
  <div>
    <div className="text-center text-gray-500 pb-3 pt-10">Backed by</div>
    <Image src={ycImg} height={30} />
  </div>
</div>

## Why Langfuse?

<Callout type="info" emoji="â„¹ï¸">
  We want to make it fast and fun build reliable LLM applications. Our goal is
  to have the best developer experience for building LLM applications. Think
  "hot reload" (frontend) or "all tests passed" (backend), but for LLM
  applications.
</Callout>

<div className="flex flex-col gap-3 sm:gap-5 mt-8">
  <div className="flex gap-2 sm:gap-4">
    <div className="flex-1 font-semibold">With Langfuse</div>
    <div className="flex-1 font-semibold">Without Langfuse</div>
  </div>
  <div className="flex gap-2 sm:gap-4">
    <div className="flex-1 bg-green-50 text-green-900 px-3 py-1 rounded">
      Fast feedback loop to make rapid changes with confidence
    </div>
    <div className="flex-1 bg-red-50 text-red-900 px-3 py-1 rounded">
      Slow feedback loop in development
    </div>
  </div>
  <div className="flex gap-2 sm:gap-4">
    <div className="flex-1 bg-green-50 text-green-900 px-3 py-1 rounded">
      Experiment based on metrics and data
    </div>
    <div className="flex-1 bg-red-50 text-red-900 px-3 py-1 rounded">
      Experiment by looking at outputs
    </div>
  </div>
  <div className="flex gap-2 sm:gap-4">
    <div className="flex-1 bg-green-50 text-green-900 px-3 py-1 rounded">
      Dashboard to track experimentation evolution
    </div>
    <div className="flex-1 bg-red-50 text-red-900 px-3 py-1 rounded">
      Remember which changes led to improvements
    </div>
  </div>
  <div className="flex gap-2 sm:gap-4">
    <div className="flex-1 bg-green-50 text-green-900 px-3 py-1 rounded">
      Prebuilt library of popular metrics and evals
    </div>
    <div className="flex-1 bg-red-50 text-red-900 px-3 py-1 rounded">
      Don't know where to start with evaluation/scoring
    </div>
  </div>
</div>

## Monitor improvements in development

After each change you make, you can easily run an experiment in Langfuse to understand the impact of your changes.

### CLI

```raw /langfuse run experiment/
foo@bar:~$ langfuse run experiment
```

```raw {7-12}
? Name of experiment: (<enter> for current timestamp) smaller_doc_chunks
...
Running experiment ..
...
Experiment completed
Result
Aggregated metrics: 0.81 (+10%)
 - factEval (based on ideal output): 0.65 (+2%)
 - hallucination: 0.99 (+- 0)
 - kindness: 0.85
 - sameLanguage: 0.78
 - avg. execution time: 503.42 ms

Want to add manual eval? https://localhost:8420/eval
Compare to previous experiment? https://localhost:8420/dashboard
```

### Dashboard

```raw /langfuse dashboard/
foo@bar:~$ langfuse dashboard
```

<div className="mt-8 md:max-w-3xl mx-auto">
  <Image alt="Dashboard Screenshot" src={dashboardImg} />
</div>

## How it works

<div className="mt-8 md:max-w-3xl mx-auto">
  <Image alt="Experimentation Chart" src={experimentationChart} />
</div>

## Prebuilt metrics

Prebuilt metrics take the pain out of getting started with experimentation. Langfuse comes with a library of popular metrics and evals that you can use out of the box.

**Types of metrics**

- Algorithmic: <span className="text-gray-400">sentiment, grammar, readability, complexity, ...</span>
- Algorithmic with ideal output: <span className="text-gray-400">equality, fuzzyMatch, ...</span>
- Model-based: <span className="text-gray-400">hallucination, prompt injection prevention, same language, ...</span>
- Model-based with ideal output: <span className="text-gray-400">factual correctness, matching style, ...</span>
- Manual evaluation using Langfuse UI

**Integrated packages**

- [openAI Evals](https://github.com/openai/evals)
- [whylabs langkit](https://github.com/whylabs/langkit)
- [Let us know](request-eval-packages@langfuse.com) if there are other packages you would like to see integrated.

**Custom metrics/evals**

- Add own custom functions that you want to use with Langfuse.
- Add own custom evaluation prompts for model-based evaluation.

## Understand which metrics work for your use case

Langfuse helps you correlate metrics with your (teamâ€™s) manual evaluation to gain confidence in your metrics and evals.

<div className="mt-5 grid sm:grid-cols-2 md:px-20 gap-5 sm:gap-10 md:gap-20">
  <Image src={experimentationMetricEvalFact} />
  <Image src={experimentationMetricEvalKindness} />
</div>

## Interested?

Sign up for product updates

<div className="mt-2">
  <ProductUpdateSignup source="Experimentation [Landingpage test]" />
</div>

We are currently working on `v1` of _Langfuse experimentation_ with alpha users. If you are interested, [contact us](experimentation@langfuse.com), join our [discord](/discord), or [book a short call](https://cal.com/marc-kl) with one of the builders if you'd like to share more about your use case.

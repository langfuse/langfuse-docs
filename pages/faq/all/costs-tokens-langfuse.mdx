---
title: How do I track LLM cost and tokens in Langfuse?
tags: [features]
---

# How do I track LLM cost and tokens in Langfuse?

You can track cost and token usage for any LLM model and endpoint in Langfuse. In general there are two ways to do this

1. Automatically calculated by Langfuse: For [supported models](/docs/model-usage-and-cost#infer) Langfuse will infer the cost. This requires you to ingest the correct model names. We currently support OpenAI and Anthropic off the shelf. Please refer to the *Models* tab in Langfuse for exact model names. 

2. Explicitly pass cost and tokens: You can [ingest](/docs/model-usage-and-cost#infer) cost and token counts for your LLM calls that you already track with Langfuse. Some model providers return cost and tokens as payload in their return requests. You can pass these back to Langfuse. 

Bonus: Cost tracking is natively supported in our [OpenAI integration](/docs/model-usage-and-cost#compatibility-with-openai). 

Please see more info and examples at [cost and tokens in Langfuse](/docs/model-usage-and-cost)
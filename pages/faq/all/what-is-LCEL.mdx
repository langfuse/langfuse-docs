---
title: "What is LangChain Expression Language (LCEL)?"
description: "Learn about LangChain Expression Language (LCEL) — a declarative syntax for composing LLM chains and workflows. Understand LCEL advantages, criticisms, syntax examples, and how to trace LCEL chains with Langfuse."
tags: [integration, integration-langchain]
---

# What is LangChain Expression Language (LCEL)?

<Frame fullWidth>
  ![LangChain Expression Language (LCEL)](/images/blog/faq/what-is-lcel.png)
</Frame>

[LangChain Expression Language](https://python.langchain.com/docs/concepts/lcel/) (LCEL) is a declarative syntax for composing complex LLM chains and workflows in [LangChain](/integrations/frameworks/langchain). It uses the pipe operator (`|`) to chain components together, letting you represent even complex multi-step workflows in just a few lines of code.

LCEL is the recommended way to build chains in LangChain. It provides a consistent interface for composing prompts, models, output parsers, retrievers, and tools into production-ready pipelines.

## How LCEL Works

At its core, LCEL uses Python's `|` (pipe) operator to chain together **Runnables** — components that take an input and produce an output. Each component in the chain receives the output of the previous component as its input.

Here's a simple example:

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# Define components
prompt = ChatPromptTemplate.from_template("Tell me a joke about {topic}")
model = ChatOpenAI(model="gpt-4o-mini")
output_parser = StrOutputParser()

# Compose with LCEL pipe syntax
chain = prompt | model | output_parser

# Run the chain
result = chain.invoke({"topic": "programming"})
```

This creates a chain that: (1) formats the prompt with the topic, (2) sends it to the model, (3) parses the output to a string.

### More Complex LCEL Patterns

LCEL supports advanced composition patterns beyond simple linear chains:

```python
from langchain_core.runnables import RunnableParallel, RunnablePassthrough

# Parallel execution — run multiple chains simultaneously
chain = RunnableParallel(
    joke=prompt | model | output_parser,
    original_input=RunnablePassthrough()
)

# Branching and routing
from langchain_core.runnables import RunnableBranch

branch = RunnableBranch(
    (lambda x: "math" in x["topic"], math_chain),
    (lambda x: "code" in x["topic"], code_chain),
    default_chain  # fallback
)
```

## Advantages of LCEL (LangChain Expression Language)

- **Ease of Use & Flexibility**: Simplifies creating and scaling complex workflows; smooth transition from prototype to production.
- **Performance & Optimization**: Enhances performance with parallel execution and reduced latency, helpful for real-time applications.
- **Built-in streaming**: Every LCEL chain supports streaming out of the box, enabling responsive user experiences where tokens are displayed as they're generated.
- **Advanced Features**: Supports retries, fallbacks, and streaming, improves reliability and monitoring.
- **Async support**: LCEL chains work with both synchronous and asynchronous execution, making them suitable for web applications.
- **Community & Adoption**: Positively received, with growing community adoption.

## Criticisms of LCEL (LangChain Expression Language)

- **Learning Curve**: Steep for those unfamiliar with the declarative syntax; may not justify the effort for simple use cases.
- **Overkill for Simple Tasks**: Adds complexity to small projects where plain Python functions would suffice.
- **Debugging Challenges**: Harder to trace and debug complex chains without proper observability tooling (see [Tracing LCEL Chains](#tracing-lcel-chains-with-langfuse) below).
- **Performance Overhead**: Potential to slow down development if not optimally used.
- **Abstraction trade-offs**: The pipe syntax can obscure what's actually happening, making it harder to reason about data flow in deeply nested chains.

## Tracing LCEL Chains with Langfuse

One of the common challenges with LCEL is debugging complex chains. [Langfuse](/integrations/frameworks/langchain) provides full observability for LangChain and LCEL chains, automatically capturing every step:

```python
from langfuse.langchain import CallbackHandler

langfuse_handler = CallbackHandler()

# Pass the handler to any LCEL chain invocation
result = chain.invoke(
    {"topic": "programming"},
    config={"callbacks": [langfuse_handler]}
)
```

With Langfuse tracing, you can see the full execution flow of your LCEL chain — every prompt template rendering, model call, and output parsing step — with timing, inputs, outputs, and cost information.

Learn more in our [LangChain & LangGraph integration guide](/integrations/frameworks/langchain).

## FAQ

<Accordion title="What is LCEL in LangChain?">
LCEL (LangChain Expression Language) is a declarative syntax for composing LLM chains in LangChain. It uses Python's pipe operator (`|`) to chain together prompts, models, output parsers, retrievers, and other components into production-ready workflows. It's the recommended way to build chains in LangChain, providing built-in streaming, async support, and parallel execution.
</Accordion>

<Accordion title="Is LCEL required to use LangChain?">
No. While LCEL is the recommended way to compose chains in LangChain, you can still use LangChain components individually without LCEL syntax. You can call models, prompts, and other components directly as Python functions. However, LCEL provides benefits like automatic streaming, parallel execution, and consistent interfaces that make it valuable for production applications.
</Accordion>

<Accordion title="How do I debug LCEL chains?">
LCEL chains can be difficult to debug because the pipe syntax abstracts away the intermediate steps. The best approach is to use an observability tool like [Langfuse](/integrations/frameworks/langchain) that automatically traces every step of your LCEL chain. You can also use LangChain's built-in verbose mode or add print statements at each step for quick debugging during development.
</Accordion>

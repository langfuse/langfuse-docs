---
title: "Why does Langfuse exist?"
---

# Why does Langfuse exist?

> Accelerate the deployment of useful AI applications/agents

Langfuse is the neutral and [open](/handbook/chapters/open-source) tooling layer for AI systems; based on production-grade tracing, online monitoring, collaborative prompt management and offline evals. With Langfuse teams can measure, improve, and govern every model, prompt, and agent. We are building the default way companies understand and optimize AI application performance at scale, independent of any model, framework, or cloud.

AI can create so much value for society and drive meaningful economic growth. We are still at the very early stages (est < 1% compared to what we will see over the next years). Every (successful) company will be an AI company with AI at the core of its strategy, value creation, and business processes.

Most of value creation will happen at the application-layer and will be split between enterprises/incumbents who own the transaction/process and AI-native startups.

Today, these teams face a lot of challenges when trying to make their applications useful, safe, scalable, explainable, and cheap:

- Visibility/explainability of applications/agents --> Langfuse Observability
- Collaboration in interdisciplinary teams --> Langfuse Prompt Management, sharable views/dashboards
- Evaluation, dataset management, labeling --> Langfuse Evaluations

Over time, the issues that are most pressing will change. Model capabilities increase, inference gets cheaper, models can work on problems for longer. If a large enterprise had an unlimited quantity of "1 week of phd-level intelligence" available, it's certain that many back-office tasks are solvable even without a lot of optimization and supervision. Focus will shift from "how to make it work/useful" to "how does it work and what is even happening".

We are building Langfuse to help today's and tomorrow's AI application builders.

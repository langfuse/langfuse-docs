---
title: "How did we get here?"
---

import { ProductUpdateSignup } from "@/components/productUpdateSignup";

# How did we get here?

Langfuse has grown a lot over the last few years. This is a high-level overview of how we got here. If you really want more details, check out the [changelog](/changelog).

## Timeline

<Steps>

### 2022: Clemens, Max, and Marc start working together

We got started working together in 2022. We explored different ideas and landed on building a usage-based billing product (named _Finto_) to solve problems we had encountered in previous roles.

With an initial product and customers, we got accepted into YC W23 in November 2022.

### Jan-Apr 2023: Building AI applications in YC W23

<Frame className="max-w-sm">
  ![YC Sign](/images/handbook/story/2023_founders.jpeg)
</Frame>

We moved to San Francisco for the YC W23 batch. While our customers were excited about Finto (the billing product), we realized that we were not excited about building the _nth_ generation of product in an established (small) market. Given the progress in LLMs, we realized that there were much bigger and more exciting problems to solve.

We used most of the YC Batch to work on all sorts of AI application problems, including:

- Learn from AI: Educational courses on any topic
- Sales data enrichment via LLM-based web research
- Collaborative LLM-agnostic ChatGPT for teams
- LLM-created PRs for any GitHub issue assigned to our bot

We moved through most ideas rather quickly (usually < 2 weeks each). On the final idea, we spent much longer as creating multi-file edits was significantly more work and more exciting. Throughout this process we learned:

1. There are so many use cases for the technology, building startups is less about validating a problem / pain point and more about demonstrating that you can build an AI-enabled product that solves it. Lots of companies want to try and are willing to pay for AI products given the high returns.
2. We want to work on a problem where we deeply care about the users
3. Building LLM applications is hard. Many disregarded them as _GPT-wrappers_, but they are core to the value creation and don't _just work_, they need methodical evaluation and iteration

The last point was reconfirmed every week when meeting with other YC founders who tried hard to make their products work to win customers.

### May - Aug 2023: Langfuse v0.x and public launch

This realization led us to finally focus on building open-source tooling for LLM application developers (see [_Why do we exist?_](/handbook/chapters/mission)), as it seemed to be a much bigger problem and solving it would have an outsized impact by helping more teams build better LLM applications.

We built an initial version and had our first customers in the YC batch. It was exciting to see how much time these early customers spent in-product to iterate and test their applications, and how much feedback and how many referrals to other teams we received from them. We decided that we wanted Langfuse to be open source (more on this [here](/handbook/chapters/open-source)) and published the repo.

Once the product was stable enough (not in a semver sense), we publicly launched Langfuse as _Product Analytics for LLM Apps_ in July/August 2023:

- [Show HN](https://news.ycombinator.com/item?id=37310070)
- [Launch YC](https://www.ycombinator.com/launches/J2s-langfuse-open-source-product-analytics-for-llm-apps)
- [Product Hunt](https://www.producthunt.com/products/langfuse/launches/langfuse) (Product of the Day, Golden Kitty Award)

### Sep 2023: $4M Seed led by Lightspeed Venture Partners, La Famiglia, and Y Combinator

It quickly became clear that Langfuse _works_, our customers loved the initial product, and we were excited to build it.

Given our excitement about the project and great feedback from customers on the launch, we raised a [$4M seed round](/blog/announcing-our-seed-round) led by Lightspeed Venture Partners, La Famiglia, Y Combinator, and angel investors.

### Oct 2023: 1,000 GitHub Stars

### Jan 2024: Launch of Prompt Management

In the first months of Langfuse, we focused exclusively on getting the tracing/observability features right. Over the New Year, we decided to branch out into Prompt Management as (1) many early customers asked for it, and (2) we saw a lot of benefit in a prompt management product that is tightly integrated with the tracing/observability features. We launched an [initial version](/changelog/2024-01-03-prompt-management) within a couple of days and it has since grown into a [core part](/docs/prompt-management) of Langfuse.

### Feb 2024: Initial team

<Frame className="max-w-sm">
  ![Team 2024](/images/handbook/story/2024_team_foundingeng.jpg)
</Frame>

Given strongly increasing traction, it was the right time to build the initial team. Marlies and Hassieb joined as Founding Engineers.

### Apr 2024: Launch Week 1 and _The LLM Engineering Platform_

Our ambition grew to help developers cover the full development lifecycle of LLM applications beyond observability and prompt management. The lifecycle was still ambiguous, and we were excited to define it together with the growing community.

In our [first Launch Week](/blog/launch-week-1), we reintroduced Langfuse as the [LLM Engineering Platform](/blog/2024-04-introducing-langfuse-2.0) and launched essential features to cover the workflow:

- [LLM Playground](/docs/prompt-management/features/playground)
- [Datasets](/docs/evaluation/experiments/datasets)
- [LLM-as-Judge evaluations](/docs/evaluation/evaluation-methods/llm-as-a-judge) run by Langfuse

We [launched](https://www.producthunt.com/products/langfuse/launches/langfuse-2-0) a second time on Product Hunt and became Product of the Day again. To celebrate Launch Week, we hosted our [first community town hall](https://www.youtube.com/watch?v=WGERHcRnBYQ) which is an essential part of our community-focused culture ever since.

### Sep 2024: >2M SDK installs/month

We looked at the SDK installs and realized that they were downloaded _a lot_. We [added](https://github.com/langfuse/langfuse-docs/commit/8909c0d9ea6169515087ce526ebcbf4a521fb5c7) them to the website as we thought it was cool.

### Nov 2024: Launch Week 2

After the success of our first Launch Week, we decided to do another one to support the next generation of models and closing the end-to-end development loop within Langfuse. We launched:

- Experiment Comparison View
- LLM-as-a-Judge on Experiments
- Multi-modal support
- Prompt Experiments

### Dec 2024: Langfuse v3 (switch to ClickHouse)

<Frame className="max-w-sm">
  ![Langfuse
  v3](/images/blog/2024-12-langfuse-v3-infrastructure-evolution/og.png)
</Frame>

Langfuse was growing a lot and we needed to make it way more scalable to allow the ingestion of hundreds of millions of records. Langfuse v3 was a major upgrade of the infrastructure powering Langfuse and marked a maturation from a simple prototype (on Postgres) to a scalable observability platform (on ClickHouse).

We [wrote](/blog/2024-12-langfuse-v3-infrastructure-evolution) extensively about this change when releasing v3. It has been the largest ever in the history of Langfuse.

### Apr 2025: 10,000 GitHub Stars

The Langfuse community grew a lot and we reached 10,000 GitHub Stars. GitHub Discussions has become the primary place for the community to discuss all things Langfuse, with over 1,400 threads started.

### Feb 2025: SF Office

Clemens moved to San Francisco and started the SF office to work more closely with our Bay Area community/customers. Akio joined shortly after to build out the commercial side of Langfuse, until now we have focused exclusively on engineering in our Berlin office.

### May 2025: Launch Week 3

Powered by the scalability of Langfuse v3, the tracing volume grew rapidly. In [Launch Week 3](/blog/2025-05-19-launch-week-3), we focused on making this data more accessible and actionable. We released:

- Full-text search
- Saved/shared table views
- Custom dashboards

Custom dashboards were a very popular request that we wanted to build for a very long time. First we did not have the capacity, and then the data volume Langfuse processed was infeasible to plot on postgres-backed Langfuse v2. We wrote more about how we built them [here](/blog/2025-05-21-customizable-dashboards).

### Jun 2025: Doubling Down on Open Source

<Frame className="max-w-sm">
  ![Doubling Down on Open
  Source](/images/blog/2025-06-04-open-sourcing-langfuse-product/langfuse-open-source-og.png)
</Frame>

In [June 2025](/blog/2025-06-04-open-sourcing-langfuse-product), we made a pivotal decision: all Langfuse product features were open sourced under the MIT license. Capabilities that were previously reserved for commercial users, such as LLM-as-a-Judge evaluations, annotation queues, prompt experiments, and the playground, became freely available for anyone to self-host.

This marked a major expansion of our open core. Now, only essential Enterprise Security and Platform features (like SCIM, Audit Logs, and Data Retention Policies) remain under a commercial license. Our [goal](/handbook/chapters/mission) is to empower engineering teams to build ambitious LLM applications with robust [open source](/handbook/chapters/open-source) tools.

### Jun - Aug 2025: OpenTelemetry

In 2025, we went all-in on OpenTelemetry for the Observability product to increase openness, scalability, vendor-neutrality and interoperability.
We launched:

- OpenTelemetry Endpoint for Langfuse
- Python SDK v3 (OpenTelemetry-based)
- JS SDK v4 (OpenTelemetry-based)

### Sep 2025: 2nd Annual Offsite

<Frame className="max-w-sm">
  ![Langfuse team together in Portugal, September
  2025](/images/handbook/story/2025_team_offsite.jpg)
</Frame>

In 2025, the team has grown quite a bit in Berlin and SF. We all met in Portugal to work on some exiting new topics, get to know each other and also celebrate a bit.

### Sep 2025: Graduated Pricing + Price Drop + Self-serve Enterprise

Over these months, we grew rapidly on the business side and decided to make some changes that help us scale faster:

- Graduated Pricing: if you use more of Langfuse, it gets cheaper; we scale and we want to share the benefits with everyone, not just with those who try to negotiate
- Price Drop: the Core plan decreased in price by 50% from $59 to $29/month to make it super easy to get started with Langfuse for even the smallest teams
- Self-serve Enterprise: again, we like to let customers serve themselves whenever it is possible and do not want to force them to go through a sales process or call when it is not necessary

</Steps>

## Where are we headed?

- Short term: [Roadmap](/roadmap)
- Long term: [Why does Langfuse exist?](/handbook/chapters/mission)

Want to keep up? Subscribe to our mailing list:

<ProductUpdateSignup source="Handbook Story" className="mt-4" />

## Community Metrics

import PublicMetricsDashboard from "@/components-mdx/public-metrics-dashboard.mdx";

<PublicMetricsDashboard />

import { Card, Cards } from "nextra-theme-docs";
import { SiGithub } from "react-icons/si";
import { AiOutlineCloud } from "react-icons/ai";

<div className="gap-3 mt-0 mb-10 md:mt-24 md:mb-20 lg:my-30">
  <h1>`ðŸª¢ langfuse`</h1>
  <div className="text-xl text-center">
    open-source tracing and feedback collection for applications built on top of
    LLMs
  </div>

  <div className="flex mt-3 gap-3 justify-center flex-wrap">
    <Card icon={<span>ðŸš€</span>} title="Quickstart" href="/docs/get-started" />
    <Card
      icon={<SiGithub size="24" />}
      title="Repo"
      href="https://github.com/langfuse/langfuse"
    />
    <Card
      icon={<AiOutlineCloud size="24" />}
      title="Sign in"
      href="https://cloud.langfuse.com"
    />
  </div>
</div>

import Demo from "/components/demoVideo";

<div className="mb-20">
  <Demo />
  <div className="text-center -mt-4 text-gray-500">Walkthrough (3:33 min)</div>
</div>

## `langfuse` overview

> Debug and improve your LLM-based application by logging/analyzing all user interactions, backend traces, and user feedback.

import Overview from "/components/start/overview.mdx";

<Overview />

## Features

import { Feature } from "/components/feature";
import screenDashboard from "../src/screen_dashboard.png";

<Feature src={screenDashboard} imageAlt="test" imagePosition="left">

### Monitor

- Fast overview: Have a quick view on output quality and feature adoption in real-time
- Track token usage by feature (coming soon)

</Feature>

<Feature src={screenDashboard} imageAlt="test" imagePosition="right">

### Understand and segment use cases

- Powerful filtering: filter LLM traces by dimensions like user attributes or scores to find clusters of underperforming outputs
- Model-based clustering of use cases (coming soon)

</Feature>

<Feature src={screenDashboard} imageAlt="test" imagePosition="left">

### View all executions of a subset side-by-side

- Browse LLM data side-by-side to gain a deep understanding on why chains did not perform well and derive how to improve them.
- Model-based comparison of traces (coming soon)

</Feature>

import { TwoCards, StartCard } from "/components/cards";

<TwoCards>
<StartCard>
  
### Open source

- Powered by NextJs and postgres
- Fully typed SDKs for Typescript and Python
- Easy deployments with docker or in the cloud

</StartCard>
<StartCard>
  
### Build your data moat (coming soon)

Log executions and prompt/completion pairs for future fine tuning, prompt engineering and few shotting.

1. Retrieval API for good prompt completion pairs for few-shotting
2. Create exports of high-quality prompt/completions for fine tuning models for your use case

</StartCard>
</TwoCards>

**Architecture**

- Server ([cloud](/docs/cloud), [local](/docs/local), [self-hosted](/docs/self-host))
  - API server on top database
  - Web app to explore data
- [Client SDKs](/docs/sdk) to integrate with LLM application
  - Backend SDK for tracing
  - Frontend SDK for scoring of traces based on user feedback/interaction

## Why are we building `langfuse`?

1. **Situation:** LLMs introduce a _'black box'_ character to Software Engineering: outputs of LLM-based applications are unpredictable
2. **Problem:** Quality of application in production cannot be assured with testing before launching the feature
3. **Consequence:** Engineers need to embrace active learning from users in production to improve their LLM-based applications. Many teams build UX around their applications to make the imperfect outputs usable and to collect feedback from users.
4. **Need:** Holistic tracing of what happens in production, linked to user feedback and other signals to understand how to improve the application.

## Get in touch

`langfuse` is being actively developed in open source together with the community. Join our [Discord](https://discord.com/invite/DNDAarxE)! Provide feedback, report bugs, or request features via GitHub issues. If you want to chat about your use case, reach out to us via email: contact@langfuse.com

## Roadmap

- [x] MVP: API server for collecting traces, scores, and basic UI to explore data, runs locally or self-hosted
- [x] [SDKs](/docs/sdk) for tracing and scoring, typescript and python
- [x] [Docs](/docs) and walkthrough (v1) ([video](#), [NextJS example](https://github.com/langfuse/langfuse-demo), [Jupyter Notebook example](https://github.com/langfuse/langfuse-demo-python/blob/main/notebook.ipynb))
- [x] [Dashboard](/docs/interface#dashboard) to explore data
- [x] Authentication and authorization on project level in UI, API, SDKs
- [x] [langfuse cloud](/docs/cloud) to simplify setup
- [ ] Model-based evaluation of traces and LLM calls
- [ ] Pre-built SDK functions for best-practice scoring
- [ ] Tracing integration with frameworks, e.g. langchain
- [ ] API to retrieve few-shot examples based on embedding similarity to current prompt
- [ ] LLM playground to interactively adapt prompts based on production examples

Want to see something else? Share your thoughts by creating a [GitHub issue](https://github.com/langfuse/langfuse/issues/new/choose) or on [Discord](https://discord.com/invite/DNDAarxE)

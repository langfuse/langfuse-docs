import { Card, Cards } from "nextra-theme-docs";
import { SiGithub, SiTypescript, SiPython } from "react-icons/si";
import { AiOutlineCloud } from "react-icons/ai";
import { BsCode } from "react-icons/bs";
import { Button } from "/components/ui/button";
import Link from "next/link";
import { Buttons } from "/components/demoVideo";

<div className="container">
<div className="flex flex-col gap-5 mt-0 mb-10 md:mt-24 md:mb-20 lg:my-30">
  <div className="text-center text-2xl">
   `ðŸª¢ langfuse`
  </div>
  <div className="text-xl text-center">
    open-source tracing and feedback collection for applications built on top of
    LLMs
  </div>

  <div className="flex mt-3 gap-3 justify-center flex-wrap">
    <Buttons />
  </div>
</div>

import { Feature } from "/components/feature";
import screenDashboard from "../src/screenshots_dashboard.png";
import screenSegmentTraces from "../src/screenshots_segment_traces.png";
import screenSideBySide from "../src/screenshots_side_by_side.png";

<Feature src={screenDashboard} imageAlt="test" imagePosition="left">

## Monitor

Fast overview: Have a quick view on output quality and feature adoption in real-time

Track token usage by feature (coming soon)

</Feature>

<Feature src={screenSegmentTraces} imageAlt="test" imagePosition="right">

## Understand and segment use cases

Powerful filtering: filter LLM traces by dimensions like user attributes or scores to find clusters of underperforming outputs

Model-based clustering of use cases (coming soon)

</Feature>

<Feature src={screenSideBySide} imageAlt="test" imagePosition="left">

## View all executions of a subset side-by-side

Browse LLM data side-by-side to gain a deep understanding on why chains did not perform well and derive how to improve them.

Model-based comparison of traces (coming soon)

</Feature>

import { TwoCards, StartCard } from "/components/cards";

<TwoCards className="my-24">
<StartCard isOutline>
  
## Open source

- Powered by NextJs and postgres
- Fully typed SDKs for Typescript and Python
- Simple self-hosting on your own infrastructure

</StartCard>
<StartCard isOutline>
  
## Build your data moat

- Retrieval API (coming soon) to query prompts/completions based on similarity to current prompt
- Exports of high-quality prompt/completions for fine tuning; e.g. use GPT-4 completions to train own Llama models

</StartCard>
</TwoCards>

## Langfuse is easy to get started with

<div className="grid lg:grid-cols-2 lg:gap-7">
<div>

### 1. Capture execution data

<div className="flex gap-3 my-2 flex-wrap">
  <Button variant="outline" asChild>
    <Link href="/docs/reference">
      <BsCode className="mr-2 h-5 w-5" />
      API
    </Link>
  </Button>
  <Button variant="outline" asChild>
    <Link href="/docs/sdk/python">
      <SiPython className="mr-2" />
      Python SDK
    </Link>
  </Button>
  <Button variant="outline" asChild>
    <Link href="/docs/sdk/typescript">
      <SiTypescript className="mr-2" />
      Typescript SDK
    </Link>
  </Button>
</div>

```python filename="server.py"
# LLM-based server route
trace = langfuseClient.trace.create( request = {
    "name": "chat-completion",
    "attributes": {
        "prompt": "Hi there!",
        "completion": "Hi ðŸ‘‹",
        "model": ...
    },
    ...
}))
```

</div>
<div>

### 2. Capture scores from user feedback

<div className="flex gap-3 my-2 flex-wrap">
  <Button variant="outline" asChild>
    <Link href="/docs/reference#restricted-access-with-publishable-client-side">
      <BsCode className="mr-2 h-5 w-5" />
      API
    </Link>
  </Button>
  <Button variant="outline" asChild>
    <Link href="/docs/sdk/typescript#frontend">
      <SiTypescript className="mr-2" />
      Typescript SDK
    </Link>
  </Button>
</div>

```typescript filename="UserFeedbackComponent.tsx"
// feedback button handler
const handleUserFeedback = (value: number) =>
  langfuseClient.score.create({
    traceId: props.traceId,
    name: "user_feedback",
    value,
  });
```

</div>
</div>

### 3. Run langfuse server

<TwoCards className="mt-6">
<StartCard isDark>
  
### Langfuse cloud

- Fully managed
- Generous free tier to get started ([pricing](/docs/cloud#pricing))

<div className="flex gap-2 pt-3">
  <Button asChild>
    <Link href="https://forms.reform.app/hYLlrw/langfuse-cloud">
      <AiOutlineCloud className="mr-2 h-4 w-4" />
      Sign up for early access
    </Link>
  </Button>
  <Button variant="ghost">Docs</Button>
</div>

</StartCard>
<StartCard isOutline>
  
### Opensource

- Full data ownership
- Within your own VPS

<div className="flex gap-2 pt-3 items-end">
  <Button asChild>
    <Link href="https://github.com/langfuse/langfuse/">
      <SiGithub className="mr-2" />
      GitHub
    </Link>
  </Button>
  <Button variant="secondary" asChild>
    <Link href="/docs/local">Run locally</Link>
  </Button>
  <Button variant="secondary">
    <Link href="/docs/self-host">Self-host</Link>
  </Button>
</div>

</StartCard>
</TwoCards>

## Why are we building `langfuse`?

1. **Situation:** LLMs introduce a _'black box'_ character to Software Engineering: outputs of LLM-based applications are unpredictable
2. **Problem:** Quality of application in production cannot be assured with testing before launching the feature
3. **Consequence:** Engineers need to embrace active learning from users in production to improve their LLM-based applications. Many teams build UX around their applications to make the imperfect outputs usable and to collect feedback from users.
4. **Need:** Holistic tracing of what happens in production, linked to user feedback and other signals to understand how to improve the application.

## Get in touch

`langfuse` is being actively developed in open source together with the community. Join our [Discord](https://discord.com/invite/DNDAarxE)! Provide feedback, report bugs, or request features via GitHub issues. If you want to chat about your use case, reach out to us via email: contact@langfuse.com

## Roadmap

- [x] API server for collecting traces, scores, and basic UI to explore data, runs locally or self-hosted
- [x] [SDKs](/docs/sdk) for tracing and scoring, typescript and python
- [x] [Docs](/docs) and walkthrough (v1) ([video](#), [NextJS example](https://github.com/langfuse/langfuse-demo), [Jupyter Notebook example](https://github.com/langfuse/langfuse-demo-python/blob/main/notebook.ipynb))
- [x] [Dashboard](/docs/interface#dashboard) to explore data
- [x] Authentication and authorization on project level in UI, API, SDKs
- [x] [langfuse cloud](/docs/cloud) to simplify setup
- [ ] Model-based evaluation of traces and LLM calls
- [ ] Pre-built SDK functions for best-practice scoring
- [ ] Tracing integration with frameworks, e.g. langchain
- [ ] API to retrieve few-shot examples based on embedding similarity to current prompt
- [ ] LLM playground to interactively adapt prompts based on production examples

Want to see something else? Share your thoughts by creating a [GitHub issue](https://github.com/langfuse/langfuse/issues/new/choose) or on [Discord](https://discord.com/invite/DNDAarxE)

</div>

---
title: "TrueFoundry Integration"
sidebarTitle: TrueFoundry
logo: /images/integrations/truefoundry-logo.png
description: "Learn how to integrate Langfuse with TrueFoundry."
---

## What is TrueFoundry AI Gateway?

[TrueFoundry AI Gateway](https://www.truefoundry.com/ai-gateway) is a unified interface that provides access to multiple AI models with advanced features for control, visibility, security, and cost optimization in your Generative AI applications. It offers seamless integration with popular observability tools like Langfuse.

#### How TrueFoundry Integrates with Langfuse

TrueFoundry integrates with Langfuse with the help of Langfuse SDK's OpenAI class. Requests are routed via TrueFoundry AI Gateway and the traces are pushed to Langfuse with the help of their SDK. Some features of TrueFoundry:

<details>
<summary><strong>Unified OpenAI-Compatible Endpoint</strong></summary>

Simply point the Langfuse OpenAI client at TrueFoundry's gateway URL. TrueFoundry routes requests to any supported model (OpenAI, Anthropic, Azure OpenAI, self-hosted models, etc.), while Langfuse transparently captures every call with full contextâ€”no application code changes required.
</details>

<details>
<summary><strong>Comprehensive Tracing & Analytics</strong></summary>

Langfuse automatically captures:
- **Complete request/response logs** (including system messages and metadata)
- **Detailed token usage** (prompt tokens, completion tokens, total consumption)
- **Performance metrics** (latency breakdowns, response times)
- **Cost analytics** by model, environment, and user
- **Error tracking** and debugging information

Drill into any trace instantly to optimize performance or debug issues.
</details>

<details>
<summary><strong>Enterprise-Grade Controls</strong></summary>

TrueFoundry adds production-ready governance to your LLM stack:
- **Rate limiting & quotas** with granular controls per team or user
- **Budget alerts & spend caps** to prevent cost overruns
- **Role-based access control** with scoped API keys for dev, staging, and production
- **On-premises/VPC deployment** for complete data sovereignty and compliance
- **Model fallbacks** and load balancing for high availability
</details>

## Prerequisites

Before integrating Langfuse with TrueFoundry, ensure you have:

1. **TrueFoundry Account**: Create a [TrueFoundry account](https://docs.truefoundry.com/gateway/quick-start) with atleast one model provider and generate a Personal Access Token by following the instructions in [Generating Tokens](https://docs.truefoundry.com/gateway/authentication)
2. **Langfuse Account**: Sign up for a free [Langfuse Cloud account](https://cloud.langfuse.com) or self-host Langfuse

## Integration Guide

### Step 1: Install Dependencies

Install the required packages for TrueFoundry and Langfuse integration:

```bash
pip install openai langfuse
```

### Step 2: Set Up Environment Variables

Configure your Langfuse API keys. Get these keys from your [Langfuse project settings](https://cloud.langfuse.com):

```python
import os

# Langfuse Configuration
os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-lf-..."
os.environ["LANGFUSE_SECRET_KEY"] = "sk-lf-..." 
os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com"  # ðŸ‡ªðŸ‡º EU region
# os.environ["LANGFUSE_HOST"] = "https://us.cloud.langfuse.com"  # ðŸ‡ºðŸ‡¸ US region

# TrueFoundry Configuration
os.environ["TRUEFOUNDRY_API_KEY"] = "your-truefoundry-token"
os.environ["TRUEFOUNDRY_BASE_URL"] = "https://your-control-plane.truefoundry.cloud/api/llm"
```

Verify your Langfuse connection:

```python
from langfuse import get_client

# Test Langfuse authentication
get_client().auth_check()
```

### Step 3: Configure Langfuse OpenAI Drop-in Replacement

First, get the base URL and model name from your TrueFoundry AI Gateway:

1. **Navigate to AI Gateway Playground**: Go to your TrueFoundry AI Gateway playground
2. **Access Unified Code Snippet**: Use the Langchain library code snippet
3. **Copy Base URL**: You will get the base path from the unified code snippet
4. **Copy model name**: You will get the model name from the same code snippet (ensure you use the same model name as written)

<Frame caption="Get Base URL from Unified Code Snippet">
  <img src="/images/unified-code-tfy.png" />
</Frame>

Use Langfuse's OpenAI-compatible client to automatically trace all requests sent through TrueFoundry's AI Gateway:

```python
from langfuse.openai import OpenAI
import os

# Initialize OpenAI client with TrueFoundry Gateway
client = OpenAI(
    api_key=os.environ["TRUEFOUNDRY_API_KEY"],
    base_url=os.environ["TRUEFOUNDRY_GATEWAY_BASE_URL"]  # Base URL from unified code snippet
)
```

### Step 4: Run an Example

Execute a sample request to test the integration:

```python
# Make a request through TrueFoundry Gateway with Langfuse tracing
response = client.chat.completions.create(
    model="openai-main/gpt-4o",  # Paste the model ID you copied from TrueFoundry Gateway
    messages=[
        {"role": "system", "content": "You are a helpful AI assistant specialized in explaining AI concepts."},
        {"role": "user", "content": "Why does an AI gateway help enterprises?"},
    ],
    max_tokens=500,
    temperature=0.7
)

print(response.choices[0].message.content)

# Ensure all traces are sent to Langfuse
langfuse = get_client()
langfuse.flush()
```

### Step 5: View Traces in Langfuse

After running your code, log in to your Langfuse dashboard to view detailed traces including:

- **Request Parameters**: Model, temperature, max tokens, and other configuration
- **Response Content**: Full response text and metadata  
- **Performance Metrics**: Token usage, latency, and cost information
- **Gateway Information**: TrueFoundry-specific routing and processing details

<Frame caption="Langfuse Trace Dashboard">
  <img src="/images/langfuse-trace-tfy.png" />
</Frame>

Your TrueFoundry AI Gateway is now fully integrated with Langfuse for comprehensive LLM observability and optimization.


## Advanced Integration with Langfuse Python SDK

Enhance your observability by combining the automatic tracing with additional Langfuse features.

### Using the @observe Decorator

The `@observe()` decorator automatically wraps your functions and adds custom attributes to traces:

```python
from langfuse import observe, get_client

langfuse = get_client()

@observe()
def analyze_customer_query(query, customer_id):
    """Analyze customer query using TrueFoundry Gateway with full observability"""
    
    response = client.chat.completions.create(
        model="openai-main/gpt-4o",
        messages=[
            {"role": "system", "content": "You are a customer service AI assistant."},
            {"role": "user", "content": query},
        ],
        temperature=0.3
    )
    
    result = response.choices[0].message.content
    
    # Add custom metadata to the trace
    langfuse.update_current_trace(
        input={"query": query, "customer_id": customer_id},
        output={"response": result},
        user_id=customer_id,
        session_id=f"session_{customer_id}",
        tags=["customer-service", "truefoundry-gateway"],
        metadata={
            "model_used": "openai-main/gpt-4o",
            "gateway": "truefoundry",
            "query_type": "customer_support"
        },
        version="1.0.0"
    )
    
    return result

# Usage
result = analyze_customer_query("How do I reset my password?", "customer_123")
```

> **Note**: All other features of Langfuse will work as expected, including prompt management, evaluations, custom dashboards, and advanced observability features. The TrueFoundry integration seamlessly supports the full Langfuse feature set.

## Learn More

- **TrueFoundry AI Gateway Introduction**: [https://docs.truefoundry.com/gateway/intro-to-llm-gateway](https://docs.truefoundry.com/gateway/intro-to-llm-gateway)
- **TrueFoundry Authentication Guide**: [https://docs.truefoundry.com/gateway/authentication](https://docs.truefoundry.com/gateway/authentication)
- **Langfuse OpenAI Integration**: [https://langfuse.com/docs/integrations/openai](https://langfuse.com/docs/integrations/openai)
- **Langfuse @observe() Decorator**: [https://langfuse.com/docs/sdk/python/decorators](https://langfuse.com/docs/sdk/python/decorators)
- **Langfuse Python SDK Guide**: [https://langfuse.com/docs/sdk/python](https://langfuse.com/docs/sdk/python) 

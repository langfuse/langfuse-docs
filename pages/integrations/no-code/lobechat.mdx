---
title: Observability and Tracing for LobeChat
description: "Monitor and trace your LobeChat conversations with Langfuse. Capture detailed traces, costs, and usage patterns for your open-source LLM chat platform."
sidebarTitle: LobeChat
logo: /images/integrations/lobechat_icon.png
---

# Langfuse Integration with LobeChat

## What is LobeChat?

[LobeChat](https://lobehub.com/) is an **[open-source](https://github.com/lobehub/lobe-chat) LLM chat platform** that provides a modern, feature-rich interface for interacting with large language models. It supports multiple AI models and providers, making it a popular choice for teams and individuals who want a self-hosted ChatGPT alternative.

Key features of LobeChat:
- **Multi-model support** — Connect to OpenAI, Anthropic, Google, Ollama, and many other LLM providers
- **Plugin ecosystem** — Extend capabilities with tools like web browsing, image generation, and file analysis
- **Knowledge base** — Upload documents for RAG-powered conversations
- **Multi-user support** — Deploy for teams with user management and authentication
- **Self-hostable** — Full control over your data with Docker-based deployment
- **Beautiful UI** — Modern, responsive chat interface with markdown rendering and code highlighting

## What is Langfuse?

[Langfuse](https://langfuse.com/) is one of the most used **open-source LLM Observability platforms**. By enabling the Langfuse integration, you can trace your application data with Langfuse to develop, monitor, and improve the use of LobeChat, including:

- Application [traces](/docs/observability/overview)
- Usage patterns
- Cost data by user and model
- [Evaluations](/docs/evaluation/overview)

## Get Started

<Steps>

### Set up Langfuse

Get your Langfuse API key by signing up for [Langfuse Cloud](https://cloud.langfuse.com) or [self-hosting](/self-hosting) Langfuse.

### Set up LobeChat

There are multiple ways to [self-host LobeChat](https://lobehub.com/docs/self-hosting/start). For this example, we will use the Docker Desktop deployment.

<Tabs items={["Environment Variables", "Example in Docker Desktop"]}>
<Tab>

Before deploying LobeChat, set the following four environment variables with the Langfuse API keys you created in the previous step.

```sh
ENABLE_LANGFUSE = '1'
LANGFUSE_SECRET_KEY = 'sk-lf...'
LANGFUSE_PUBLIC_KEY = 'pk-lf...'
LANGFUSE_HOST = 'https://cloud.langfuse.com'
```

</Tab>

<Tab>

Before running the Docker container, set the environment variables in the Docker Desktop with the Langfuse API keys you created in the previous step.

<Frame className="sm:w-1/2">
![Environment Variables in Docker Desktop](/images/docs/lobechat-docker-desktop-env.png)
</Frame>
</Tab>

</Tabs>

### Activate Analytics in Settings

Once you have LobeChat running, navigate to the **About** tab in the **Settings** and activate analytics. This is necessary for traces to be sent to Langfuse.

<Frame className="mt-5">
  ![LobeChat Settings](/images/docs/lobechat-settings.png)
</Frame>

### See your traces in Langfuse

After setting your LLM model key, you can start interacting with your LobeChat application.

<Frame className="mt-5">
  ![LobeChat Conversation](/images/docs/lobechat-converstation.png)
</Frame>

All conversations in the chat are automatically traced and sent to Langfuse. You can view the traces in the [Traces section](/docs/observability/overview) of the Langfuse platform.

<Frame className="mt-5">
  ![LobeChat Example Trace](/images/docs/lobechat-example-trace.png)
</Frame>
_[Example trace in the Langfuse UI](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/63e9246d-3f22-4e45-936d-b0c4ccf55a1e?timestamp=2024-11-26T17%3A00%3A02.028Z&observation=7ea75a0c-d9d1-425c-9b88-27561c63b413)_

</Steps>

## Feedback

If you have any feedback or requests, please create a GitHub [Issue](/issue) or share your work with the community on [Discord](https://discord.langfuse.com/).

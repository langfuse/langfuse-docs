---
title: Self-host Langfuse (Open Source LLM Observability)
description: Self-host Langfuse - This guide shows you how to deploy open-source LLM observability with Docker, Kubernetes, or VMs on your own infrastructure.
label: "Version: v3"
---

import { Callout } from "nextra/components";

# Self-host Langfuse

<Callout type="info">
  Looking for a managed solution? Consider [Langfuse
  Cloud](https://cloud.langfuse.com) maintained by the Langfuse team.
</Callout>

Langfuse is open source and can be self-hosted using Docker.
This section contains guides for different deployment scenarios.

When self-hosting Langfuse, you run the same infrastructure that powers Langfuse Cloud. Read ["Why Langfuse?"](/why) to learn more about why this is important to us.

## Deployment Options [#deployment-options]

### Langfuse Cloud

[Langfuse Cloud](https://cloud.langfuse.com) is a fully managed version of Langfuse that is hosted and maintained by the Langfuse team. Generally, it is the easiest and fastest way to get started with Langfuse at affordable [pricing](/pricing).

### Low-scale deployments

You can [run Langfuse on a VM or locally using Docker Compose](/self-hosting/docker-compose).
This is recommended for testing and low-scale deployments and lacks high-availability, scaling capabilities, and backup functionality.

### Production-scale deployments

For production and high-availability deployments, we recommend one of the following options:

- [Kubernetes (Helm)](/self-hosting/kubernetes-helm)
- [AWS (Terraform)](/self-hosting/aws)
- [Azure (Terraform)](/self-hosting/azure)
- [GCP (Terraform)](/self-hosting/gcp)
- [Railway](/self-hosting/railway)

## Architecture

Langfuse only depends on open source components and can be deployed locally, on cloud infrastructure, or on-premises.

import ArchitectureDiagram from "@/components-mdx/architecture-diagram-v3.mdx";

<ArchitectureDiagram />

import ArchitectureDescription from "@/components-mdx/architecture-description-v3.mdx";

<ArchitectureDescription />

## Optimized for performance, reliability, and uptime

Langfuse self-hosted is optimized for production environments. It is the exact same codebase as Langfuse Cloud, just deployed on your own infrastructure. The Langfuse teams serves thousands of teams with Langfuse Cloud with high availability ([status page](https://status.langfuse.com)) and performance.

Some of the optimizations include:

- **Queued trace ingestion**: All traces are received in batches by the Langfuse Web container and immediately written to S3. Only a reference is persisted in Redis for queueing. Afterwards, the Langfuse Worker will pick up the traces from S3 and ingest them into Clickhouse. This ensures that high spikes in request load do not lead to timeouts or errors constrained by the database.
- **Caching of API keys**: API keys are cached in-memory in Redis. Thereby, the database is not hit on every API call and unauthorized requests can be rejected with very low resource usage.
- **Caching of prompts (SDKs and API)**: Even though prompts are cached client-side by the Langfuse SDKs and only revalidated in the background ([docs](/docs/prompts)), they need to be fetched from the Langfuse on first use. Thus, API response times are very important. Prompts are cached in a read-through cache in Redis. Thereby, hot prompts can be fetched from Langfuse without hitting a database.
- **OLAP database**: All read-heavy analytical operations are offloaded to an OLAP database (Clickhouse) for fast query performance.
- **Multi-modal traces in S3**: Multi-modal traces can include large videos or arbitrary files. To enable support for these, they are directly uploaded to S3/Blob Storage from the client SDKs. Learn more [here](/docs/tracing-features/multi-modality).
- **Recoverability of events**: All incoming tracing and evaluation events are persisted in S3/Blob Storage first. Only after successful processing, the events are written to the database. This ensures that even if the database is temporarily unavailable, the events are not lost and can be processed later.
- **Background migrations**: Long-running migrations that are required by an upgrade but not blocking for regular operations are offloaded to a background job. This massively reduces the downtime during an upgrade. Learn more [here](/self-hosting/background-migrations).

If you have any feedback or questions regarding the architecture, please reach out to us.

## Features

Langfuse supports many configuration options and self-hosted features.
For more details, please refer to the [configuration guide](/self-hosting/configuration).

import SelfHostFeatures from "@/components-mdx/self-host-features.mdx";

<SelfHostFeatures />

## Subscribe to updates

import { ProductUpdateSignup } from "@/components/productUpdateSignup";

Release notes are published on [GitHub](https://github.com/langfuse/langfuse/releases). Langfuse uses tagged semver releases ([versioning policy](/self-hosting/versioning)).

You can subscribe to our mailing list to get notified about new releases and new major versions.

<ProductUpdateSignup source="self-host" className="mt-3 mb-3 max-w-sm" />

You can also watch the GitHub releases to get notified about new releases:

<Frame className="max-w-md block" border>
  ![Langfuse releases](/images/docs/github-watch-changelog.gif)
</Frame>

## Support

The Langfuse maintainers are dedicated to make self-hosting Langfuse as easy as possible.

If you encounter any issues, we recommend the following support options:

1. First, check this documentation and use the [Ask AI](/ask-ai) widget for quick answers
2. If you need additional help, create a support thread on [GitHub Discussions](/gh-support)
3. For enterprise deployments, we offer dedicated support through our enterprise team. Contact us at enterprise@langfuse.com or [schedule a call](/talk-to-us) to learn more

Alternatively, you may consider using [Langfuse Cloud](/docs/deployment/cloud), which is a fully managed version of Langfuse. You can find information about its security and privacy [here](/security).

## FAQ

import { FaqPreview } from "@/components/faq/FaqPreview";

<FaqPreview tags={["self-hosting"]} />

## GitHub Discussions

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["self-hosting"]} />

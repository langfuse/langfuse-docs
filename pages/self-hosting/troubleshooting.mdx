---
title: Troubleshooting a self-hosted Langfuse deployment
description: Learn how to troubleshoot common issues with self-hosted Langfuse.
label: "Version: v3"
---

# Troubleshooting

This guide covers common issues that Langfuse self-hosters observe and how to address them. If you encounter an issue that is not covered here, please [open a GitHub issue](https://github.com/langfuse/langfuse/issues) or reach out to [support](/support).

## Missing Events After POST /api/public/ingestion

If you are not seeing events within minutes of posting them to `/api/public/ingestion`, it is likely that the events are not being ingested correctly.
Events do not appear immediately in the UI, as they are being processed asynchronously.
If your events are not shown after a few minutes, you can check the following:

- **Check the Langfuse Web logs**: Look for any errors in the Langfuse Web container around the time that you ingested the events.
  Any errors you observe indicate that the event is malformatted or that either [Redis](/self-hosting/infrastructure/cache) or [S3](/self-hosting/infrastructure/blobstorage) are not available.
  In this case, you should also see non-207 status codes within your application.
- **Check the S3/Blob Storage bucket**: Validate that the event was uploaded correctly into your blob storage.
  It should be available in a path like `/<projectId>/<type>/<eventId>/<randomId>.json`.
  If the event was accepted in the Langfuse Web container, but is not available in S3, it indicates an issue with your S3 configuration.
- **Check the Langfuse Worker logs**: Look for any errors in the Langfuse Worker container about within 0-60 seconds of ingesting your event.
  If no events at all are being processed, it usually indicates a configuration issue around Redis or S3.
- **Check ClickHouse tables**: If the previous processing looks correct, validate whether you can find the event in ClickHouse in the `traces`, `observations`, or `scores` table.
  Search for the respective `projectId` and `eventId`.
  If you cannot find the event in ClickHouse, but the worker indicates it was processed or if you can find it in ClickHouse and it is not returned via the API, please [open an issue](https://github.com/langfuse/langfuse/issues).

## Intermittent 502 and 504 network errors

If you are experiencing intermittent 502 and 504 network errors, this is likely related to your Loadbalancer and keep-alive configuration.
It is recommended to have the keep-alive of a server set to a higher value than the idle timeout on a Loadbalancer.

As an example, the AWS Application Loadbalancer has a default idle timeout of 60 seconds.
If your service closes a connection after 45 seconds, the Loadbalancer will attempt to reuse the connection which it still believes to be alive which will result in a 502 error.

Hence, we recommend that you configure `KEEP_ALIVE_TIMEOUT` on the Langfuse Web container to be at least 5 seconds higher than your Loadbalancer idle timeout.

## JavaScript heap out of memory

If you are experiencing JavaScript heap out of memory errors within your applications, it indicates that the application thinks it has less memory available than it does.
An example case is that your container has 2 GiB of memory, whereas the Node.js application uses the default max-old-space-size of 1.7 GiB.
This would surface as an error message like

> FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory

To address this issue, we recommend that you configure `NODE_OPTIONS=--max-old-space-size=${var.memory}` on the Langfuse Web and the Langfuse Worker containers.
Use the available memory in MiB as the value for `var.memory`, e.g. 4096 for 4 GiB of memory.
The value should be equal or above the memory limit of the container.
This ensures that your container orchestrator kills the pod gracefully if the memory limit is exceeded, instead of the application terminating abruptly.

## Socket usage at capacity

If you are experiencing socket usage at capacity errors, it indicates that the Langfuse Web container is not able to open new connections.
You can either increase the number of langfuse-web containers handling requests or increase the number of available sockets.
To achieve the latter, set `LANGFUSE_S3_CONCURRENT_WRITES` to a value greater than `50`.
Note that an increased number of sockets may increase the memory consumption of your container.

## Timezone Errors

Langfuse is engineered to run in the UTC timezone and expects that all infrastructure components default to UTC.
Especially Postgres and ClickHouse settings that overwrite the UTC default are not supported and may lead to unexpected behavior.
If you would like us to consider supporting other timezones, please vote on this [GitHub Discussion](https://github.com/orgs/langfuse/discussions/5046).

## PostgreSQL: Table Ownership and Migration Failures

If you encounter permission errors during PostgreSQL migrations like the following, it typically occurs when the database user running migrations has changed,
as new users won't own existing tables and therefore cannot modify them.

```
DbError { severity: "ERROR", code: SqlState(E42501), message: "permission denied for table projects" }
```

You can verify mixed ownership by checking table owners:

```sql
\dt public.*
```

### Solutions

**Option 1: Transfer table ownership**

```sql
-- Replace 'new_user' with your current migration user
ALTER TABLE table_name OWNER TO new_user;
```

**Option 2: Use dedicated migration user**

Set the `DIRECT_URL` environment variable to use a superuser or table owner specifically for migrations:

```bash
DIRECT_URL=postgresql://migration_user:password@host:port/database
```

This allows Prisma to use different credentials for migrations while keeping your regular `DATABASE_URL` for application operations.

## Clickhouse: Handling Failed Migrations

If you encounter a migration error, the migration tool will prevent you from running additional migrations on the same database. You'll see an error message like "Dirty database version 1. Fix and force version" even after fixing the erred migration. This means your database has been marked as 'dirty'. You need to investigate whether the migration was partially applied or not applied at all. After determining the actual state, force your database to the version that accurately reflects its current state. Once you've forced the correct version and fixed the migration, your database will be 'clean' again, allowing you to proceed with subsequent migrations.

<details>
<summary>Code Example to fix failed migrations</summary>

Let's assume your migration 16 failed. You have corrected the failed migration. If you try to migrate again, migrate will STILL refuse:

```bash
error: Dirty database version 16. Fix and force version.
```

You will have to force your database to the last successful version, which is 15. Make sure to replace the database credentials with your own.
Before running the command below, make sure you have golang-migrate installed. If you do not, please follow the guide linked in our [contributing guide](https://github.com/langfuse/langfuse/blob/main/CONTRIBUTING.md#development-setup). Then, navigate to the root of your Langfuse project folder in your terminal. Then run the following command:

```bash
migrate -path migrations/ -database clickhouse://test:test@localhost:8123/dummy force 15
```

If you migrate again, the output will now be:

```bash
16/u migration_name (12.718637ms)
```

</details>

## Queue Management with BullMQ Admin API

Langfuse uses BullMQ for managing background job queues. The BullMQ admin endpoint allows you to monitor queue lengths, replay failed events, and remove unwanted events from the queue. This is particularly useful for troubleshooting event processing issues and managing queue backlogs.

<Callout type="warning">
  This API is meant for administrative purpose by instance owners and may change at any point in time.
  We recommend not to develop against this API or build significant logic around it.
</Callout>

### Authentication Setup

<Steps>

  ### Configure an `ADMIN_API_KEY`

  Configure an `ADMIN_API_KEY` in your environment configuration:

  ```bash filename="Environment"
  ADMIN_API_KEY=your-admin-api-key
  ```

  ### Authenticate with the API

  Then, authenticate with the API by setting the Authorization header:

  ```bash
  Authorization: Bearer $ADMIN_API_KEY
  ```
</Steps>

### Monitoring Queue Lengths

To check the current status and job counts across all queues, make a GET request to the admin endpoint:

```bash
curl -X GET "https://your-langfuse-instance.com/api/admin/bullmq" \
  -H "Authorization: Bearer YOUR_ADMIN_API_KEY"
  -H 'Content-Type: application/json' \
  --data '{
    "action": "retry",
    "queueNames": [ ]
}'
```

This will return job counts for all queues, helping you identify bottlenecks or failed jobs that need attention.
The content-type and payload is required, but not evaluated within the request.

### Replaying Failed Events

To retry failed jobs in specific queues, use the POST endpoint with the `retry` action:

```bash
curl -X POST "https://your-langfuse-instance.com/api/admin/bullmq" \
  -H "Authorization: Bearer YOUR_ADMIN_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "action": "retry",
    "queueNames": ["ingestion-queue", "evaluation-queue"]
  }'
```

### Removing Events from Queue

To remove jobs with a specific status from queues, use the POST endpoint with the `remove` action:

```bash
curl -X POST "https://your-langfuse-instance.com/api/admin/bullmq" \
  -H "Authorization: Bearer YOUR_ADMIN_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "action": "remove",
    "queueNames": ["ingestion-queue"],
    "bullStatus": "failed"
  }'
```

Available status options: `completed`, `failed`, `active`, `delayed`, `prioritized`, `paused`, `wait`.

### API Specification

<details>
  <summary>Complete BullMQ Admin API Specification</summary>

  ```yaml
  openapi: 3.0.1
  info:
    title: Langfuse Admin BullMQ API
    description: API for managing BullMQ jobs in Langfuse
    version: '1.0.0'
  paths:
    /api/admin/bullmq:
      get:
        summary: Get job counts for all queues
        operationId: bullmq_getCounts
        tags:
          - BullMQ
        responses:
          '200':
            description: Job counts for all queues
            content:
              application/json:
                schema:
                  type: array
                  items:
                    type: object
                    properties:
                      queueName:
                        type: string
                      jobCount:
                        type: object
                        additionalProperties:
                          type: number
      post:
        summary: Manage BullMQ jobs
        operationId: bullmq_manageJobs
        tags:
          - BullMQ
        requestBody:
          required: true
          content:
            application/json:
              schema:
                oneOf:
                  - type: object
                    required:
                      - action
                      - queueNames
                    properties:
                      action:
                        type: string
                        enum: [retry]
                      queueNames:
                        type: array
                        items:
                          type: string
                  - type: object
                    required:
                      - action
                      - queueNames
                      - bullStatus
                    properties:
                      action:
                        type: string
                        enum: [remove]
                      queueNames:
                        type: array
                        items:
                          type: string
                      bullStatus:
                        type: string
                        enum: [completed, failed, active, delayed, prioritized, paused, wait]
        responses:
          '200':
            description: Jobs successfully managed
            content:
              application/json:
                schema:
                  type: object
                  properties:
                    message:
                      type: string
  ```

</details>


## FAQ

import { FaqPreview } from "@/components/faq/FaqPreview";

<FaqPreview tags={["self-hosting"]} />

## GitHub Discussions

import { GhDiscussionsPreview } from "@/components/gh-discussions/GhDiscussionsPreview";

<GhDiscussionsPreview labels={["self-hosting"]} />

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlceIPalN3QR"
      },
      "source": [
        "---\n",
        "description: Langchain users can integrated with Langfuse in seconds using the integration\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqBspBzuRk9C"
      },
      "source": [
        "# Langchain integration (Python)\n",
        "\n",
        "- [View as notebook on GitHub](https://github.com/langfuse/langfuse-docs/blob/main/src/ipynb/langfuse_docs_langchain_integration_python.ipynb)\n",
        "- [Open as notebook in Google Colab](http://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/src/ipynb/langfuse_docs_langchain_integration_python.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05afP0VbYHX0"
      },
      "source": [
        "Langfuse integrates with Langchain using the [Langchain Callbacks](https://python.langchain.com/docs/modules/callbacks/). Thereby, the Langfuse SDK automatically creates a nested trace for the abstractions offered by Langchain.\n",
        "\n",
        "Add the handler as a callback when running your Langchain model/chain/agent:\n",
        "\n",
        "```python /callbacks=[handler]/\n",
        "# Initialize Langfuse handler\n",
        "from langfuse.callback import CallbackHandler\n",
        "handler = CallbackHandler(PUBLIC_KEY, SECRET_KEY)\n",
        "\n",
        "# Setup Langchain\n",
        "from langchain.chains import LLMChain\n",
        "...\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Add Langfuse handler as callback\n",
        "chain.run(input=\"<user_input\", callbacks=[handler])\n",
        "```\n",
        "\n",
        "---\n",
        " **_NOTE:_**\n",
        "When integrating callbacks, there are two main ways:\n",
        "- *Constructor Callbacks*: Set when initializing an object, like <code>LLMChain(callbacks=[handler])</code>. This approach will use the callback for every call made on that specific object. However, it won't apply to its child objects, making it limited in scope.\n",
        "- *Request Callbacks*: Defined when issuing a request, like <code>chain.run(input, callbacks=[handler])</code>. This not only uses the callback for that specific request but also for any subsequent sub-requests it triggers.\n",
        "\n",
        "For comprehensive data capture across objects, it's advised to use the request-based approach, as demonstrated above. Refer to the [Langchain callbacks documentation](https://python.langchain.com/docs/modules/callbacks/#where-to-pass-in-callbacks) for more details.\n",
        "\n",
        "---\n",
        "\n",
        "The Langfuse `CallbackHandler` tracks the following actions when using Langchain:\n",
        "\n",
        "- Chains: `on_chain_start`, `on_chain_end`. `on_chain_error`\n",
        "- Agents: `on_agent_start`, `on_agent_action`, `on_agent_finish`, `on_agent_end`\n",
        "- Tools: `on_tool_start`, `on_tool_end`, `on_tool_error`\n",
        "- Retriever: `on_retriever_start`, `on_retriever_end`\n",
        "- ChatModel: `on_chat_model_start`,\n",
        "- LLM: `on_llm_start`, `on_llm_end`, `on_llm_error`\n",
        "\n",
        "Missing some useful information/context in Langfuse? Join the [Discord](/discord) or share your feedback directly with us: feedback@langfuse.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq3SJ-XHN3QT"
      },
      "source": [
        "## Notebook Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbSpd5EiZouE"
      },
      "source": [
        "### 1. Initializing the Langfuse Callback handler\n",
        "\n",
        "The Langfuse SDKs are hosted on the pypi index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNyU6IzCZouE"
      },
      "outputs": [],
      "source": [
        "%pip install langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpE57ujJZouE"
      },
      "source": [
        "Initialize the client with api keys and optionally your environment. In the example we are using the cloud environment which is also the default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEdF-668ZouF"
      },
      "outputs": [],
      "source": [
        "ENV_HOST = \"https://cloud.langfuse.com\"\n",
        "ENV_SECRET_KEY = \"sk-lf-...\"\n",
        "ENV_PUBLIC_KEY = \"pk-lf-...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "divRadPqZouF"
      },
      "outputs": [],
      "source": [
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzsO2Ci4EjJS"
      },
      "source": [
        "### 2. Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R66lMkgabfLN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGLLnTWsbevn"
      },
      "outputs": [],
      "source": [
        "%pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9u5QMVCbPtR"
      },
      "outputs": [],
      "source": [
        "# further imports\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langfuse.callback import CallbackHandler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAW-Gt4mN3QV"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUenj0aca9qo"
      },
      "source": [
        "### 1. Sequential Chain\n",
        "\n",
        "![Trace of Langchain Sequential Chain in Langfuse](https://langfuse.com/images/docs/langchain_chain.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTagwV_cbFVr"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
        "    Title: {title}\n",
        "    Playwright: This is a synopsis for the above play:\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
        "\n",
        "    Play Synopsis:\n",
        "    {synopsis}\n",
        "    Review from a New York Times play critic of the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[synopsis_chain, review_chain],\n",
        ")\n",
        "review = overall_chain.run(\"Tragedy at sunset on the beach\", callbacks=[handler]) # add the handler to the run method\n",
        "handler.langfuse.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5avhNb3TBH"
      },
      "source": [
        "### 2. QA Retrieval\n",
        "\n",
        "![Trace of Langchain QA Retrieval in Langfuse](https://langfuse.com/images/docs/langchain_qa_retrieval.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjiWEkRUFzCf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"SERPAPI_API_KEY\"] = '...'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0CgEPSlEpkC"
      },
      "outputs": [],
      "source": [
        "%pip install unstructured chromadb tiktoken google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHDVa-Ssb-KT"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/langfuse/langfuse-docs/main/public/state_of_the_union.txt\",\n",
        "]\n",
        "\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "\n",
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "docsearch = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 1}),\n",
        ")\n",
        "\n",
        "result = chain.run(query, callbacks=[handler])\n",
        "\n",
        "print(result)\n",
        "\n",
        "handler.langfuse.flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCmI0I20-sbI"
      },
      "source": [
        "\n",
        "\n",
        "![Trace of Langchain Agent in Langfuse](https://langfuse.com/images/docs/langchain_agent.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReaHdQOT-S3n"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)\n",
        "\n",
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "result = agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\", callbacks=[handler])\n",
        "\n",
        "handler.langfuse.flush()\n",
        "\n",
        "print(\"output variable: \", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxQlUOmVPEwz"
      },
      "source": [
        "## Adding scores\n",
        "\n",
        "To add [scores](/docs/scores) to traces created with the Langchain integration, access the traceId via `handler.get_trace_id()`\n",
        "\n",
        "\n",
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PudCopwEPFgh"
      },
      "outputs": [],
      "source": [
        "from langfuse import Langfuse\n",
        "from langfuse.model import CreateScore\n",
        "from langfuse.model import CreateScoreRequest\n",
        "\n",
        "\n",
        "# Trace langchain run via the Langfuse CallbackHandler as shown above\n",
        "\n",
        "# Get id of created trace\n",
        "traceId = handler.get_trace_id()\n",
        "\n",
        "# Add score, e.g. via the Python SDK\n",
        "langfuse = Langfuse(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)\n",
        "trace = langfuse.score(\n",
        "    CreateScoreRequest(\n",
        "        traceId=traceId,\n",
        "        name=\"user-explicit-feedback\",\n",
        "        value=1,\n",
        "        comment=\"I like how personalized the response is\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEWWS8PGo4A1"
      },
      "source": [
        "## Adding trace as context to a Langchain handler\n",
        "\n",
        "It is also possible to generate a Langchain handler based on a trace. This can help to add context such as a specific `id` or `metadata`. All the Langchain observations will be collected on that trace.\n",
        "\n",
        "To do that, we first need to initialise the [Python SDK](/docs/integrations/sdk/python), create a `trace`, and finally create the handler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXDUkqbfqDim"
      },
      "outputs": [],
      "source": [
        "%pip install uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sBgSeuMp5o4"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "import os\n",
        "\n",
        "from langfuse.client import Langfuse\n",
        "from langfuse.model import CreateTrace\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "langfuse = Langfuse(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)\n",
        "\n",
        "trace_id = str(uuid.uuid4())\n",
        "trace = langfuse.trace(CreateTrace(id=trace_id))\n",
        "\n",
        "handler = trace.getNewHandler()\n",
        "\n",
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
        "    Title: {title}\n",
        "    Playwright: This is a synopsis for the above play:\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "synopsis_chain.run(\"Tragedy at sunset on the beach\", callbacks=[handler])\n",
        "\n",
        "langfuse.flush()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqBspBzuRk9C"
      },
      "source": [
        "# Langchain integration (Python)\n",
        "\n",
        "- [View as notebook on GitHub](https://github.com/langfuse/langfuse-docs/blob/main/src/ipynb/langfuse_docs_langchain_integration_python.ipynb)\n",
        "- [Open as notebook in Google Colab](http://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/src/ipynb/langfuse_docs_langchain_integration_python.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05afP0VbYHX0"
      },
      "source": [
        "Langfuse integrates with Langchain using the [Langchain Callbacks](https://python.langchain.com/docs/modules/callbacks/). Thereby, the Langfuse SDK automatically creates a nested trace for the abstractions offered by Langchain.\n",
        "\n",
        "Add the handler as a callback when running your Langchain model/chain/agent:\n",
        "\n",
        "```python /callbacks=[handler]/\n",
        "# Initialize Langfuse handler\n",
        "from langfuse.callback import CallbackHandler\n",
        "handler = CallbackHandler(PUBLIC_KEY, SECRET_KEY)\n",
        " \n",
        "# Setup Langchain\n",
        "from langchain.chains import LLMChain\n",
        "...\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        " \n",
        "# Add Langfuse handler as callback\n",
        "chain.run(input=\"<user_input\", callbacks=[handler])\n",
        "```\n",
        "\n",
        "The Langfuse `CallbackHandler` tracks the following actions when using Langchain:\n",
        "\n",
        "- Chains: `on_chain_start`, `on_chain_end`. `on_chain_error`\n",
        "- Agents: `on_agent_start`, `on_agent_action`, `on_agent_finish`, `on_agent_end`\n",
        "- Tools: `on_tool_start`, `on_tool_end`, `on_tool_error`\n",
        "- Retriever: `on_retriever_start`, `on_retriever_end`\n",
        "- ChatModel: `on_chat_model_start`,\n",
        "- LLM: `on_llm_start`, `on_llm_end`, `on_llm_error`\n",
        "\n",
        "Missing some useful information/context in Langfuse? Join the [Discord](https://discord.gg/7NXusRtqYU) or share your feedback directly with us: feedback@langfuse.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbSpd5EiZouE"
      },
      "source": [
        "### 1. Initializing the Langfuse Callback handler\n",
        "\n",
        "The Langfuse SDKs are hosted on the pypi index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNyU6IzCZouE",
        "outputId": "f68a7ebc-40b0-4d0a-8593-117f32f65d30"
      },
      "outputs": [],
      "source": [
        "%pip install langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpE57ujJZouE"
      },
      "source": [
        "Initialize the client with api keys and optionally your environment. In the example we are using the cloud environment which is also the default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEdF-668ZouF"
      },
      "outputs": [],
      "source": [
        "ENV_HOST = \"https://cloud.langfuse.com\"\n",
        "ENV_SECRET_KEY = \"sk-lf-...\"\n",
        "ENV_PUBLIC_KEY = \"pk-lf-...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "divRadPqZouF"
      },
      "outputs": [],
      "source": [
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzsO2Ci4EjJS"
      },
      "source": [
        "### 2. Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R66lMkgabfLN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-...'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGLLnTWsbevn",
        "outputId": "fba42847-fa84-4059-ef7f-7b4fa162ed23"
      },
      "outputs": [],
      "source": [
        "%pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L9u5QMVCbPtR"
      },
      "outputs": [],
      "source": [
        "# further imports\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langfuse.callback import CallbackHandler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUenj0aca9qo"
      },
      "source": [
        "### 1. Sequential Chain\n",
        "\n",
        "![Trace of Langchain Sequential Chain in Langfuse](https://langfuse.com/images/docs/langchain_chain.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTagwV_cbFVr",
        "outputId": "215fdc36-2ed9-4cc2-d22e-44188469d5ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'success'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
        "    Title: {title}\n",
        "    Playwright: This is a synopsis for the above play:\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
        "\n",
        "    Play Synopsis:\n",
        "    {synopsis}\n",
        "    Review from a New York Times play critic of the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[synopsis_chain, review_chain],\n",
        ")\n",
        "review = overall_chain.run(\"Tragedy at sunset on the beach\", callbacks=[handler]) # add the handler to the run method\n",
        "await handler.langfuse.async_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5avhNb3TBH"
      },
      "source": [
        "### 2. QA Retrieval\n",
        "\n",
        "![Trace of Langchain QA Retrieval in Langfuse](https://langfuse.com/images/docs/langchain_qa_retrieval.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wjiWEkRUFzCf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"SERPAPI_API_KEY\"] = '...'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p0CgEPSlEpkC",
        "outputId": "fd2f2a93-888d-4e02-e479-220ef5abe366"
      },
      "outputs": [],
      "source": [
        "%pip install unstructured chromadb tiktoken google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHDVa-Ssb-KT",
        "outputId": "fca9e58a-6a05-4d98-fe8e-aac77bb46cf0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The president said that Ketanji Brown Jackson is one of our nation's top legal minds and will continue Justice Breyer's legacy of excellence.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'status': 'success'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/langfuse/langfuse-docs/main/public/state_of_the_union.txt\",\n",
        "]\n",
        "\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "\n",
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "docsearch = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 1}),\n",
        ")\n",
        "\n",
        "result = chain.run(query, callbacks=[handler])\n",
        "\n",
        "print(result)\n",
        "\n",
        "await handler.langfuse.async_flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCmI0I20-sbI"
      },
      "source": [
        "### 3. Agent\n",
        "\n",
        "![Trace of Langchain Agent in Langfuse](https://langfuse.com/images/docs/langchain_agent.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReaHdQOT-S3n",
        "outputId": "05af8e5a-1229-4cbe-9efe-5ca78097371d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out who the girlfriend is and then use a calculator to calculate the age raised to the 0.43 power.\n",
            "Action: Search\n",
            "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe actor is believed to have recently split from his girlfriend of five years, actor Camila Morrone, but has previously been romantically ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out how old Camila Morrone is.\n",
            "Action: Search\n",
            "Action Input: \"Camila Morrone age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m26 years\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to use the calculator to calculate 26 raised to the 0.43 power.\n",
            "Action: Calculator\n",
            "Action Input: 26^0.43\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 4.059182145592686\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Leo DiCaprio's girlfriend is Camila Morrone, who is 26 years old and her age raised to the 0.43 power is 4.059182145592686.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "output variable:  Leo DiCaprio's girlfriend is Camila Morrone, who is 26 years old and her age raised to the 0.43 power is 4.059182145592686.\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)\n",
        "\n",
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "result = agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\", callbacks=[handler])\n",
        "\n",
        "await handler.langfuse.async_flush()\n",
        "\n",
        "print(\"output variable: \", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgtTX-Vd_Ac-"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter any issue, we are happy to help on [Discord](https://discord.gg/7NXusRtqYU) or shoot us an email: help@langfuse.com"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

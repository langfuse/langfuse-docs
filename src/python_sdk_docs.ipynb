{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqBspBzuRk9C"
      },
      "source": [
        "# Python SDK\n",
        "\n",
        "- [View as notebook on GitHub](https://github.com/langfuse/langfuse-docs/blob/main/src/python_sdk_docs.ipynb)\n",
        "- [Open as notebook in Google Colab](http://colab.research.google.com/github/langfuse/langfuse-docs/blob/main/src/python_sdk_docs.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating Langfuse\n",
        "Most people write all the LLM chains and agents themselves. This section explains, how you can report LLM data to Langfuse while owning the APIs to your infrastructure such as LLM providers or databases. Below, you can explore how to integrate Langfuse with Langchain."
      ],
      "metadata": {
        "id": "qL7HhNyIYNwn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc6Uxbl3R5El"
      },
      "source": [
        "## 1. Initializing the client\n",
        "\n",
        "The Langfuse SDKs are hosted on the pypi index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F21wZSUyKLzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bc2595-1015-4897-e5c4-7f51ebbf7363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langfuse\n",
            "  Downloading langfuse-0.0.52-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from langfuse) (23.1.0)\n",
            "Collecting httpx<0.25.0,>=0.15.4 (from langfuse)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain<0.0.238,>=0.0.237 (from langfuse)\n",
            "  Downloading langchain-0.0.237-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.7 (from langfuse)\n",
            "  Downloading pydantic-1.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from langfuse) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.7->langfuse) (4.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.15.4->langfuse) (2023.5.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx<0.25.0,>=0.15.4->langfuse)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.15.4->langfuse) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.15.4->langfuse) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain<0.0.238,>=0.0.237->langfuse)\n",
            "  Downloading dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.0.11,>=0.0.10 (from langchain<0.0.238,>=0.0.237->langfuse)\n",
            "  Downloading langsmith-0.0.10-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain<0.0.238,>=0.0.237->langfuse)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (8.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.0->langfuse) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.238,>=0.0.237->langfuse)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.238,>=0.0.237->langfuse)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.15.4->langfuse)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.15.4->langfuse) (3.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.0.238,>=0.0.237->langfuse) (1.26.16)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.0.238,>=0.0.237->langfuse) (2.0.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.15.4->langfuse) (1.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.238,>=0.0.237->langfuse) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.238,>=0.0.237->langfuse)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: pydantic, mypy-extensions, marshmallow, h11, typing-inspect, openapi-schema-pydantic, langsmith, httpcore, httpx, dataclasses-json, langchain, langfuse\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.11\n",
            "    Uninstalling pydantic-1.10.11:\n",
            "      Successfully uninstalled pydantic-1.10.11\n",
            "Successfully installed dataclasses-json-0.5.13 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 langchain-0.0.237 langfuse-0.0.52 langsmith-0.0.10 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 pydantic-1.10.7 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAupsw1pR_6q"
      },
      "source": [
        "Initialize the client with api keys and optionally your environment. In the example we are using the cloud environment which is also the default. The Python client can modify all entities in the Langfuse API and therefore requires the secret key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iDfYwZf4KUnY"
      },
      "outputs": [],
      "source": [
        "ENV_HOST = \"https://cloud.langfuse.com\"\n",
        "ENV_SECRET_KEY = \"sk-lf-...\"\n",
        "ENV_PUBLIC_KEY = \"pk-lf-...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PuPgkTU476y4"
      },
      "outputs": [],
      "source": [
        "from langfuse import Langfuse\n",
        "\n",
        "langfuse = Langfuse(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT4uaBm4SLvw"
      },
      "source": [
        "## 2. Trace execution of backend\n",
        "\n",
        "- Each backend execution is logged with a single `trace`.\n",
        "- Each trace can contain multiple `observations` to log the individual steps of the execution.\n",
        "  - Observations can be nested.\n",
        "  - Observations can be of different types\n",
        "    - `Events` are the basic building block. They are used to track discrete events in a trace.\n",
        "    - `Spans` represent durations of units of work in a trace.\n",
        "    - `Generations` are spans which are used to log generations of AI model. They contain additional metadata about the model and the prompt/completion and are specifically rendered in the langfuse UI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GjVFk7N9jZr"
      },
      "source": [
        "### Traces\n",
        "\n",
        "Traces are the top-level entity in the Langfuse API. They represent an execution flow in a LLM application usually triggered by an external event.\n",
        "\n",
        "Traces can be created and updated.\n",
        "\n",
        "`trace.create()` takes the following parameters:\n",
        "\n",
        "- `name` (optional): identifier of the trace. Useful for sorting/filtering in the UI.\n",
        "- `metadata` (optional): additional metadata of the trace. Can be any JSON object.\n",
        "- `externalId` (optional): the id of the execution in the external system. Useful for linking traces to external systems. Frequently used to create scores without having access to the Langfuse `traceId`.\n",
        "- `userId` (optional): the id of the user who triggered the execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z9Kxxjp004WD"
      },
      "outputs": [],
      "source": [
        "from langfuse.api.model import CreateTrace\n",
        "\n",
        "trace = langfuse.trace(CreateTrace(\n",
        "    name = \"docs-retrieval\",\n",
        "    userId = \"user__935d7d1d-8625-4ef4-8651-544613e7bd22\",\n",
        "    metadata = {\n",
        "        \"env\": \"production\",\n",
        "        \"email\": \"user@langfuse.com\",\n",
        "    }\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtWxwt3H90qF"
      },
      "source": [
        "### Span\n",
        "\n",
        "Spans represent durations of units of work in a trace. We generated convenient SDK functions for generic spans as well as LLM spans.\n",
        "\n",
        "`span.create()` take the following parameters:\n",
        "\n",
        "- `startTime` (optional): the time at which the span started. If no startTime is provided, the current time will be used.\n",
        "- `endTime` (optional): the time at which the span ended. Can also be set using `span.update()`.\n",
        "- `name` (optional): identifier of the span. Useful for sorting/filtering in the UI.\n",
        "- `metadata` (optional): additional metadata of the span. Can be any JSON object. Can also be set or updated using `span.update()`.\n",
        "- `level` (optional): the level of the event. Can be `DEBUG`, `DEFAULT`, `WARNING` or `ERROR`. Used for sorting/filtering of traces with elevated error levels and for highlighting in the UI.\n",
        "- `statusMessage` (optional): the status message of the event. Additional field for context of the event. E.g. the error message of an error event.\n",
        "- `input` (optional): the input to the span. Can be any JSON object.\n",
        "- `output` (optional): the output to the span. Can be any JSON object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "otJQPNC198Ti"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from langfuse.api.model import CreateSpan\n",
        "\n",
        "retrievalStartTime = datetime.datetime.now()\n",
        "\n",
        "# retrieveDocs = retrieveDoc()\n",
        "# ...\n",
        "\n",
        "span = trace.span(CreateSpan(\n",
        "        name=\"embedding-search\",\n",
        "        startTime=retrievalStartTime,\n",
        "        endTime=datetime.datetime.now(),\n",
        "        metadata={\"database\": \"pinecone\"},\n",
        "        input = {'query': 'This document entails the OKR goals for ACME'},\n",
        "        output = {\"response\": \"[{'name': 'OKR Engineering', 'content': 'The engineering department defined the following OKR goals...'},{'name': 'OKR Marketing', 'content': 'The marketing department defined the following OKR goals...'}]\"}\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNPQH8Nz-duo"
      },
      "source": [
        "### Generation\n",
        "\n",
        "Generations are used to log generations of AI model. They contain additional metadata about the model and the prompt/completion and are specifically rendered in the langfuse UI.\n",
        "\n",
        "`generation.log()` take the following parameters:\n",
        "\n",
        "- `startTime` (optional): the time at which the generation started.\n",
        "- `endTime` (optional): the time at which the generation ended.\n",
        "- `name` (optional): identifier of the generation. Useful for sorting/filtering in the UI.\n",
        "- `model` (optional): the name of the model used for the generation\n",
        "- `modelParameters` (optional): the parameters of the model used for the generation; can be any key-value pairs\n",
        "- `prompt` (optional): the prompt used for the generation; can be any string or JSON object (recommended for chat models or other models that use structured input)\n",
        "- `completion` (optional): the completion generated by the model\n",
        "- `usage` (optional): the usage of the model during the generation; takes two optional key-value pairs: `promptTokens` and `completionTokens`\n",
        "- `metadata` (optional): additional metadata of the generation. Can be any JSON object.\n",
        "- `level` (optional): the level of the event. Can be `DEBUG`, `DEFAULT`, `WARNING` or `ERROR`. Used for sorting/filtering of traces with elevated error levels and for highlighting in the UI.\n",
        "- `statusMessage` (optional): the status message of the event. Additional field for context of the event. E.g. the error message of an error event."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nJfTbXvNQ6iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ed1055-238b-4967-acee-ce026a53aa5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langfuse.client.StatefulGenerationClient at 0x7f5b914d52a0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from langfuse.api.model import CreateGeneration, Usage\n",
        "import datetime\n",
        "\n",
        "generationStartTime = datetime.datetime.now()\n",
        "\n",
        "# chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world\"}])\n",
        "# ...\n",
        "\n",
        "trace.generation(CreateGeneration(\n",
        "    name=\"summary-generation\",\n",
        "    startTime=generationStartTime,\n",
        "    endTime=datetime.datetime.now(),\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    modelParameters={\"maxTokens\": \"1000\", \"temperature\": \"0.9\"},\n",
        "    prompt=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Please generate a summary of the following documents \\nThe engineering department defined the following OKR goals...\\nThe marketing department defined the following OKR goals...\"}],\n",
        "    completion=\"The Q3 OKRs contain goals for multiple teams...\",\n",
        "    usage=Usage(promptTokens=50, completionTokens = 49),\n",
        "    metadata={\"interface\": \"whatsapp\"}\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfzAYslz9Aks"
      },
      "source": [
        "### Events\n",
        "\n",
        "Events are used to track discrete events in a trace.\n",
        "\n",
        "- `startTime`: the time at which the event started.\n",
        "- `name` (optional): identifier of the event. Useful for sorting/filtering in the UI.\n",
        "- `metadata` (optional): additional metadata of the event. JSON object.\n",
        "- `level` (optional): the level of the event. Can be `DEBUG`, `DEFAULT`, `WARNING` or `ERROR`. Used for sorting/filtering of traces with elevated error levels and for highlighting in the UI.\n",
        "- `statusMessage` (optional): the status message of the event. Additional field for context of the event. E.g. the error message of an error event.\n",
        "- `input` (optional): the input to the event. Can be any JSON object.\n",
        "- `output` (optional): the output to the event. Can be any JSON object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tuSjykFW9Iw1"
      },
      "outputs": [],
      "source": [
        "from langfuse.api.model import CreateEvent\n",
        "import datetime\n",
        "\n",
        "event = span.event(CreateEvent(\n",
        "        name=\"chat-docs-retrieval\",\n",
        "        startTime=datetime.datetime.now(),\n",
        "        metadata={\"key\": \"value\"},\n",
        "        input = {\"key\": \"value\"},\n",
        "        output = {\"key\": \"value\"}\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4h-gogK-YLh"
      },
      "source": [
        "`span.update()` take the following parameters:\n",
        "\n",
        "- `spanId`: the id of the span to update\n",
        "- `endTime` (optional): the time at which the span ended\n",
        "- `metadata` (optional): merges with existing metadata of the span. Can be any JSON object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDoIw_Wj7r3b"
      },
      "source": [
        "### Nesting of observations\n",
        "\n",
        "Nesting of observations is helpful to structure the trace in a hierarchical way. This is especially helpful for complex chains and agents.\n",
        "\n",
        "```\n",
        "Simple example\n",
        "- trace: chat-app-session\n",
        "  - span: chat-interaction\n",
        "    - event: get-user-profile\n",
        "    - generation: chat-completion\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R0qJYfnw8BDb"
      },
      "outputs": [],
      "source": [
        "trace = langfuse.trace(CreateTrace(name = \"chat-app-session\"))\n",
        "span = trace.span(CreateSpan(name = \"chat-interaction\"))\n",
        "event = span.event(CreateEvent(name = \"get-user-profile\"))\n",
        "generation = span.generation(CreateGeneration(name = \"chat-completion\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EABnZymiSej8"
      },
      "source": [
        "## 3. Collect scores\n",
        "\n",
        "Scores are used to evaluate executions/traces. They are always attached to a single trace. If the score relates to a specific step of the trace, the score can optionally also be atatched to the observation to enable evaluating it specifically.\n",
        "\n",
        "- `traceId`: the id of the trace to which the score should be attached\n",
        "- `name`: identifier of the score, string\n",
        "- `value`: the value of the score; float; optional: scale it to e.g. 0..1 to make it comparable to other scores\n",
        "- `traceIdType` (optional): the type of the traceId. Can be `LANGFUSE` (default) or `EXTERNAL`. If `EXTERNAL` is used, the score will be attached to the trace with the given externalId.\n",
        "- `comment` (optional): additional context/explanation of the score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mj19Zby3SfT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee4ec75-c29b-4ecd-d763-ce6a53e73d5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langfuse.client.StatefulClient at 0x7f5b914d6200>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from langfuse.api.model import CreateScore\n",
        "\n",
        "\n",
        "trace.score(CreateScore(\n",
        "    name=\"user-explicit-feedback\",\n",
        "    value=1,\n",
        "    comment=\"I like how personalized the response is\"\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEh4aFFfIK5I",
        "outputId": "1d491464-7b55-434e-b578-a12321e456aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': 'success'}\n"
          ]
        }
      ],
      "source": [
        "result = await langfuse.async_flush()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q5aljyIoU42"
      },
      "source": [
        "### Flushing\n",
        "\n",
        "The Langfuse client is built asynchronous to not add latency. Only when calling the flush function, the network requests to the langfuse backend will be executed.\n",
        "\n",
        "Langfuse offers two different fush functions. `async_flush` returns a coroutine and hence can be used in async contexts such as this Notebook. `flush` is a synchronous function and takes care of asynchronous code in the background and is blocking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jpWEosnINa4",
        "outputId": "2df9f734-0ebc-43e5-fc2c-21ed1bccb6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': 'success'}\n"
          ]
        }
      ],
      "source": [
        "# result = await client.flush()\n",
        "# returns a result and executes a coroutine in the background\n",
        "\n",
        "result = await langfuse.async_flush() # returns a coroutine\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrate Langfuse with Langchain\n",
        "Many people use Langchain to get started fast with LLM apps. This section explains, how you can integrate Langchain with Langfuse."
      ],
      "metadata": {
        "id": "05afP0VbYHX0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbSpd5EiZouE"
      },
      "source": [
        "## 1. Initializing the client\n",
        "\n",
        "The Langfuse SDKs are hosted on the pypi index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YNyU6IzCZouE",
        "outputId": "f68a7ebc-40b0-4d0a-8593-117f32f65d30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langfuse in /usr/local/lib/python3.10/dist-packages (0.0.52)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from langfuse) (23.1.0)\n",
            "Requirement already satisfied: httpx<0.25.0,>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from langfuse) (0.24.1)\n",
            "Requirement already satisfied: langchain<0.0.238,>=0.0.237 in /usr/local/lib/python3.10/dist-packages (from langfuse) (0.0.237)\n",
            "Requirement already satisfied: pydantic==1.10.7 in /usr/local/lib/python3.10/dist-packages (from langfuse) (1.10.7)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from langfuse) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.7->langfuse) (4.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.15.4->langfuse) (2023.5.7)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.15.4->langfuse) (0.17.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.15.4->langfuse) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.25.0,>=0.15.4->langfuse) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (0.5.13)\n",
            "Requirement already satisfied: langsmith<0.0.11,>=0.0.10 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (0.0.10)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (1.2.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.0.238,>=0.0.237->langfuse) (8.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.0->langfuse) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.0.238,>=0.0.237->langfuse) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.238,>=0.0.237->langfuse) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.238,>=0.0.237->langfuse) (0.9.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.15.4->langfuse) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.15.4->langfuse) (3.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.0.238,>=0.0.237->langfuse) (1.26.16)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.0.238,>=0.0.237->langfuse) (2.0.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx<0.25.0,>=0.15.4->langfuse) (1.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.238,>=0.0.237->langfuse) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain<0.0.238,>=0.0.237->langfuse) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpE57ujJZouE"
      },
      "source": [
        "Initialize the client with api keys and optionally your environment. In the example we are using the cloud environment which is also the default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dEdF-668ZouF"
      },
      "outputs": [],
      "source": [
        "ENV_HOST = \"https://cloud.langfuse.com\"\n",
        "ENV_SECRET_KEY = \"sk-lf-...\"\n",
        "ENV_PUBLIC_KEY = \"pk-lf-...\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "divRadPqZouF"
      },
      "outputs": [],
      "source": [
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Langchain setup"
      ],
      "metadata": {
        "id": "FzsO2Ci4EjJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-...'"
      ],
      "metadata": {
        "id": "R66lMkgabfLN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain openai"
      ],
      "metadata": {
        "id": "LGLLnTWsbevn",
        "outputId": "fba42847-fa84-4059-ef7f-7b4fa162ed23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.237)\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.13)\n",
            "Requirement already satisfied: langsmith<0.0.11,>=0.0.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.10)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# further imports\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langfuse.callback import CallbackHandler\n"
      ],
      "metadata": {
        "id": "L9u5QMVCbPtR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Sequential Chain\n"
      ],
      "metadata": {
        "id": "ZUenj0aca9qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
        "    Title: {title}\n",
        "    Playwright: This is a synopsis for the above play:\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
        "\n",
        "    Play Synopsis:\n",
        "    {synopsis}\n",
        "    Review from a New York Times play critic of the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[synopsis_chain, review_chain],\n",
        ")\n",
        "review = overall_chain.run(\"Tragedy at sunset on the beach\", callbacks=[handler]) # add the handler to the run method\n",
        "await handler.langfuse.async_flush()\n"
      ],
      "metadata": {
        "id": "dTagwV_cbFVr",
        "outputId": "215fdc36-2ed9-4cc2-d22e-44188469d5ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'success'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. QA Retrieval"
      ],
      "metadata": {
        "id": "FP5avhNb3TBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SERPAPI_API_KEY\"] = '...'"
      ],
      "metadata": {
        "id": "wjiWEkRUFzCf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install unstructured chromadb tiktoken google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p0CgEPSlEpkC",
        "outputId": "fd2f2a93-888d-4e02-e479-220ef5abe366"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.8.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.3-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.0/399.0 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
            "Collecting msg-parser (from unstructured)\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.5.3)\n",
            "Collecting pdf2image (from unstructured)\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.4.0)\n",
            "Collecting pypandoc (from unstructured)\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Collecting python-docx (from unstructured)\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from unstructured)\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.27.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.0.1)\n",
            "Collecting requests (from unstructured)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.7)\n",
            "Collecting chroma-hnswlib==0.7.1 (from chromadb)\n",
            "  Downloading chroma-hnswlib-0.7.1.tar.gz (30 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.7.1)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.65.0)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.16)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.6)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting olefile>=0.46 (from msg-parser->unstructured)\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured)\n",
            "  Downloading cryptography-41.0.2-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting XlsxWriter>=0.5.7 (from python-pptx->unstructured)\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
            "Building wheels for collected packages: chroma-hnswlib, google-search-results, pypika, python-docx, python-pptx, olefile\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.1-cp310-cp310-linux_x86_64.whl size=2272522 sha256=f78d1b4068e5b604729287f9badff77c290005bdaf1e9162981794f91050f06f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/f2/d2/3f32228e9f4713a9f32a468de8bbc3c642f7805ebef888418b\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32002 sha256=92ecc1c62eb32e3427bc7829811b7bef244d21e1ff0038a40578d3caeb2e293a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=36d34a90f5d37f52fe073824b32f83a4b02472f3cb1463852cdc3abf5d36acfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=24a2659a30e0493f55649bcdff101bee6cf9a049e1d0399510efec65b98efb4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=e382cb3f16e1b696912e663ea9d446f830d44b66095dbb5e321b936cef726ad2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/dd/74/01b3ec7256a0800b99384e9a0f7620e358afc3a51a59bf9b49\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=a6e393c1c04225a3ae09e76c8ae827d0bdd2848e2900abddae320fc636878445\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/39/c0/9eb1f7a42b4b38f6f333b6314d4ed11c46f12a0f7b78194f0d\n",
            "Successfully built chroma-hnswlib google-search-results pypika python-docx python-pptx olefile\n",
            "Installing collected packages: tokenizers, pypika, monotonic, filetype, XlsxWriter, websockets, uvloop, uvicorn, requests, python-magic, python-dotenv, python-docx, pypandoc, pulsar-client, pdf2image, overrides, olefile, humanfriendly, httptools, chroma-hnswlib, backoff, watchfiles, tiktoken, starlette, python-pptx, posthog, msg-parser, google-search-results, cryptography, coloredlogs, pdfminer.six, onnxruntime, fastapi, unstructured, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed XlsxWriter-3.1.2 backoff-2.2.1 chroma-hnswlib-0.7.1 chromadb-0.4.3 coloredlogs-15.0.1 cryptography-41.0.2 fastapi-0.99.1 filetype-1.2.0 google-search-results-2.4.2 httptools-0.6.0 humanfriendly-10.0 monotonic-1.6 msg-parser-1.2.0 olefile-0.46 onnxruntime-1.15.1 overrides-7.3.1 pdf2image-1.16.3 pdfminer.six-20221105 posthog-3.0.1 pulsar-client-3.2.0 pypandoc-1.11 pypika-0.48.9 python-docx-0.8.11 python-dotenv-1.0.0 python-magic-0.4.27 python-pptx-0.6.21 requests-2.31.0 starlette-0.27.0 tiktoken-0.4.0 tokenizers-0.13.3 unstructured-0.8.1 uvicorn-0.23.1 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cryptography",
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/langfuse/langfuse-docs/main/public/state_of_the_union.txt\",\n",
        "]\n",
        "\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "\n",
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "docsearch = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 1}),\n",
        ")\n",
        "\n",
        "result = chain.run(query, callbacks=[handler])\n",
        "\n",
        "print(result)\n",
        "\n",
        "await handler.langfuse.async_flush()\n"
      ],
      "metadata": {
        "id": "kHDVa-Ssb-KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca9e58a-6a05-4d98-fe8e-aac77bb46cf0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The president said that Ketanji Brown Jackson is one of our nation's top legal minds and will continue Justice Breyer's legacy of excellence.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'success'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Agent"
      ],
      "metadata": {
        "id": "JCmI0I20-sbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "\n",
        "handler = CallbackHandler(ENV_PUBLIC_KEY, ENV_SECRET_KEY, ENV_HOST)\n",
        "\n",
        "llm = OpenAI(openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "result = agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\", callbacks=[handler])\n",
        "\n",
        "await handler.langfuse.async_flush()\n",
        "\n",
        "print(\"output variable: \", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReaHdQOT-S3n",
        "outputId": "05af8e5a-1229-4cbe-9efe-5ca78097371d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out who the girlfriend is and then use a calculator to calculate the age raised to the 0.43 power.\n",
            "Action: Search\n",
            "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe actor is believed to have recently split from his girlfriend of five years, actor Camila Morrone, but has previously been romantically ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out how old Camila Morrone is.\n",
            "Action: Search\n",
            "Action Input: \"Camila Morrone age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m26 years\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to use the calculator to calculate 26 raised to the 0.43 power.\n",
            "Action: Calculator\n",
            "Action Input: 26^0.43\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 4.059182145592686\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Leo DiCaprio's girlfriend is Camila Morrone, who is 26 years old and her age raised to the 0.43 power is 4.059182145592686.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "output variable:  Leo DiCaprio's girlfriend is Camila Morrone, who is 26 years old and her age raised to the 0.43 power is 4.059182145592686.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgtTX-Vd_Ac-"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter any issue, we are happy to help on [Discord](https://discord.gg/7NXusRtqYU) or shoot us an email: help@langfuse.com"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqBspBzuRk9C"
      },
      "source": [
        "# Python SDK\n",
        "\n",
        "- [View as notebook on GitHub](https://github.com/langfuse/langfuse-demo-python/blob/main/notebook.ipynb)\n",
        "- [Open as notebook in Google Colab](http://colab.research.google.com/github/langfuse/langfuse-demo-python/blob/main/notebook.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc6Uxbl3R5El"
      },
      "source": [
        "## 1. Initializing the client\n",
        "\n",
        "The langfuse SDKs are hosted in a private pypi index by [Fern](https://buildwithfern.com/). To install the sdk, you need to specify the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F21wZSUyKLzb",
        "outputId": "915fed2f-ce42-451d-ef0b-bc64dc5ea324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.buildwithfern.com\n",
            "Collecting finto-fern-langfuse\n",
            "  Downloading https://pypi.buildwithfern.com/finto-fern-langfuse/0.0.348/finto_fern_langfuse-0.0.348-py3-none-any.whl (20 kB)\n",
            "Collecting httpx==0.23.3 (from finto-fern-langfuse)\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0.0,>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from finto-fern-langfuse) (1.10.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.23.3->finto-fern-langfuse) (2022.12.7)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx==0.23.3->finto-fern-langfuse)\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3 (from httpx==0.23.3->finto-fern-langfuse)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.23.3->finto-fern-langfuse) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.9.2->finto-fern-langfuse) (4.5.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.17.0,>=0.15.0->httpx==0.23.3->finto-fern-langfuse)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx==0.23.3->finto-fern-langfuse) (3.6.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from rfc3986[idna2008]<2,>=1.3->httpx==0.23.3->finto-fern-langfuse) (3.4)\n",
            "Installing collected packages: rfc3986, h11, httpcore, httpx, finto-fern-langfuse\n",
            "Successfully installed finto-fern-langfuse-0.0.348 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 rfc3986-1.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install --extra-index-url https://pypi.buildwithfern.com finto-fern-langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAupsw1pR_6q"
      },
      "source": [
        "Initialize the client with your environment and api keys. In the example we are using the cloud environment. The Python client can modify all entities in the Langfuse API and requires the secret key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iDfYwZf4KUnY"
      },
      "outputs": [],
      "source": [
        "ENV_HOST = \"https://cloud.langfuse.com\"\n",
        "ENV_SECRET_KEY = \"sk-lf-...\"\n",
        "ENV_PUBLIC_KEY = \"pk-lf-...\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from finto.client import FintoLangfuse\n",
        "\n",
        "client = FintoLangfuse(\n",
        "    environment=ENV_HOST,\n",
        "    password=ENV_SECRET_KEY,\n",
        "    username=ENV_PUBLIC_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "PuPgkTU476y4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT4uaBm4SLvw"
      },
      "source": [
        "## 2. Trace execution of backend\n",
        "\n",
        "- Each backend execution is logged with a single `trace`.\n",
        "- Each trace can contain multiple `observations` to log the individual steps of the execution.\n",
        "  - Observations can be nested.\n",
        "  - Observations can be of different types\n",
        "    - `Events` are the basic building block. They are used to track discrete events in a trace.\n",
        "    - `Spans` represent durations of units of work in a trace.\n",
        "    - `Generations` are spans which are used to log generations of AI model. They contain additional attributes about the model and the prompt/completion and are specifically rendered in the langfuse UI.\n",
        "\n",
        "**Timestamps**\n",
        "\n",
        "All timestamps need to be formatted in the following way before being used in the SDK. This is a limitation of the current python SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SB2FAfezKfLq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a83d787b-bce2-4c23-c9fb-bcd2d8e451a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2023-06-22T11:56:38Z'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traces\n",
        "\n",
        "Traces are the top-level entity in the Langfuse API. They represent an execution flow in a LLM application usually triggered by an external event.\n",
        "\n",
        "Traces can be created and updated.\n",
        "\n",
        "`trace.create()` takes the following parameters:\n",
        "\n",
        "- `name` (optional): identifier of the trace. Useful for sorting/filtering in the UI.\n",
        "- `metadata` (optional): additional metadata of the trace. Can be any JSON object."
      ],
      "metadata": {
        "id": "3GjVFk7N9jZr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z9Kxxjp004WD"
      },
      "outputs": [],
      "source": [
        "from finto.resources.trace.types.create_trace_request import CreateTraceRequest\n",
        "\n",
        "trace = client.trace.create(\n",
        "    request = CreateTraceRequest(\n",
        "        name=\"chat-completion\",\n",
        "        metadata= {\n",
        "            \"env\": \"production\",\n",
        "            \"user\": \"user__935d7d1d-8625-4ef4-8651-544613e7bd22\",\n",
        "        }\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations\n",
        "\n",
        "### Events\n",
        "\n",
        "Events are used to track discrete events in a trace.\n",
        "\n",
        "- `traceId` (optional): the id of the trace to which the event should be attached. If no traceId is provided, the event will be attached to a new trace.\n",
        "- `startTime`: the time at which the event started.\n",
        "- `name` (optional): identifier of the event. Useful for sorting/filtering in the UI.\n",
        "- `metadata` (optional): additional metadata of the event. JSON object.\n",
        "- `parentObservationId` (optional): the id of the span or event to which the event should be attached"
      ],
      "metadata": {
        "id": "wfzAYslz9Aks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from finto.resources.event.types.create_event_request import CreateEventRequest\n",
        "\n",
        "event = client.event.create(\n",
        "    request=CreateEventRequest(\n",
        "        traceId=trace.id,\n",
        "        name=\"chat-docs-retrieval\",\n",
        "        startTime=datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
        "        metadata={\n",
        "            \"key\": \"value\"\n",
        "        },\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "tuSjykFW9Iw1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Span\n",
        "\n",
        "Spans represent durations of units of work in a trace. We generated convenient SDK functions for generic spans as well as LLM spans.\n",
        "\n",
        "`span.create()` take the following parameters:\n",
        "\n",
        "- `traceId` (optional): the id of the trace to which the span should be attached. If no traceId is provided, the span will be attached to a new trace.\n",
        "- `startTime` (optional): the time at which the span started. If no startTime is provided, the current time will be used.\n",
        "- `endTime` (optional): the time at which the span ended. Can also be set using `span.update()`.\n",
        "- `name` (optional): identifier of the span. Useful for sorting/filtering in the UI.\n",
        "- `metadata` (optional): additional metadata of the span. Can be any JSON object. Can also be set or updated using `span.update()`.\n",
        "- `parentObservationId` (optional): the id of the observation to which the span should be attached"
      ],
      "metadata": {
        "id": "UtWxwt3H90qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from finto.resources.span.types.create_span_request import CreateSpanRequest\n",
        "\n",
        "retrievalStartTime = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "\n",
        "# retrieveDocs = retrieveDoc()\n",
        "# ...\n",
        "\n",
        "span = client.span.create(\n",
        "    request=CreateSpanRequest(\n",
        "        traceId=trace.id,\n",
        "        name=\"chat-completion\",\n",
        "        startTime=retrievalStartTime,\n",
        "        endTime=datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
        "        metadata={\n",
        "            \"key\": \"value\"\n",
        "        },\n",
        "        parentObservationId=event.id,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "otJQPNC198Ti"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`span.update()` take the following parameters:\n",
        "\n",
        "- `spanId`: the id of the span to update\n",
        "- `endTime` (optional): the time at which the span ended\n",
        "- `metadata` (optional): merges with existing metadata of the span. Can be any JSON object."
      ],
      "metadata": {
        "id": "u4h-gogK-YLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation\n",
        "\n",
        "Generations are used to log generations of AI model. They contain additional attributes about the model and the prompt/completion and are specifically rendered in the langfuse UI.\n",
        "\n",
        "`generation.log()` take the following parameters:\n",
        "\n",
        "- `traceId` (optional): the id of the trace to which the generation should be attached. If no traceId is provided, the generation will be attached to a new trace.\n",
        "- `startTime` (optional): the time at which the generation started.\n",
        "- `endTime` (optional): the time at which the generation ended.\n",
        "- `name` (optional): identifier of the generation. Useful for sorting/filtering in the UI.\n",
        "- `model` (optional): the name of the model used for the generation\n",
        "- `modelParameters` (optional): the parameters of the model used for the generation; can be any key-value pairs\n",
        "- `prompt` (optional): the prompt used for the generation; can be any string or JSON object (recommended for chat models or other models that use structured input)\n",
        "- `completion` (optional): the completion generated by the model\n",
        "- `usage` (optional): the usage of the model during the generation; takes two optional key-value pairs: `promptTokens` and `completionTokens`\n",
        "- `metadata` (optional): additional metadata of the generation. Can be any JSON object.\n",
        "- `parentObservationId` (optional): the id of the observation to which the generation should be attached as a child."
      ],
      "metadata": {
        "id": "uNPQH8Nz-duo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nJfTbXvNQ6iD"
      },
      "outputs": [],
      "source": [
        "from finto.resources.generations.types.create_log import CreateLog\n",
        "from finto.resources.generations.types.llm_usage import LlmUsage\n",
        "\n",
        "generationStartTime = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "\n",
        "# chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world\"}])\n",
        "# ...\n",
        "\n",
        "generation = client.generations.log(\n",
        "    request=CreateLog(\n",
        "        traceId=trace.id,\n",
        "        name=\"test\",\n",
        "        startTime=generationStartTime,\n",
        "        endTime=datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        modelParameters= {\n",
        "            \"temperature\":0.9,\n",
        "            \"maxTokens\":1000,\n",
        "            \"topP\":None,\n",
        "        },\n",
        "        prompt=[{\"role\": \"user\", \"content\":\"Hello, how are you?\"}],\n",
        "        completion=\"I am fine, thank you\",\n",
        "        usage=LlmUsage(\n",
        "            prompt_tokens=512,\n",
        "            completion_tokens=49\n",
        "        ),\n",
        "        metadata= {\n",
        "            \"userid\":'user__935d7d1d-8625-4ef4-8651-544613e7bd22',\n",
        "        }\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EABnZymiSej8"
      },
      "source": [
        "## 3. Collect scores\n",
        "\n",
        "Scores are used to evaluate executions/traces. They are always attached to a single trace. If the score relates to a specific step of the trace, the score can optionally also be atatched to the observation to enable evaluating it specifically.\n",
        "\n",
        "- `traceId`: the id of the trace to which the score should be attached\n",
        "- `name`: identifier of the score, string\n",
        "- `value`: the value of the score; float; optional: scale it to e.g. 0..1 to make it comparable to other scores\n",
        "- `observationId` (optional): the id of the span, event or generation to which the score should be attached\n",
        "\n",
        "Scores can also be modified by the serverClient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mj19Zby3SfT9"
      },
      "outputs": [],
      "source": [
        "from finto.resources.score.types.create_score_request import CreateScoreRequest\n",
        "\n",
        "score = client.score.create(\n",
        "    request=CreateScoreRequest(\n",
        "        traceId=trace.id,                  # trace the score is related to\n",
        "        name=\"user-explicit-feedback\",\n",
        "        value=1,\n",
        "        observationId=generation.id           # optionally: also attach the score to an individual observation\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter any issue, we are happy to help on [Discord](https://discord.gg/7NXusRtqYU) or shoot us an email: help@langfuse.com"
      ],
      "metadata": {
        "id": "DgtTX-Vd_Ac-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}